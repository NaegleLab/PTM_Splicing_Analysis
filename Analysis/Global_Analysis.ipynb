{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of PTMs and Splicing\n",
    "\n",
    "This notebook contains all analysis used to generate data for the analysis of PTMs and Splicing (detailed in our manuscript here). To run this, notebook, you must have the resulting files from a complete mapping run of the [ExonPTMapper](https://github.com/NaegleLab/ExonPTMapper/tree/main) python package.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Load Data](#load-data)\n",
    "2. [Exclusion of PTMs (Figure 2)](#ptm-exclusion)\n",
    "    1. [Constitutive PTM Rates (Figure 2A/B)](#constitutive-ptm-rate)\n",
    "        1. [All alternative isoforms (Figure 2B)](#all-alternative-isoforms)\n",
    "        2. [Filtering out potentially non-functional transcripts (Supplementary Figure 8)](#filtering-out-potentially-non-functional-transcripts)\n",
    "    2. [Biological Process and Function Enrichment of Splicing-Controlled PTMs (Supplementary Figure 9)](#biological-process-and-function-enrichment-of-splicing-controlled-ptms)\n",
    "    3. [Splice Events Responsible for Exclusion (Figure 2C)](#splice-events-responsible-for-ptm-exclusion) \n",
    "    4. [Density of PTMs in Tissue Specific Exons (Figure 2D)](#density-of-ptms-in-tissue-specific-exons)\n",
    "3. [Altered Flanking Sequences of PTMs (Figure 3)](#altered-flanking-sequences)\n",
    "    1. [Modification specific flanking sequence alteration rates (Figure 3C)](#mod-specific-rates-of-alteration)\n",
    "    2. [Events Causing Altered Flanking Sequences (Figure 3D)](#events-causing-altered-flanking-sequences)\n",
    "    3. [Sequence Similarity Between Canonical and Alternative Flanking Sequences (Figure 3E)](#sequence-similarity-between-flanking-sequences-in-canonical-and-alternative)\n",
    "    4. [Position of Altered Residues in Flanking Sequences (Supplementary Figure 11)](#position-of-altered-residues-in-flanking-sequence)\n",
    "    5. [Kinase Library Analysis (Figure 3F-G)](#kinase-library-analysis)\n",
    "4. [ESRP1-mediated Splicing in Prostate Cancer (Figure 4)](#esrp1-mediated-splicing-in-prostate-cancer)\n",
    "    1. [Project PTMs onto the SpliceSeq splicegraph](#projecting-ptms-onto-spliceseq-exons)\n",
    "    2. [Identifying differentially included PTMs in ESRP1-High Prostate Cancer Patients](#identify-differentially-included-ptm-containing-exons)\n",
    "    3. [Gene set enrichment of ESRP1-correlated genes (Supplementary Figure 12)](#gene-set-enrichment-of-esrp1-correlated-genes)\n",
    "    4. [Site-specific set enrichment of ESRP1-correlated PTMs (Supplementary Figure 13)](#site-enrichment-of-esrp1-correlated-ptms)\n",
    "    5. [Kinase Enrichment of ESRP1-correlated Substrates (Supplementary Figure 16)](#kinase-enrichment-of-esrp1-correlated-substrates)\n",
    "5. [Analysis of PTMs in Canonical and Alternative UniProt Isoforms (Supplementary Figure 2)](#analysis-of-ptms-in-canonical-and-alternative-uniprot-isoforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam\\miniconda3\\envs\\splice\\Lib\\site-packages\\Bio\\pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Canonical UniProt isoforms\n",
      "Downloading ID translator file\n",
      "Loading mapper object from .tsv files\n",
      "Loading exon-specific data\n",
      "Loading transcript-specific data\n",
      "Loading gene-specific info\n",
      "Loading unique protein isoforms\n",
      "Loading protein-specific info\n",
      "Loading information on PTMs on canonical proteins\n",
      "Loading genomic coordinates of PTMs associated with canonical proteins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\OneDrive\\Documents\\GradSchool\\Research\\Splicing\\ExonPTMapper\\ExonPTMapper\\mapping.py:1767: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.ptm_coordinates = pd.read_csv(config.processed_data_dir + 'ptm_coordinates.csv',index_col = 0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading information on PTMs on alternative proteins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_40120\\1599296572.py:35: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mapper.isoform_ptms = pd.read_csv(config.processed_data_dir + 'isoform_ptms.csv', header = 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from Bio import pairwise2\n",
    "from ExonPTMapper import mapping, config\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import custom statistic functions\n",
    "import stat_utils\n",
    "\n",
    "#location of figshare data\n",
    "figshare_dir = 'C:/Users/Sam/OneDrive/Documents/GradSchool/Research/Splicing/Paper_Prep/PTM_Splicing_FigShare_Update/'\n",
    "#where to find projected PTMs\n",
    "#ptm_data_dir = figshare_dir + 'PTM_Projection_Data/'\n",
    "ptm_data_dir = 'C:/Users/Sam/OneDrive/Documents/GradSchool/Research/Splicing/Data/April18_2024/'\n",
    "#where to find information from different databases\n",
    "database_dir = figshare_dir + 'External_Data/'\n",
    "#where analysis data will be saved\n",
    "#analysis_dir = figshare_dir + 'Analysis_For_Paper/'\n",
    "analysis_dir = figshare_dir + '/Analysis_For_Paper/'\n",
    "\n",
    "\n",
    "\n",
    "#set global figure parameters\n",
    "min_mods = 150\n",
    "\n",
    "\n",
    "\n",
    "#load and process mapping data\n",
    "mapper = mapping.PTM_mapper()\n",
    "mapper.ptm_info.index = mapper.ptm_info['Protein'] + '_' + mapper.ptm_info['Residue']+mapper.ptm_info['PTM Location (AA)'].astype(str)\n",
    "if os.path.exists(config.processed_data_dir + 'isoform_ptms.csv'):\n",
    "    mapper.isoform_ptms = pd.read_csv(config.processed_data_dir + 'isoform_ptms.csv', header = 0)\n",
    "\n",
    "\n",
    "#get modification class names and subtypes (converting between classes and subtypes)\n",
    "mod_groups = pd.read_csv('C:/Users/Sam/OneDrive/Documents/GradSchool/Research/Splicing/Paper_Prep/PTM_Splicing_FigShare_Update/External_Data/modification_conversion.csv', header = 0)\n",
    "\n",
    "\n",
    "#separate ptm_info into unique exon/PTM pairs\n",
    "exploded_ptms = mapper.explode_PTMinfo(explode_cols=['Transcripts', 'Gene Location (NC)', 'Transcript Location (NC)', 'Exon Location (NC)', 'Exon stable ID', 'Exon rank in transcript', 'Distance to C-terminal Splice Boundary (NC)', 'Distance to N-terminal Splice Boundary (NC)'])\n",
    "exploded_ptms = exploded_ptms.dropna(subset = ['Exon stable ID'])\n",
    "\n",
    "\n",
    "#separate based on modifications (unique PTM/modification class pairs)\n",
    "exploded_mods = mapper.ptm_info.copy()\n",
    "exploded_mods[\"Modification Class\"] = exploded_mods['Modification Class'].apply(lambda x: x.split(';'))\n",
    "exploded_mods = exploded_mods.explode('Modification Class').reset_index()\n",
    "exploded_mods = exploded_mods.rename({'index':'PTM'}, axis = 1)\n",
    "exploded_mods = exploded_mods.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6880696014811886"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = mapper.ptm_info[mapper.ptm_info['Isoform Type'] == 'Canonical']\n",
    "tmp[tmp[\"PTM Conservation Score\"] == 1].shape[0]/tmp.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get isoform-specific PTM information\n",
    "\n",
    "Code used to collapse ptm information into data for only unique protein isoforms (unique amino acid sequence). Then the constitutive rates and rate of altered flanking sequences can be calculated. These functions are present in the standard pipeline code, but are not automatically done when running the pipeline. \n",
    "\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1339434/1339434 [00:30<00:00, 44110.40it/s]\n"
     ]
    }
   ],
   "source": [
    "#collapse alternative ptms dataframe to only include unique protein isoforms\n",
    "mapper.getIsoformSpecificPTMs()\n",
    "#calculate fraction of isoforms containing the a given ptm\n",
    "mapper.calculate_PTMconservation()\n",
    "\n",
    "#get flanking sequence changes\n",
    "for size in range(1,11):\n",
    "    mapper.isoform_ptms[f'Conserved Flank (Size = {size})'] = mapper.compareAllFlankSeqs(flank_size=size)\n",
    "\n",
    "#get tryptic fragments\n",
    "mapper.isoform_ptms['Conserved Fragment'] = mapper.compareAllTrypticFragments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mapping Result\n",
       "Not Found           0.175347\n",
       "Ragged Insertion    0.000372\n",
       "Residue Mismatch    0.000037\n",
       "Success             0.824244\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canonical_isoforms = config.translator.loc[config.translator['UniProt Isoform Type'] == 'Canonical', 'Transcript stable ID'].unique()\n",
    "alternative_isoform_ptms = mapper.isoform_ptms.copy()\n",
    "#alternative_isoform_ptms['Isoform ID'] = alternative_isoform_ptms['Source of PTM'].apply(lambda x: x.split('_')[0])\n",
    "alternative_isoform_ptms = alternative_isoform_ptms[~alternative_isoform_ptms['Isoform ID'].isin(canonical_isoforms)]\n",
    "alternative_isoform_ptms.groupby('Mapping Result').size()/alternative_isoform_ptms.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "mapper.isoform_ptms.to_csv(ptm_data_dir + 'processed_data_dir/isoform_ptms.csv', index = False)\n",
    "mapper.ptm_info.to_csv(ptm_data_dir + 'processed_data_dir/ptm_info.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTM Exclusion\n",
    "\n",
    "The following code was used to generate data for Figure 2 and supplementary figures 4-10, all focused on the exclusion/inclusion of PTMs across isoforms.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constitutive PTM Rate\n",
    "\n",
    "The first analysis we performed after projecting PTMs onto alternative isoforms was to determine the fraction of PTMs that could be defined as constitutive (found in all isoforms of a given gene). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall PTM Constitutive Rate: 0.6822873222451133\n"
     ]
    }
   ],
   "source": [
    "overall_rate, num_isoforms = mapper.calculate_PTMconservation(return_score = True)\n",
    "print('Overall PTM Constitutive Rate: ' + str(overall_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Alternative Isoforms\n",
    "\n",
    "Constitutive PTM rates were calculated for all protein-coding transcripts in Ensembl, grouped by broad modificaiton classes and modification subtypes.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "groupings = ['Modification Class', 'Modification']\n",
    "fname = ['ByModificationClass', 'ByModificationSubtype']\n",
    "\n",
    "for group, f in zip(groupings, fname):\n",
    "    #get non-duplicate data for the group type\n",
    "    if group == 'Modification Class':\n",
    "        mod_data = exploded_mods[exploded_mods['Isoform Type'] == 'Canonical'].copy()\n",
    "    elif group == 'Modification':\n",
    "        exploded_subtype = mapper.ptm_info[mapper.ptm_info['Isoform Type'] == 'Canonical'].copy()\n",
    "        exploded_subtype[\"Modification\"] = exploded_subtype['Modification'].apply(lambda x: x.split(';'))\n",
    "        exploded_subtype = exploded_subtype.explode('Modification').reset_index()\n",
    "        exploded_subtype = exploded_subtype.rename({'index':'PTM'}, axis = 1)\n",
    "        exploded_subtype = exploded_subtype.drop_duplicates(subset = ['Modification', 'PTM'])\n",
    "        mod_data = exploded_subtype.copy()\n",
    "\n",
    "    #get number of modifications\n",
    "    sizes = mod_data.groupby(group).size()\n",
    "    sizes = sizes.sort_values(ascending = False)\n",
    "    #get the number of constitutive ptms, then add in any mod types that don't have any constitutive ptms\n",
    "    constitutive_ptms = mod_data[mod_data['PTM Conservation Score'] == 1]\n",
    "    grouped_conserved = constitutive_ptms.groupby(group).size()\n",
    "    #add in any modification types that don't have any constitutive ptms\n",
    "    for mod in sizes.index:\n",
    "        if mod not in grouped_conserved.index.values:\n",
    "            grouped_conserved[mod] = 0\n",
    "    rate_data = grouped_conserved[sizes.index]/sizes\n",
    "    rate_data = pd.concat([sizes, rate_data], axis = 1)\n",
    "    rate_data.columns = ['Number of Instances in Proteome', 'Rate']\n",
    "    \n",
    "    #save data\n",
    "    if not os.path.exists(analysis_dir + '/Constitutive_Rates'):\n",
    "        os.makedirs(analysis_dir + '/Constitutive_Rates')\n",
    "    rate_data.to_csv(analysis_dir + f'/Constitutive_Rates/{f}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering out potentially non-functional transcripts\n",
    "\n",
    "To account for the possibility that some transcripts may not ultimately code for functional transcripts, we repeated the analysis of constitutive PTM rates after filtering using different criteria for functional transcripts.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51133/51133 [01:58<00:00, 430.23it/s]\n",
      "100%|██████████| 51133/51133 [00:52<00:00, 974.91it/s] \n",
      "100%|██████████| 51133/51133 [05:59<00:00, 142.22it/s]\n",
      "100%|██████████| 51133/51133 [04:47<00:00, 177.88it/s]\n",
      "100%|██████████| 51133/51133 [10:56<00:00, 77.90it/s]   \n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "num_isoforms = {}\n",
    "label = 'Ensembl (All)'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(return_score = True)\n",
    "\n",
    "label = 'UniProt'\n",
    "uniprot_isoforms = config.translator.loc[config.translator['UniProt Isoform Type'] == 'Alternative', 'Transcript stable ID'].values\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = uniprot_isoforms, save_col = 'UniProt Isoform Score', return_score = True)\n",
    "\n",
    "appris_isoforms = mapper.transcripts.dropna(subset = 'APPRIS annotation').index.values\n",
    "label = 'APPRIS'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = appris_isoforms, save_col = 'APPRIS Score', return_score = True)\n",
    "\n",
    "label = 'CCDS'\n",
    "ccds_isoforms = config.translator.dropna(subset = 'CCDS ID')['Transcript stable ID'].values\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = ccds_isoforms, save_col = 'CCDS Isoform Score', return_score = True)\n",
    "\n",
    "label = 'PDB'\n",
    "pdb_isoforms = config.translator.dropna(subset = 'PDB ID')['Transcript stable ID'].values\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = pdb_isoforms, save_col = 'PDB Isoform Score', return_score = True)\n",
    "\n",
    "label = 'RefSeq'\n",
    "refseq_isoforms = config.translator.dropna(subset = 'RefSeq mRNA ID')['Transcript stable ID'].values\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = pdb_isoforms, save_col = 'Refseq Isoform Score', return_score = True)\n",
    "\n",
    "#combine data and save\n",
    "scores = pd.Series(scores, name = 'Constitutive Rate')\n",
    "num_isoforms = pd.Series(num_isoforms, name = 'Number of Isoforms')\n",
    "scores = pd.concat([scores, num_isoforms], axis = 1)  \n",
    "\n",
    "if not os.path.exists(analysis_dir + '/Constitutive_Rates/Filtered'):\n",
    "    os.makedirs(analysis_dir + '/Constitutive_Rates/Filtered')\n",
    "scores.to_csv(analysis_dir + '/Constitutive_Rates/Filtered/ByDatabase.csv')\n",
    "\n",
    "\n",
    "#save mapper ptm info with added rate columns\n",
    "mapper.ptm_info.to_csv(ptm_data_dir + 'processed_data_dir/ptm_info.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By Transcript Support Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51133/51133 [01:29<00:00, 569.27it/s]\n",
      "100%|██████████| 51133/51133 [01:07<00:00, 756.58it/s]\n",
      "100%|██████████| 51133/51133 [01:00<00:00, 846.71it/s]\n",
      "100%|██████████| 51133/51133 [00:51<00:00, 992.27it/s] \n",
      "100%|██████████| 51133/51133 [00:35<00:00, 1441.98it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "num_isoforms = {}\n",
    "\n",
    "#all isoforms\n",
    "label = 'All'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(return_score = True)\n",
    "\n",
    "#transcript support level\n",
    "tsl_transcripts = mapper.transcripts.dropna(subset = 'Transcript support level (TSL)').copy()\n",
    "tsl1_isoforms = tsl_transcripts.loc[tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl1')].index.values\n",
    "tsl1_2_isoforms = tsl_transcripts.loc[tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl1') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl2')].index.values\n",
    "tsl1_2_3_isoforms = tsl_transcripts.loc[tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl1') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl2') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl3')].index.values\n",
    "tsl1_2_3_4_isoforms = tsl_transcripts.loc[tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl1') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl2') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl3')| tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl4')].index.values\n",
    "tsl1_2_3_4_5_isoforms = tsl_transcripts.loc[tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl1') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl2') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl3')| tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl4')| tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl5')].index.values\n",
    "label = 'TSL1/2/3/4/5'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = tsl1_2_3_4_5_isoforms, save_col = 'TSL1/2/3/4/5 Score', return_score = True)\n",
    "label = 'TSL1/2/3/4'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = tsl1_2_3_4_isoforms, save_col = 'TSL1/2/3/4/5 Score', return_score = True)\n",
    "label = 'TSL1/2/3'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = tsl1_2_3_isoforms, save_col = 'TSL1/2/3 Score', return_score = True)\n",
    "label = 'TSL1/2'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = tsl1_2_isoforms, save_col = 'TSL1/2 Score', return_score = True)\n",
    "label = 'TSL1'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = tsl1_isoforms, save_col = 'TSL1 Score', return_score = True)\n",
    "\n",
    "\n",
    "#combine data and save\n",
    "scores = pd.Series(scores, name = 'Constitutive Rate')\n",
    "num_isoforms = pd.Series(num_isoforms, name = 'Number of Isoforms')\n",
    "scores = pd.concat([scores, num_isoforms], axis = 1)  \n",
    "\n",
    "if not os.path.exists(analysis_dir + '/Constitutive_Rates/Filtered'):\n",
    "    os.makedirs(analysis_dir + '/Constitutive_Rates/Filtered')\n",
    "scores.to_csv(analysis_dir + '/Constitutive_Rates/Filtered/ByTranscriptSupportLevel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By TRIFID Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51133/51133 [01:34<00:00, 539.01it/s]\n",
      "100%|██████████| 51133/51133 [01:14<00:00, 682.26it/s]\n",
      "100%|██████████| 51133/51133 [00:57<00:00, 886.95it/s]\n",
      "100%|██████████| 51133/51133 [00:56<00:00, 897.21it/s] \n",
      "100%|██████████| 51133/51133 [00:47<00:00, 1067.76it/s]\n",
      "100%|██████████| 51133/51133 [00:48<00:00, 1063.01it/s]\n",
      "100%|██████████| 51133/51133 [00:46<00:00, 1105.58it/s]\n",
      "100%|██████████| 51133/51133 [00:44<00:00, 1149.40it/s]\n",
      "100%|██████████| 51133/51133 [00:47<00:00, 1082.72it/s]\n",
      "100%|██████████| 51133/51133 [00:47<00:00, 1071.27it/s]\n",
      "100%|██████████| 51133/51133 [00:47<00:00, 1074.49it/s]\n",
      "100%|██████████| 51133/51133 [00:45<00:00, 1125.22it/s]\n",
      "100%|██████████| 51133/51133 [00:43<00:00, 1167.73it/s]\n",
      "100%|██████████| 51133/51133 [00:45<00:00, 1125.83it/s]\n",
      "100%|██████████| 51133/51133 [00:44<00:00, 1136.81it/s]\n",
      "100%|██████████| 51133/51133 [00:43<00:00, 1176.25it/s]\n",
      "100%|██████████| 51133/51133 [00:42<00:00, 1193.58it/s]\n",
      "100%|██████████| 51133/51133 [00:41<00:00, 1229.65it/s]\n",
      "100%|██████████| 51133/51133 [00:39<00:00, 1310.95it/s]\n",
      "100%|██████████| 51133/51133 [00:37<00:00, 1359.36it/s]\n",
      "100%|██████████| 20/20 [21:45<00:00, 65.30s/it]\n"
     ]
    }
   ],
   "source": [
    "scores ={}\n",
    "num_isoforms = {}\n",
    "for cutoff in tqdm(np.arange(0, 1, 0.05)):\n",
    "    alt_transcripts = mapper.transcripts[mapper.transcripts['TRIFID Score'] > cutoff].index.values\n",
    "    scores[cutoff], num_isoforms[cutoff] = mapper.calculate_PTMconservation(transcript_subset = alt_transcripts, save_col = 'Tmp TRIFID Col', return_score = True)\n",
    "\n",
    "#combine data and save\n",
    "scores = pd.Series(scores, name = 'Constitutive Rate')\n",
    "num_isoforms = pd.Series(num_isoforms, name = 'Number of Isoforms')\n",
    "scores = pd.concat([scores, num_isoforms], axis = 1)  \n",
    "\n",
    "if not os.path.exists(analysis_dir + '/Constitutive_Rates/Filtered'):\n",
    "    os.makedirs(analysis_dir + '/Constitutive_Rates/Filtered')\n",
    "scores.to_csv(analysis_dir + '/Constitutive_Rates/Filtered/ByTRIFID.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological Process and Function Enrichment of Splicing-Controlled PTMs\n",
    "\n",
    "Identify the biological processes and functions enriched in genes with splicing-controlled PTMs, based on annotations from PhosphoSitePlus. Used for supplementary figure 9.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting enrichment of function for all ptms\n"
     ]
    }
   ],
   "source": [
    "#annotations from phosphositeplus\n",
    "annotations = pd.read_csv(database_dir + '/PhosphoSitePlus/Regulatory_sites.gz', sep = '\\t',compression = 'gzip', on_bad_lines='skip', header = 2)\n",
    "annotations['Substrate'] = annotations['ACC_ID'] + '_' + annotations['MOD_RSD'].apply(lambda x: x.split('-')[0])\n",
    "\n",
    "#add ptm column to match phosphositeplus information (isoform id for only alternative isoforms)\n",
    "ptm_info = mapper.ptm_info[mapper.ptm_info['Isoform Type'] == 'Canonical'].copy()\n",
    "ptm_info['PTM'] = ptm_info.apply(lambda x: x['Protein'].split('-')[0]+'_'+x['Residue']+str(x['PTM Location (AA)']) if x['Isoform Type'] == 'Canonical' else x['Protein']+'_'+x['Residue']+str(x['PTM Location (AA)']), axis = 1) \n",
    "\n",
    "print('Getting enrichment of function for all ptms')\n",
    "#get list of constitutive and non-constitutive ptms\n",
    "constitutive_ptms = ptm_info[ptm_info['PTM Conservation Score'] == 1]\n",
    "non_constitutive_ptms = ptm_info[ptm_info['PTM Conservation Score'] != 1]\n",
    "\n",
    "\n",
    "function_table = stat_utils.constructPivotTable(ptm_info, annotations, reference_col='ON_FUNCTION', collapse_on_similar = True, include_unknown=True)\n",
    "process_table = stat_utils.constructPivotTable(ptm_info,annotations, reference_col='ON_PROCESS', collapse_on_similar = True, include_unknown=True)\n",
    "\n",
    "function_enrichment = stat_utils.generate_site_enrichment(constitutive_ptms['PTM'].values, function_table, subset_name = 'Constitutive', type = 'Function', fishers = True)\n",
    "process_enrichment = stat_utils.generate_site_enrichment(constitutive_ptms['PTM'].values, process_table, subset_name = 'Constitutive', type = 'Process', fishers = True)\n",
    "\n",
    "function_enrichment.to_csv(analysis_dir + '/Constitutive_Rates/Enrichment/Function_Enrichment.csv')\n",
    "process_enrichment.to_csv(analysis_dir + '/Constitutive_Rates/Enrichment/Process_Enrichment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def constructPivotTable(annotated_ptms, reference_col, database = 'PhosphoSitePlus', collapse_on_similar = False, include_unknown = False):\n",
    "    \"\"\"\n",
    "    Given a ptm dataframe and regulatory data from phosphositeplus, create a table with PTMs in the rows and annotations in the columns, with 1 indicating that the PTM has that annotation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ptms : pandas dataframe\n",
    "        dataframe containing PTM data\n",
    "    regulatory : pandas dataframe\n",
    "        dataframe containing regulatory data from phosphositeplus\n",
    "    reference_col : str, optional\n",
    "        column in regulatory dataframe to use as annotations. The default is 'ON_FUNCTION'.\n",
    "    collapse_on_similar : bool, optional\n",
    "        whether to collapse similar annotations into one category. The default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    annotation : pandas dataframe\n",
    "        dataframe with PTMs in the rows and annotations in the columns, with 1 indicating that the PTM has that annotation\n",
    "    \"\"\"\n",
    "    #create matrix indicating function of each ptm: ptm in the rows, function in columns, and 1 indicating that the ptm has that function## create molecular function table, with\n",
    "    annotation = annotated_ptms.copy()\n",
    "    if include_unknown:\n",
    "        annotation.loc[annotation[reference_col].isna(), reference_col] = 'unknown'\n",
    "    annotation = annotation.dropna(subset = reference_col)\n",
    "    annotation[reference_col] = annotation[reference_col].apply(lambda x: x.split(';') if x == x else x)\n",
    "    annotation = annotation.explode(reference_col).reset_index()\n",
    "    if collapse_on_similar:\n",
    "        annotation[reference_col] = annotation[reference_col].apply(lambda x: x.split(',')[0].strip(' ') if x == x else x)\n",
    "    else:\n",
    "        annotation[reference_col] = annotation[reference_col].apply(lambda x: x.strip(' ') if x == x else x)\n",
    "    annotation['value'] = 1\n",
    "    annotation = annotation[['PTM',reference_col, 'value']].drop_duplicates()\n",
    "    annotation = annotation.pivot(index = 'PTM', columns = reference_col, values = 'value')\n",
    "    #remove any sites with no functions\n",
    "    annotation = annotation.dropna(how = 'all')\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_40120\\2573021089.py:12: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  regphos = pd.read_csv('http://140.138.144.141/~RegPhos/download/RegPhos_Phos_human.txt', sep = '\\t')\n"
     ]
    }
   ],
   "source": [
    "ks_dataset = pd.read_csv(database_dir + '/PhosphoSitePlus/Kinase_Substrate_Dataset.tsv', sep = '\\t', on_bad_lines='skip')\n",
    "ks_dataset  = ks_dataset[(ks_dataset['SUB_ORGANISM'] == 'human') & (ks_dataset['KIN_ORGANISM'] == 'human')]\n",
    "ks_dataset['Substrate'] = ks_dataset['SUB_ACC_ID'] + '_' + ks_dataset['SUB_MOD_RSD']\n",
    "\n",
    "\n",
    "#add ptm column to match phosphositeplus information (isoform id for only alternative isoforms)\n",
    "annotated_ptms = mapper.ptm_info[mapper.ptm_info['Isoform Type'] == 'Canonical'].copy()\n",
    "annotated_ptms['PTM'] = annotated_ptms.apply(lambda x: x['Protein'].split('-')[0]+'_'+x['Residue']+str(x['PTM Location (AA)']) if x['Isoform Type'] == 'Canonical' else x['Protein']+'_'+x['Residue']+str(x['PTM Location (AA)']), axis = 1) \n",
    "annotated_ptms = annotated_ptms.merge(ks_dataset[['GENE', 'Substrate']], right_on = 'Substrate', left_on = 'PTM', how = 'left')\n",
    "\n",
    "\n",
    "regphos = pd.read_csv('http://140.138.144.141/~RegPhos/download/RegPhos_Phos_human.txt', sep = '\\t')\n",
    "\n",
    "\n",
    "regphos = regphos.dropna(subset = 'catalytic kinase')\n",
    "#regphos['Residue'] = regphos['code'] + regphos['position'].astype(str)\n",
    "regphos = regphos.rename(columns = {'code': 'Residue', 'position':'PTM Position in Canonical Isoform', 'AC': 'UniProtKB Accession', 'catalytic kinase': 'RegPhos:Kinase'})\n",
    "regphos['PTM'] = regphos['UniProtKB Accession'] + '_' + regphos['Residue'] + regphos['PTM Position in Canonical Isoform'].astype(str)\n",
    "regphos = regphos[['PTM', 'RegPhos:Kinase']].dropna()\n",
    "regphos = regphos.groupby(['PTM']).agg(';'.join).reset_index()\n",
    "\n",
    "#add to splice data\n",
    "annotated_ptms = annotated_ptms.merge(regphos, how = 'left', on = ['PTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regphos_conversion = {'CK2A1':'CSNK2A1', 'PKACA':'PRKACA', 'ABL1(ABL)':'ABL1'}\n",
    "def combine_kinases(row):\n",
    "    psp = row['GENE'].split(';') if row['GENE'] == row['GENE'] else []\n",
    "    regphos = row['RegPhos:Kinase'].split(';') if row['RegPhos:Kinase'] == row['RegPhos:Kinase'] else []\n",
    "    for i, rp in enumerate(regphos):\n",
    "        if rp.upper() in regphos_conversion:\n",
    "            regphos[i] = regphos_conversion[rp.upper()]\n",
    "        else:\n",
    "            regphos[i] = rp.upper()\n",
    "    combined = np.unique(psp+regphos)\n",
    "    if len(combined) > 0:\n",
    "        return ';'.join(combined)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "annotated_ptms['Combined:Kinase'] = annotated_ptms.apply(combine_kinases, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting enrichment of function for all ptms\n"
     ]
    }
   ],
   "source": [
    "#add ptm column to match phosphositeplus information (isoform id for only alternative isoforms)\n",
    "ptm_info = mapper.ptm_info[mapper.ptm_info['Isoform Type'] == 'Canonical'].copy()\n",
    "ptm_info['PTM'] = ptm_info.apply(lambda x: x['Protein'].split('-')[0]+'_'+x['Residue']+str(x['PTM Location (AA)']) if x['Isoform Type'] == 'Canonical' else x['Protein']+'_'+x['Residue']+str(x['PTM Location (AA)']), axis = 1) \n",
    "\n",
    "print('Getting enrichment of function for all ptms')\n",
    "#get list of constitutive and non-constitutive ptms\n",
    "constitutive_ptms = ptm_info[ptm_info['PTM Conservation Score'] == 1]\n",
    "non_constitutive_ptms = ptm_info[ptm_info['PTM Conservation Score'] != 1]\n",
    "\n",
    "\n",
    "kinase_table = constructPivotTable(annotated_ptms, reference_col='Combined:Kinase', collapse_on_similar = False, include_unknown=True)\n",
    "\n",
    "kinase_enrichment = stat_utils.generate_site_enrichment(constitutive_ptms['PTM'].values, kinase_table, subset_name = 'Constitutive', type = 'Kinase', fishers = True)\n",
    "kinase_enrichment.to_csv(analysis_dir + '/Constitutive_Rates/Enrichment/Kinase_Enrichment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splice events responsible for PTM exclusion\n",
    "\n",
    "Given splice event data obtained from ExonPTMapper package, calculate the fraction of PTM exclusion events that are caused by skipped exon events, alternative splice sites, and mutually exclusive exons.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab ptms in alternative isoforms\n",
    "alternative_ptms = mapper.alternative_ptms.copy()\n",
    "\n",
    "#extract events causing loss of PTMs\n",
    "alternative_ptms = alternative_ptms[alternative_ptms['Mapping Result'] == 'Not Found']\n",
    "#remove canonical isoforms and transcripts not associated with gene name in translator object, which might mean entry is old and makes splice event mapping more difficult\n",
    "canonical_transcripts = mapper.transcripts[mapper.transcripts['UniProt Isoform Type'] == 'Canonical'].index\n",
    "missing_gene_name=config.translator.loc[config.translator['Gene name'].isna(), 'Transcript stable ID'].unique()\n",
    "alternative_ptms = alternative_ptms[(~alternative_ptms['Event Type'].isna()) & (~alternative_ptms['Alternative Transcript'].isin(canonical_transcripts)) & (~alternative_ptms['Alternative Transcript'].isin(missing_gene_name))]\n",
    "\n",
    "alternative_ptms['Event Type'] = alternative_ptms['Event Type'].apply(lambda x: x.split(';'))\n",
    "alternative_ptms = alternative_ptms.explode('Event Type').dropna(subset = 'Event Type')\n",
    "\n",
    "#separate based on modifications (unique PTM/modification class pairs)\n",
    "exploded_res = alternative_ptms.copy()\n",
    "exploded_res['Modification Class'] = exploded_res['Modification Class'].apply(lambda x: x.split(';'))\n",
    "exploded_res = exploded_res.explode('Modification Class')\n",
    "#exploded_res = exploded_res.merge(mod_groups[['Modification', 'Mod Class Code']], left_on = 'Modification', right_on = 'Modification')\n",
    "\n",
    "#extract only true splice events (ignore alternative promoters, etc.)\n",
    "events_to_keep = [\"3' ASS\", \"3' and 5' ASS\", \"5' ASS\", 'Skipped', 'Mutually Exclusive']\n",
    "exploded_res = exploded_res[exploded_res['Event Type'].isin(events_to_keep)]\n",
    "\t\n",
    "#group by modification type and event type\n",
    "grouped_res = exploded_res.groupby(['Modification Class','Event Type'])\n",
    "grouped_res = grouped_res.size().reset_index()\n",
    "\n",
    "#count number of events for each modification\n",
    "sizes = grouped_res.groupby('Modification Class')[0].sum().sort_values(ascending = False)\n",
    "mods_to_keep = sizes.index\n",
    "\n",
    "total_events = {}\n",
    "for mod in grouped_res['Modification Class'].unique():\n",
    "\tmod_grouped = grouped_res[grouped_res['Modification Class'] == mod]\n",
    "\ttotal_events[mod] = mod_grouped[0].sum()\n",
    "\t\n",
    "possible_events = grouped_res['Event Type'].unique()\n",
    "plt_data = []\n",
    "mods = mods_to_keep\n",
    "for event in possible_events:\n",
    "\tevent_data = []\n",
    "\tevent_grouped = grouped_res[grouped_res['Event Type'] == event]\n",
    "\tfor mod in mods:\n",
    "\t\tif mod in event_grouped['Modification Class'].values:\n",
    "\t\t\tevent_data.append(int(event_grouped.loc[event_grouped['Modification Class'] == mod, 0].values[0])/total_events[mod])\n",
    "\t\telse:\n",
    "\t\t\tevent_data.append(0)\n",
    "\tplt_data.append(event_data)\n",
    "\t\n",
    "event_data = pd.DataFrame(plt_data, index = possible_events, columns = mods_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data.to_csv(analysis_dir + '/Constitutive_Rates/Splice_Event_Fractions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density of PTMs in tissue specific exons\n",
    "\n",
    "Tissue-specific exons were extracted from three publications, and our projected PTM data was used to determine the density of PTMs in these exons.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tissue_specificity' from 'c:\\\\Users\\\\Sam\\\\OneDrive\\\\Documents\\\\GradSchool\\\\Research\\\\Splicing\\\\Paper_Prep\\\\PTM_Splicing_Analysis\\\\Analysis\\\\tissue_specificity.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(tissue_specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting PTM Density across the entire proteome\n",
      "Getting PTMs in tissue specific exons from Buljan et al. (2012)\n",
      "Getting PTMs in tissue specific exons from Rodriguez et al. (2020)\n",
      "Getting PTMs in tissue specific exons from Gonzalez-Porta et al. (2013)\n",
      "Calculating PTM density in tissue-specific exons\n"
     ]
    }
   ],
   "source": [
    "import tissue_specificity\n",
    "all_data, densities = tissue_specificity.getTSData(mapper, exploded_ptms, exploded_mods, mod_groups, figshare_dir = figshare_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(analysis_dir + '/Tissue_Specificity'):\n",
    "    os.mkdir(analysis_dir + '/Tissue_Specificity')\n",
    "densities.to_csv(analysis_dir + '/Tissue_Specificity/PTM_Densities.csv')\n",
    "all_data.to_csv(analysis_dir + '/Tissue_Specificity/PTMs_in_TissueSpecificExons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altered Flanking Sequences (Figure 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mod specific rates of alteration\n",
    "\n",
    "Here, we sought to look at the rate of alteration considering different window sizes (number of residues on either side of the PTM), broken down by modification type. This data was used for Figure4C.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModSpecificChanges(mapper, mod_groups, flank_size = 5, return_fraction_only = True):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of ptms with altered flanking sequence of the given flank size for each modification group\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mapper: PTMmapper object\n",
    "        PTMmapper object containing alternative and canonical flanking sequence data\n",
    "    mod_groups: pandas dataframe\n",
    "        dataframe for conversion from modification subtypes ('Mod Name') to modification classes ('Mod Class)\n",
    "    flank_size: int\n",
    "        size of the flanking sequence to compare. IMPORTANT, this should not be larger than the available flanking sequence in the ptm_info dataframe\n",
    "    return_fraction_only: bool\n",
    "        If True, return only the fraction of ptms with altered flanking sequence. If False, return the fraction of ptms with altered flanking sequence and the total number of ptms altered + total number of ptms\n",
    "    unique_isoforms: bool\n",
    "        If True, compare ptms found in unique isoforms only. If False, compare ptms found in all transcripts, regardless of if there is redundant protein sequences\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    If return_fraction_only is True:\n",
    "        fraction_altered: pandas Series\n",
    "            Series containing the fraction of ptms with altered flanking sequence for each modification group\n",
    "    If return_fraction_only is False:\n",
    "        results: pandas dataframe\n",
    "            dataframe containing the fraction of ptms with altered flanking sequence and the total number of ptms altered + total number of ptms for each modification group\n",
    "\n",
    "    \"\"\"\n",
    "    conserved = mapper.isoform_ptms[mapper.isoform_ptms['Mapping Result'] == 'Success']\n",
    "    conserved = conserved[conserved[\"Isoform Type\"] == 'Alternative']\n",
    "    conserved = conserved.drop_duplicates()\n",
    "\n",
    "    #separate into mod specific rows\n",
    "    conserved['Modification Class'] = conserved['Modification Class'].apply(lambda x: x.split(';'))\n",
    "    conserved = conserved.explode('Modification Class')\n",
    "    #conserved = conserved.merge(mod_groups[['Mod Name', 'Mod Class']], left_on = 'Modification', right_on = 'Mod Name', how = 'left')\n",
    "    #conserved = conserved.drop(['Mod Name', 'Modification'], axis = 1)\n",
    "    #conserved = conserved.drop_duplicates()\n",
    "    #calculate number of each modification type that are conserved\n",
    "    num_single_mods_conserved = conserved.groupby('Modification Class').size()\n",
    "    #calculate number of each modification type that are conserved AND have conserved flank\n",
    "    num_single_mods_conserved_flank = conserved[conserved[f'Conserved Flank (Size = {flank_size})'] == 1].groupby('Modification Class').size()\n",
    "    #calculate number of each modification type that are conserved AND have altered flank\n",
    "    num_single_mods_altered_flank = conserved[conserved[f'Conserved Flank (Size = {flank_size})'] == 0].groupby('Modification Class').size()\n",
    "\n",
    "    #fill in any mods without a conserved or altered flank\n",
    "    for mod in num_single_mods_conserved.index:\n",
    "        if mod not in num_single_mods_altered_flank.index.values:\n",
    "            num_single_mods_altered_flank[mod] = 0\n",
    "        if mod not in num_single_mods_conserved_flank.index.values:\n",
    "            num_single_mods_conserved_flank[mod] = 0\n",
    "    fraction_of_mod_with_altered_flank = num_single_mods_altered_flank/num_single_mods_conserved\n",
    "\n",
    "    if return_fraction_only:\n",
    "        fraction_of_mod_with_altered_flank.name = flank_size\n",
    "        return fraction_of_mod_with_altered_flank\n",
    "    else:\n",
    "        results = pd.concat([num_single_mods_conserved, num_single_mods_conserved_flank, num_single_mods_altered_flank, fraction_of_mod_with_altered_flank], axis = 1)\n",
    "        results.columns = ['Number of Conserved PTMs', 'Number of PTMs with Matching Flanking Sequence', 'Number of PTMs with Altered Flanking Sequence', 'Fraction of PTMs with Altered Flanking Sequence']\n",
    "        return results\n",
    "    \n",
    "def alteredByWindowSize(mapper, mod_groups, flank_size = list(range(1,6)), unique_isoforms = True):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of ptms with altered flanking sequence for each modification group for each flank size\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mapper: PTMmapper object\n",
    "        PTMmapper object containing alternative and canonical flanking sequence data\n",
    "    mod_groups: pandas dataframe\n",
    "        dataframe for conversion from modification subtypes ('Mod Name') to modification classes ('Mod Class)\n",
    "    flank_size: list\n",
    "        list of flank sizes to compare. IMPORTANT, maximum value should not be larger than the available flanking sequence in the ptm_info dataframe\n",
    "    unique_isoforms: bool\n",
    "        If True, compare ptms found in unique isoforms only. If False, compare ptms found in all transcripts, regardless of if there is redundant protein sequences\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fractions: pandas dataframe\n",
    "        dataframe containing the fraction of ptms with altered flanking sequence for each modification group for each flank size\n",
    "    \"\"\"\n",
    "    fractions = None\n",
    "    for flank in flank_size:\n",
    "        if flank == 5:\n",
    "            return_fraction_only = False\n",
    "        else:\n",
    "            return_fraction_only = True\n",
    "\n",
    "        if fractions is None:\n",
    "            fractions = getModSpecificChanges(mapper, mod_groups, flank, return_fraction_only = True)\n",
    "        elif flank == 5:\n",
    "            results = getModSpecificChanges(mapper, mod_groups, flank, return_fraction_only=False)\n",
    "            tmp_fraction = results['Fraction of PTMs with Altered Flanking Sequence']\n",
    "            tmp_fraction.name = 5\n",
    "            fractions = pd.concat([fractions, tmp_fraction], axis = 1)\n",
    "\n",
    "        else:\n",
    "            fractions = pd.concat([fractions, getModSpecificChanges(mapper, mod_groups, flank, return_fraction_only=True)], axis = 1)\n",
    "    return fractions, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions, window5_flanks = alteredByWindowSize(mapper, mod_groups)\n",
    "fractions.to_csv(analysis_dir + '/FlankingSequences/Mod_Specific_Alteration_Rates.csv')\n",
    "window5_flanks.to_csv(analysis_dir + '/FlankingSequences/Window5_FlankingSequences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events Causing Altered Flanking Sequences\n",
    "\n",
    "Analysis of the splice events that are impacting flanking sequences and whether they are caused by the PTM-containing exon or an adjacent exon. Data used in Figure 4D.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upstream_test(mapper, sevents, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript):\n",
    "    \"\"\"\n",
    "    Test for event impacting flanking sequence upstream of PTM\n",
    "    \"\"\"\n",
    "    #look at what is happening in upstream exon\n",
    "    rank = int(canonical_ptm_info['Exon rank in transcript'])\n",
    "    if rank != 1:\n",
    "        upstream_rank = rank - 1\n",
    "        upstream_exon = mapper.exons[(mapper.exons['Exon rank in transcript'] == upstream_rank) \n",
    "                                     & (mapper.exons['Transcript stable ID'] == canonical_transcript)].squeeze()\n",
    "        #check for inserted exon\n",
    "        if mapper.genes.loc[canonical_exon_info['Gene stable ID'], 'Strand'] == 1:\n",
    "            upstream_end = upstream_exon['Exon End (Gene)']\n",
    "            canonical_start = canonical_exon_info['Exon Start (Gene)']\n",
    "            alt_exons = mapper.exons[mapper.exons['Transcript stable ID'] == alt_transcript]\n",
    "            alt_exons = alt_exons[(alt_exons['Exon Start (Gene)'] > upstream_end) &\n",
    "                                    (alt_exons['Exon End (Gene)'] < canonical_start)]\n",
    "            if alt_exons.shape[0] > 0:\n",
    "                return 'Inserted Exon (Upstream Exon)'\n",
    "\n",
    "        else:\n",
    "            upstream_start = upstream_exon['Exon Start (Gene)']\n",
    "            canonical_end = canonical_exon_info['Exon End (Gene)']\n",
    "            alt_exons = mapper.exons[mapper.exons['Transcript stable ID'] == alt_transcript]\n",
    "            alt_exons = alt_exons[(alt_exons['Exon Start (Gene)'] > canonical_end) &\n",
    "                                    (alt_exons['Exon End (Gene)'] < upstream_start)]\n",
    "            if alt_exons.shape[0] > 0:\n",
    "                return 'Inserted Exon (Upstream Exon)'\n",
    "\n",
    "\n",
    "        sevent_of_interest = sevents[(sevents['Exon ID (Canonical)'] == upstream_exon['Exon stable ID'])\n",
    "                                            & (sevents['Canonical Transcript'] == canonical_transcript)]\n",
    "        if sevent_of_interest.shape[0] ==0:\n",
    "            return 'missing sevent'\n",
    "        else:\n",
    "            sevent_of_interest = sevent_of_interest.iloc[0]\n",
    "\n",
    "        if sevent_of_interest['Event Type'] == 'Skipped':\n",
    "            return 'Skipped (Upstream Exon)'\n",
    "        elif sevent_of_interest['Event Type'] == \"3' ASS\" or sevent_of_interest['Event Type'] == \"3' and 5' ASS\":\n",
    "            return 'ASS (Upstream Exon)'\n",
    "        elif sevent_of_interest['Event Type'] == 'Mutually Exclusive':\n",
    "            return 'MXE (Upstream Exon)'\n",
    "        elif sevent_of_interest['Event Type'] == 'Conserved':\n",
    "            return None\n",
    "        else:\n",
    "            return 'unclear'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def downstream_test(mapper, sevents, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript):\n",
    "    \"\"\"\n",
    "    Test for event impacting flanking sequence downstream of PTM\n",
    "    \"\"\"\n",
    "    #look at what is happening in upstream exon\n",
    "    rank = int(canonical_ptm_info['Exon rank in transcript'])\n",
    "    canonical_transcript = canonical_ptm_info['Transcripts']\n",
    "    downstream_rank = rank + 1\n",
    "    downstream_exon = mapper.exons[(mapper.exons['Exon rank in transcript'] == downstream_rank) \n",
    "                                 & (mapper.exons['Transcript stable ID'] == canonical_transcript)].squeeze()\n",
    "\n",
    "    #check for inserted exon\n",
    "    if mapper.genes.loc[canonical_exon_info['Gene stable ID'], 'Strand'] == -1:\n",
    "        downstream_end = downstream_exon['Exon End (Gene)']\n",
    "        canonical_start = canonical_exon_info['Exon Start (Gene)']\n",
    "        alt_exons = mapper.exons[mapper.exons['Transcript stable ID'] == alt_transcript]\n",
    "        alt_exons = alt_exons[(alt_exons['Exon Start (Gene)'] > downstream_end) &\n",
    "                                (alt_exons['Exon End (Gene)'] < canonical_start)]\n",
    "        if alt_exons.shape[0] > 0:\n",
    "            return 'Inserted Exon (Downstream Exon)'\n",
    "\n",
    "    else:\n",
    "        downstream_start = downstream_exon['Exon Start (Gene)']\n",
    "        canonical_end = canonical_exon_info['Exon End (Gene)']\n",
    "        alt_exons = mapper.exons[mapper.exons['Transcript stable ID'] == alt_transcript]\n",
    "        alt_exons = alt_exons[(alt_exons['Exon Start (Gene)'] > canonical_end) &\n",
    "                                (alt_exons['Exon End (Gene)'] < downstream_start)]\n",
    "        if alt_exons.shape[0] > 0:\n",
    "            return 'Inserted Exon (Downstream Exon)' \n",
    "\n",
    "    sevent_of_interest = sevents[(sevents['Exon ID (Canonical)'] == downstream_exon['Exon stable ID'])\n",
    "                                        & (sevents['Canonical Transcript'] == canonical_transcript)]\n",
    "\n",
    "    if sevent_of_interest.shape[0] == 0:\n",
    "        return 'missing sevent'\n",
    "    else:\n",
    "        sevent_of_interest = sevent_of_interest.iloc[0]\n",
    "        \n",
    "    if sevent_of_interest['Event Type'] == 'Skipped':\n",
    "        return 'Skipped (Downstream Exon)'\n",
    "    elif sevent_of_interest['Event Type'] == \"5' ASS\" or sevent_of_interest['Event Type'] == \"3' and 5' ASS\":\n",
    "        return 'ASS (Downstream Exon)'\n",
    "    elif sevent_of_interest['Event Type'] == 'Mutually Exclusive':\n",
    "        return 'MXE (Downstream Exon)'\n",
    "    elif sevent_of_interest['Event Type'] == 'Conserved':\n",
    "        return None\n",
    "    else:\n",
    "        return 'unclear'\n",
    "    \n",
    "def complete_test_forConserved(mapper, sevents, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript, flank_size = 5):\n",
    "    \"\"\"\n",
    "    If exon containing PTM is conserved, check to see what events upstream/downstream of the PTM-containing exon are impacting the flanking sequence\n",
    "    \"\"\"\n",
    "    if int(canonical_ptm_info['Distance to C-terminal Splice Boundary (NC)']) <= flank_size*3:\n",
    "        downstream_result = downstream_test(mapper, sevents, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript)\n",
    "    else:\n",
    "        downstream_result = None\n",
    "        \n",
    "    if int(canonical_ptm_info['Distance to N-terminal Splice Boundary (NC)']) <= flank_size*3:\n",
    "        upstream_result = upstream_test(mapper, sevents, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript)\n",
    "    else:\n",
    "        upstream_result = None\n",
    "        \n",
    "    if upstream_result is not None and downstream_result is not None:\n",
    "        return ','.join([upstream_result,downstream_result])\n",
    "    elif upstream_result is not None:\n",
    "        return upstream_result\n",
    "    elif downstream_result is not None:\n",
    "        return downstream_result\n",
    "    else:\n",
    "        return 'unclear'\n",
    "    \n",
    "    \n",
    "\n",
    "def complete_test_forASS(mapper, sevents, event_type, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript,alt_exon_id, flank_size = 5):\n",
    "    \"\"\"\n",
    "    If the PTM-containing exon undergoes an alternative splice site, check to see if this is causing the altered flanking sequence or if it is the result of a change to an adjacent exon\n",
    "    \"\"\"\n",
    "    alt_exon = mapper.exons[(mapper.exons['Transcript stable ID'] == alt_transcript) &\n",
    "             (mapper.exons['Exon stable ID'] == alt_exon_id)].squeeze()\n",
    "    if event_type == \"3' ASS\":\n",
    "        distance_to_altered_boundary = alt_exon['Exon End (Gene)'] -int(canonical_ptm_info['Gene Location (NC)'])\n",
    "    elif event_type == \"5' ASS\":\n",
    "        distance_to_altered_boundary = alt_exon['Exon End (Gene)'] -int(canonical_ptm_info['Gene Location (NC)'])\n",
    "    else:\n",
    "        distance_to_altered_boundary = np.min([alt_exon['Exon End (Gene)'] -int(canonical_ptm_info['Gene Location (NC)']), alt_exon['Exon End (Gene)'] -int(canonical_ptm_info['Gene Location (NC)'])])\n",
    "    \n",
    "    if distance_to_altered_boundary <= flank_size*3:\n",
    "        return 'ASS (Exon with PTM)'\n",
    "    else:\n",
    "        relevant_events = sevents[sevents['Alternative Transcript'] == alt_transcript]\n",
    "        return complete_test_forConserved(mapper, relevant_events, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper.ptm_info.index = mapper.ptm_info['Protein'] + '_' + mapper.ptm_info['Residue']+mapper.ptm_info['PTM Location (AA)'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "flank_size = 5\n",
    "mapper.alternative_ptms[f'Conserved Flank (Size = {flank_size})'] = mapper.compareAllFlankSeqs(flank_size=flank_size, unique_isoforms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16190/16190 [1:20:19<00:00,  3.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#load splice event information\n",
    "sevents = pd.read_csv(config.processed_data_dir + 'splice_events.csv').drop_duplicates()\n",
    "flank_size = 5\n",
    "#grab flanking sequences that are different from canonical, separate by event and canonical exon id\n",
    "altered_flanks = mapper.alternative_ptms[mapper.alternative_ptms[f'Conserved Flank (Size = 5)'] == 0].copy()\n",
    "#remove canonical isoforms and transcripts not associated with gene name in translator object, which might mean entry is old and makes splice event mapping more difficult\n",
    "canonical_transcripts = mapper.transcripts[mapper.transcripts['UniProt Isoform Type'] == 'Canonical'].index\n",
    "missing_gene_name=config.translator.loc[config.translator['Gene name'].isna(), 'Transcript stable ID'].unique()\n",
    "altered_flanks = altered_flanks[(~altered_flanks['Event Type'].isna()) & (~altered_flanks['Alternative Transcript'].isin(canonical_transcripts)) & (~altered_flanks['Alternative Transcript'].isin(missing_gene_name))]\n",
    "\n",
    "#extract events\n",
    "altered_flanks['Event Type'] = altered_flanks['Event Type'].apply(lambda x: x.split(';'))\n",
    "altered_flanks['Exon ID (Canonical)'] = altered_flanks['Exon ID (Canonical)'].apply(lambda x: x.split(';'))\n",
    "altered_flanks = altered_flanks.explode(['Event Type'])\n",
    "\n",
    "test = altered_flanks.copy()\n",
    "cause = []\n",
    "for i, row in tqdm(test.iterrows(), total = test.shape[0]):\n",
    "       #get distance to boundary\n",
    "    ptm = row['Source of PTM'].split(';')[0]\n",
    "    canonical_exon_id = row['Exon ID (Canonical)']\n",
    "    relevant_events = sevents[sevents['Alternative Transcript'] == row['Alternative Transcript']]\n",
    "    canonical_ptm_info = exploded_ptms[(exploded_ptms['PTM'] == ptm) & (exploded_ptms['Exon stable ID'].isin(canonical_exon_id))]\n",
    "    #grab first relevant entry (if only one, will just convert to series)\n",
    "    if canonical_ptm_info.shape[0] == 0:\n",
    "        cause.append('PTM not found')\n",
    "    elif ';' in row['Exon ID (Alternative)']:\n",
    "        cause.append('Alternative Exon ID Discrepancy')\n",
    "    else:\n",
    "        #grab canonical exon and transcript information\n",
    "        canonical_ptm_info = canonical_ptm_info.iloc[0]\n",
    "        canonical_transcript = canonical_ptm_info['Transcripts']\n",
    "        canonical_exon_info = mapper.exons[(mapper.exons['Exon stable ID'].isin(canonical_exon_id))\n",
    "                                         & (mapper.exons['Transcript stable ID'] == canonical_transcript)].squeeze()\n",
    "        #for events with a conserve exon, check for changes adjacent to exon\n",
    "        if row['Event Type'] == 'Conserved' or row['Event Type'] == 'No Difference':\n",
    "            cause.append(complete_test_forConserved(mapper, relevant_events, canonical_ptm_info, canonical_exon_info, canonical_transcript, row['Alternative Transcript'], flank_size = flank_size))\n",
    "        elif 'ASS' in row['Event Type']: #if ptm is an exon involved in ass, check if this is causing altered flank\n",
    "            cause.append(complete_test_forASS(mapper, sevents, row['Event Type'], canonical_ptm_info, canonical_exon_info, canonical_transcript, row['Alternative Transcript'], row['Exon ID (Alternative)'], flank_size = flank_size))\n",
    "        elif row['Event Type'] == 'Mutually Exclusive': #if ptm is in a mxe, annotate this as the cause\n",
    "            cause.append('MXE (Exon with PTM)')\n",
    "        else:\n",
    "            cause.append(row['Event Type'])\n",
    "\n",
    "altered_flanks['Cause'] = cause\n",
    "\n",
    "cause_breakdown = altered_flanks.groupby('Cause').size()\n",
    "cause_breakdown.name = 'Number of Instances'\n",
    "cause_breakdown.to_csv(analysis_dir + '/FlankingSequences/cause_of_alteration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Similarity Between Flanking Sequences in Canonical and Alternative Isoforms\n",
    "\n",
    "Compare sequence similarity between the flanking sequence in the canonical isoform to the altered flanking sequence in the alternative isoform. Data used for Figure 4E.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequenceSimilarity(can_flank, alt_flank):\n",
    "    \"\"\"\n",
    "    Given two flanking sequences, calculate the sequence similarity between them using Biopython and criteria definded by Pillman et al. BMC Bioinformatics 2011\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    can_flank: str\n",
    "        flanking sequence for PTM in canonical protein isoform\n",
    "    alt_flank: str\n",
    "        flanking sequence for PTM in alternative protein isoform\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    normalized_score: float\n",
    "        normalized score of sequence similarity between flanking sequences (calculated similarity/max possible similarity)\n",
    "    \"\"\"\n",
    "    #align canonical and alternative flanks, return only the score\n",
    "    actual_similarity = pairwise2.align.globalxs(can_flank, alt_flank, -10, -2, score_only = True)\n",
    "    #aling the canonical flank to itself, return only the score\n",
    "    control_similarity = pairwise2.align.globalxs(can_flank, can_flank, -10, -2, score_only = True)\n",
    "    #normalize score\n",
    "    normalized_score = actual_similarity/control_similarity\n",
    "    return normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option where we consider regulatory region for each flanking sequence size\n",
    "isoform_ptms = mapper.isoform_ptms.copy()\n",
    "similarity = defaultdict(list)\n",
    "flank_sizes = [3, 5, 7, 10]\n",
    "for size in flank_sizes:\n",
    "    altered_flanks = isoform_ptms[(isoform_ptms[f'Conserved Flank (Size = {size})'] == 0) & (isoform_ptms['Mapping Result'] == 'Success')].copy()\n",
    "    for i,row in altered_flanks.iterrows():\n",
    "        ptm = row['Source of PTM']\n",
    "        if ';' in ptm:\n",
    "            ptm = ptm.split(';')[0]\n",
    "        alt_flank = row['Flanking Sequence'][10-size:10+size+1]\n",
    "        can_flank = mapper.ptm_info.loc[ptm, 'Flanking Sequence'][10-size:10+size+1]\n",
    "        similarity[size].append(getSequenceSimilarity(can_flank, alt_flank))\n",
    "\n",
    "#construct dataframe from dictionary, adding column indicating window size\n",
    "similarity_data = []\n",
    "for size in [3,5,7,10]:\n",
    "    subset = pd.DataFrame(similarity[size], columns = ['Similarity'])\n",
    "    subset['Window Size'] = size\n",
    "    similarity_data.append(subset)\n",
    "similarity_data = pd.concat(similarity_data)\n",
    "\n",
    "#multiply similarity by 100 to get percentage\n",
    "similarity_data['Similarity'] = similarity_data['Similarity']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_data.to_csv(analysis_dir + '/FlankingSequences/SequenceSimilarity.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position of Altered Residues in Flanking Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAlteredPositions(seq1, seq2, desired_seq_size = 21):\n",
    "    \"\"\"\n",
    "    Given two sequences, identify the location of positions that have changed\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seq1, seq2: str\n",
    "        sequences to compare (order does not matter)\n",
    "    desired_seq_size: int\n",
    "        size of the flanking sequence to compare. IMPORTANT, this should not be larger than the available flanking sequence in the ptm_info dataframe\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    altered_positions: list\n",
    "        list of positions that have changed\n",
    "    residue_change: list\n",
    "        list of residues that have changed associated with that position\n",
    "    flank_side: str\n",
    "        indicates which side of the flanking sequence the change has occurred (N-term, C-term, or Both)\n",
    "    \"\"\"\n",
    "    altered_positions = []\n",
    "    residue_change = []\n",
    "    flank_side = []\n",
    "    seq_size = len(seq1)\n",
    "    flank_size = (seq_size -1)/2\n",
    "    if seq_size == len(seq2) and seq_size == desired_seq_size:\n",
    "        for i in range(seq_size):\n",
    "            if seq1[i] != seq2[i]:\n",
    "                altered_positions.append(i-(flank_size))\n",
    "                residue_change.append(f'{seq1[i]}->{seq2[i]}')\n",
    "        #check to see which side flanking sequence\n",
    "        altered_positions = np.array(altered_positions)\n",
    "        n_term = any(altered_positions < 0)\n",
    "        c_term = any(altered_positions > 0)\n",
    "        if n_term and c_term:\n",
    "            flank_side = 'Both'\n",
    "        elif n_term:\n",
    "            flank_side = 'N-term only'\n",
    "        elif c_term:\n",
    "            flank_side = 'C-term only'\n",
    "        else:\n",
    "            flank_side = 'Unclear'\n",
    "        return altered_positions, residue_change, flank_side\n",
    "    else:\n",
    "        return np.nan, np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "altered_flanks = mapper.isoform_ptms[(mapper.isoform_ptms['Conserved Flank (Size = 10)'] == 0) & (mapper.isoform_ptms['Mapping Result'] == 'Success')].copy()\n",
    "altered_flanks = altered_flanks.dropna(subset = 'Alternative Residue')\n",
    "\n",
    "altered_positions = []\n",
    "residue_changes = []\n",
    "flank_side = []\n",
    "for i, row in altered_flanks.iterrows():\n",
    "    alt_flank = row['Flanking Sequence']\n",
    "    ptm = row['Source of PTM']\n",
    "    if ';' in ptm:\n",
    "        ptm = ptm.split(';')[0]\n",
    "    can_flank = mapper.ptm_info.loc[ptm, 'Flanking Sequence']\n",
    "    results = findAlteredPositions(can_flank, alt_flank)\n",
    "    altered_positions.append(results[0])\n",
    "    residue_changes.append(results[1])\n",
    "    flank_side.append(results[2])\n",
    "altered_flanks['Altered_Positions'] = altered_positions\n",
    "altered_flanks['Residue Changes'] = residue_changes\n",
    "altered_flanks[\"Location of Altered Flank\"] = flank_side\n",
    "\n",
    "altered_flanks = altered_flanks[['Isoform ID', 'Source of PTM', 'Flanking Sequence', 'Altered_Positions', 'Residue Changes', 'Location of Altered Flank']]\n",
    "altered_flanks.to_csv(analysis_dir + '/FlankingSequences/PositionOfAlteredFlanks.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_positions = altered_flanks.explode('Altered_Positions')\n",
    "exploded_positions = exploded_positions.groupby('Altered_Positions').size()\n",
    "exploded_positions.name = 'Number of PTMs'\n",
    "exploded_positions.to_csv(analysis_dir + '/FlankingSequences/PositionBreakdown.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kinase Library Analysis\n",
    "\n",
    "In order to identify how changes to flanking sequences might change protein interactions, we turned to kinase-substrate interactions as our example. Using the Kinase Library tool, which returns a score indicating the likelihood that a kinase interacts with a given substrate based on that kinases motif, we can score the flanking sequences found in both the canonical and alternative isoform of our ptms of interest. This data was used for Figure 4F/G.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary for converting from kinase library kinase names to kinase names in phosphositeplus\n",
    "kinase_conversion = {'AURKA':'AURA','AURKB':'AURA','AURKC':'AURC','CHEK2':'CHK2','CHEK1':'CHK1','CSNK1A1':'CK1A','CSNK2A1':'CK2A1', 'CSNK2A2':'CK2A2', 'PRKACA':'PKACA',\n",
    "                     'PRKACB':'PKACB','PRKCA':'PKCA','PRKCB':'PKCB','PRKCE':'PKCE','PRKCI': 'PKCI','PRKG2':'PKG2', 'TRPM7':'CHAK1', 'MAPK14':'P38A',\n",
    "                     'MAPK1':'ERK2','MAPK3':'ERK1','RPS6KA1':'P90RSK','PRKCQ':'PKCT','PDPK1':'PDK1', 'PRKAA1':'AMPKA1','PRKAA2':'AMPKA2', 'EIF2AK2':'PKR'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing for Kinase Library Analysis\n",
    "\n",
    "Prior to using the kinase library tool, we needed to extract and format the flanking sequences of interest to be analyzed with kinase library. The following code was used to generate the flanking sequences that would ultimately be plugged into kinase library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editSequence(seq):\n",
    "    \"\"\"\n",
    "    Convert flanking sequence to version accepted by kinase library (modified residue denoted by asterick)\n",
    "    \"\"\"\n",
    "    seq = seq.replace('t','t*')\n",
    "    seq = seq.replace('s','s*')\n",
    "    seq = seq.replace('y','y*')\n",
    "    return seq\n",
    "\n",
    "def identify_flanks_for_KinaseLibrary(mapper):\n",
    "    \"\"\"\n",
    "    Using the mapper object data, identify PTMs with altered flanking sequences, which by default will restrict to ptms with at least one known kinase interaction and a conserved tryptic fragment (would be missed by MS)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mapper : PTMmapper.Mapper\n",
    "        Mapper object with data already processed\n",
    "    ks_dataset : pandas.DataFrame\n",
    "        Dataframe with kinase-substrate interactions, downloaded from phosphositeplus\n",
    "    \"\"\"\n",
    "    if 'Conserved Flank' not in mapper.isoform_ptms.columns:\n",
    "        mapper.isoform_ptms['Conserved Flank'] = mapper.compareAllFlankSeqs(flank_size = 5)\n",
    "    if 'Conserved Fragment' not in mapper.isoform_ptms.columns:\n",
    "        mapper.isoform_ptms['Conserved Fragment'] = mapper.compareAllTrypticFragments()\n",
    "\n",
    "    #extract ptms with altered flank sequences\n",
    "    conserved = mapper.isoform_ptms[mapper.isoform_ptms['Mapping Result'] == 'Success'].copy()\n",
    "    conserved = conserved[conserved[\"Isoform Type\"] == 'Alternative']\n",
    "\n",
    "    conserved = conserved[(conserved['Conserved Fragment'] == 1) & (conserved['Conserved Flank (Size = 5)'] == 0)]\n",
    "    #conserved = conserved[(conserved['Conserved Flank (Size = 5)'] == 0)]\n",
    "\n",
    "\n",
    "    #restrict to phosphorylation sites\n",
    "    conserved = conserved[(conserved['Modification Class'].str.contains('Phosphorylation'))]\n",
    "    conserved = conserved.drop_duplicates(subset = ['Source of PTM', 'Flanking Sequence'])\n",
    "\n",
    "    #separate ptm sources\n",
    "    conserved['Source of PTM'] = conserved['Source of PTM'].str.split(';')\n",
    "    conserved = conserved.explode('Source of PTM')\n",
    "    conserved['Source of PTM'] = conserved['Source of PTM'].apply(lambda x: x.split('-')[0]+'_'+ x.split('_')[1])\n",
    "    conserved = conserved[['Isoform ID', 'Source of PTM', 'Flanking Sequence']].drop_duplicates()\n",
    "\n",
    "\n",
    "    #if requested, restrict to known kinase-substrate interactions\n",
    "\n",
    "    #restrict to human interactions\n",
    "    #ks_dataset = ks_dataset[(ks_dataset['KIN_ORGANISM'] == 'human') & (ks_dataset['SUB_ORGANISM'] == 'human')].copy()\n",
    "    #inner merge kinase-substrate info with conserved flank info\n",
    "    #ks_dataset['Source of PTM'] = ks_dataset['SUB_ACC_ID']+'_'+ks_dataset['SUB_MOD_RSD']\n",
    "    #conserved = conserved.merge(ks_dataset, on = 'Source of PTM')\n",
    "\n",
    "    #extract only the columns with relevant info\n",
    "    conserved = conserved[['Isoform ID', 'Source of PTM', 'Flanking Sequence']].drop_duplicates()\n",
    "    conserved = conserved.rename({'Flanking Sequence':'Alternative Sequence'}, axis = 1)\n",
    "    #add canonical flanking sequence to data\n",
    "    canonical_ptms = mapper.ptm_info[mapper.ptm_info['Isoform Type'] == 'Canonical'].copy()\n",
    "    canonical_sequence = mapper.ptm_info['Flanking Sequence'].reset_index().rename({'index':'PTM', 'Flanking Sequence':'Canonical Sequence'}, axis = 1)\n",
    "    canonical_sequence['PTM'] = canonical_sequence['PTM'].apply(lambda x: x.split('-')[0]+'_'+ x.split('_')[1])\n",
    "    conserved = conserved.merge(canonical_sequence, right_on = 'PTM', left_on = 'Source of PTM', how = 'left')\n",
    "    \n",
    "    return conserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get flanking sequences to use for kinase library analysis \n",
    "flanking_sequences = identify_flanks_for_KinaseLibrary(mapper)\n",
    "\n",
    "#save data\n",
    "if not os.path.exists(analysis_dir + '/FlankingSequences/Kinase_Library'):\n",
    "    os.mkdir(analysis_dir + '/FlankingSequences/Kinase_Library')\n",
    "flanking_sequences.to_csv(analysis_dir + '/FlankingSequences/Kinase_Library/sequences_to_analyze.csv', index = False)\n",
    "\n",
    "#generate files to input into Kinase Library\n",
    "canonical_sequences = flanking_sequences[['PTM', 'Canonical Sequence']].drop_duplicates()\n",
    "canonical_sequences['Canonical Sequence'] = canonical_sequences['Canonical Sequence'].apply(editSequence)\n",
    "#write sequences to text file\n",
    "with open(analysis_dir + '/FlankingSequences/Kinase_Library/Canonical_Flanking_Sequences.txt', 'w') as f:\n",
    "    for index, row in canonical_sequences.iterrows():\n",
    "        f.write(row['Canonical Sequence']+'\\n')\n",
    "\n",
    "alternative_sequences = flanking_sequences[['Isoform ID', 'PTM', 'Alternative Sequence']].drop_duplicates()\n",
    "alternative_sequences['Alternative Sequence'] = alternative_sequences['Alternative Sequence'].apply(editSequence)\n",
    "alternative_sequences = alternative_sequences['Alternative Sequence'].drop_duplicates()\n",
    "#write sequences to text file\n",
    "with open(analysis_dir + '/FlankingSequences/Kinase_Library/Alternative_Flanking_Sequences.txt', 'w') as f:\n",
    "    for seq in alternative_sequences.values:\n",
    "        f.write(seq+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Kinase Library Results\n",
    "\n",
    "Kinase library analysis outputs a single file for each flanking sequence, containing scores for all kinases for the given flanking sequence. We processed these files in order to merge the information into a single file. \n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flanking_sequences = pd.read_csv(analysis_dir + '/FlankingSequences/Kinase_Library/sequences_to_analyze.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Isoform ID</th>\n",
       "      <th>Source of PTM</th>\n",
       "      <th>Alternative Sequence</th>\n",
       "      <th>PTM</th>\n",
       "      <th>Canonical Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q14847-3</td>\n",
       "      <td>Q14847_Y86</td>\n",
       "      <td>REEALLQRVRyKEEFEKNKGK</td>\n",
       "      <td>Q14847_Y86</td>\n",
       "      <td>QQSELQSQVRyKEEFEKNKGK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9P2N7-2</td>\n",
       "      <td>Q9P2N7_S46</td>\n",
       "      <td>MKLsLGGSEMGLSS</td>\n",
       "      <td>Q9P2N7_S46</td>\n",
       "      <td>VEEEDQHMKLsLGGSEMGLSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENS-CFLAR-2</td>\n",
       "      <td>O15519_Y171</td>\n",
       "      <td>RIDLKTKIQKyKQSGGWNGTW</td>\n",
       "      <td>O15519_Y171</td>\n",
       "      <td>RIDLKTKIQKyKQSVQGAGTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENS-POLDIP2-1</td>\n",
       "      <td>Q9Y2S7_Y103</td>\n",
       "      <td>GKYETGQARLyDRDVASAAPE</td>\n",
       "      <td>Q9Y2S7_Y103</td>\n",
       "      <td>VVLFPWQARLyDRDVASAAPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q9H6T3-2</td>\n",
       "      <td>Q9H6T3_S391</td>\n",
       "      <td>PGNKQAVTELsKIKKKPLKKV</td>\n",
       "      <td>Q9H6T3_S391</td>\n",
       "      <td>PGNKQAVTELsKIKKELIEKG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>Q13085-2</td>\n",
       "      <td>Q13085_S80</td>\n",
       "      <td>RYYMLQRSSMsGLHLVKQGRD</td>\n",
       "      <td>Q13085_S80</td>\n",
       "      <td>GLALHIRSSMsGLHLVKQGRD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>ENS-TBCE-2</td>\n",
       "      <td>Q15813_S495</td>\n",
       "      <td>PVSDLLLSYEsPKVSCPAKYK</td>\n",
       "      <td>Q15813_S495</td>\n",
       "      <td>PVSDLLLSYEsPKKPGREIEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>Q5JSZ5-5</td>\n",
       "      <td>Q5JSZ5_S1470</td>\n",
       "      <td>DTLAMDMRVRsPDEALPGGLS</td>\n",
       "      <td>Q5JSZ5_S1470</td>\n",
       "      <td>QNGTPLKVKRsPDEALPGGLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>Q5JSZ5-5</td>\n",
       "      <td>Q5JSZ5_S776</td>\n",
       "      <td>DTLAMDMRVRsPDEALPGGLS</td>\n",
       "      <td>Q5JSZ5_S776</td>\n",
       "      <td>DTLAMDMRVRsPDEALPGGLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>ENS-nan-109</td>\n",
       "      <td>Q16850_S66</td>\n",
       "      <td>LHLLNMETKKsPPYIFSPIPF</td>\n",
       "      <td>Q16850_S66</td>\n",
       "      <td>HLVQLPAGVKsPPYIFSPIPF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1906 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Isoform ID Source of PTM   Alternative Sequence           PTM  \\\n",
       "0          Q14847-3    Q14847_Y86  REEALLQRVRyKEEFEKNKGK    Q14847_Y86   \n",
       "1          Q9P2N7-2    Q9P2N7_S46         MKLsLGGSEMGLSS    Q9P2N7_S46   \n",
       "2       ENS-CFLAR-2   O15519_Y171  RIDLKTKIQKyKQSGGWNGTW   O15519_Y171   \n",
       "3     ENS-POLDIP2-1   Q9Y2S7_Y103  GKYETGQARLyDRDVASAAPE   Q9Y2S7_Y103   \n",
       "4          Q9H6T3-2   Q9H6T3_S391  PGNKQAVTELsKIKKKPLKKV   Q9H6T3_S391   \n",
       "...             ...           ...                    ...           ...   \n",
       "1901       Q13085-2    Q13085_S80  RYYMLQRSSMsGLHLVKQGRD    Q13085_S80   \n",
       "1902     ENS-TBCE-2   Q15813_S495  PVSDLLLSYEsPKVSCPAKYK   Q15813_S495   \n",
       "1903       Q5JSZ5-5  Q5JSZ5_S1470  DTLAMDMRVRsPDEALPGGLS  Q5JSZ5_S1470   \n",
       "1904       Q5JSZ5-5   Q5JSZ5_S776  DTLAMDMRVRsPDEALPGGLS   Q5JSZ5_S776   \n",
       "1905    ENS-nan-109    Q16850_S66  LHLLNMETKKsPPYIFSPIPF    Q16850_S66   \n",
       "\n",
       "         Canonical Sequence  \n",
       "0     QQSELQSQVRyKEEFEKNKGK  \n",
       "1     VEEEDQHMKLsLGGSEMGLSS  \n",
       "2     RIDLKTKIQKyKQSVQGAGTS  \n",
       "3     VVLFPWQARLyDRDVASAAPE  \n",
       "4     PGNKQAVTELsKIKKELIEKG  \n",
       "...                     ...  \n",
       "1901  GLALHIRSSMsGLHLVKQGRD  \n",
       "1902  PVSDLLLSYEsPKKPGREIEL  \n",
       "1903  QNGTPLKVKRsPDEALPGGLS  \n",
       "1904  DTLAMDMRVRsPDEALPGGLS  \n",
       "1905  HLVQLPAGVKsPPYIFSPIPF  \n",
       "\n",
       "[1906 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flanking_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sequence data\n",
    "flanking_sequences = pd.read_csv(analysis_dir + '/FlankingSequences/Kinase_Library/sequences_to_analyze.csv')\n",
    "#grab canonical sequences and match kinase library formatting\n",
    "canonical_sequences = flanking_sequences[['PTM', 'Canonical Sequence']].drop_duplicates()\n",
    "canonical_sequences['Canonical Sequence'] = canonical_sequences['Canonical Sequence'].apply(lambda x: x[10-5:10+6+1].upper().replace(' ', '_'))\n",
    "#grab alternative sequences and match kinase library formatting\n",
    "alternative_sequences = flanking_sequences[['Isoform ID', 'PTM', 'Alternative Sequence']].drop_duplicates()\n",
    "alternative_sequences['Alternative Sequence'] = alternative_sequences['Alternative Sequence'].apply(lambda x: x[10-5:10+6+1].upper().replace(' ','_'))\n",
    "alternative_sequences['Label'] = alternative_sequences['Isoform ID'] + ';' + alternative_sequences['PTM']\n",
    "alternative_sequences = alternative_sequences[['Label', 'Alternative Sequence']].drop_duplicates()\n",
    "\n",
    "\n",
    "#add kinase library scorescores to sequence info\n",
    "canonical_scores = pd.read_csv(analysis_dir + '/FlankingSequences/Kinase_Library/Results/canonical_sequence_scores.tsv', sep = '\\t')\n",
    "canonical_sequences = canonical_sequences.merge(canonical_scores, left_on = 'Canonical Sequence', right_on = 'sequence', how = 'left')\n",
    "\n",
    "alternative_scores = pd.read_csv(analysis_dir + '/FlankingSequences/Kinase_Library/Results/alternative_sequence_scores.tsv', sep = '\\t')\n",
    "alternative_sequences = alternative_sequences.merge(alternative_scores, left_on = 'Alternative Sequence', right_on = 'sequence', how = 'left')\n",
    "\n",
    "\n",
    "#pivot and extract scores\n",
    "canonical_sequences_y = canonical_sequences[canonical_sequences['PTM'].str.contains('_Y')]\n",
    "canonical_percentiles_y = canonical_sequences_y.pivot_table(index = 'PTM', columns = 'kinase', values = 'site_percentile')\n",
    "canonical_sequences_st = canonical_sequences[(canonical_sequences['PTM'].str.contains('_S')) | (canonical_sequences['PTM'].str.contains('_T'))]\n",
    "canonical_percentiles_st = canonical_sequences_st.pivot_table(index = 'PTM', columns = 'kinase', values = 'site_percentile')\n",
    "\n",
    "alternative_sequences_y = alternative_sequences[alternative_sequences['Label'].str.contains('_Y')]\n",
    "alternative_percentiles_y = alternative_sequences_y.pivot_table(index = 'Label', columns = 'kinase', values = 'site_percentile')\n",
    "alternative_sequences_st = alternative_sequences[(alternative_sequences['Label'].str.contains('_S')) | (alternative_sequences['Label'].str.contains('_T'))]\n",
    "alternative_percentiles_st = alternative_sequences_st.pivot_table(index = 'Label', columns = 'kinase', values = 'site_percentile')\n",
    "\n",
    "#calculate the difference in percentiles\n",
    "\n",
    "percentiles_diff_y = alternative_percentiles_y.copy()\n",
    "percentiles_diff_y = percentiles_diff_y[canonical_percentiles_y.columns]\n",
    "for i, row in percentiles_diff_y.iterrows():\n",
    "    percentiles_diff_y.loc[i] = row - canonical_percentiles_y.loc[i.split(';')[1]]\n",
    "\n",
    "percentiles_diff_st = alternative_percentiles_st.copy()\n",
    "percentiles_diff_st = percentiles_diff_st[canonical_percentiles_st.columns]\n",
    "for i, row in percentiles_diff_st.iterrows():\n",
    "    percentiles_diff_st.loc[i] = row - canonical_percentiles_st.loc[i.split(';')[1]]\n",
    "\n",
    "#save results\n",
    "percentiles_diff_y.to_csv(analysis_dir + '/FlankingSequences/Kinase_Library/Results/Percentile_Differences_Y.csv')\n",
    "percentiles_diff_st.to_csv(analysis_dir + '/FlankingSequences/Kinase_Library/Results/Percentile_Differences_ST.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESRP1-mediated Splicing in Prostate Cancer\n",
    "\n",
    "The following code was used in the analysis of how ESRP1-mediated splicing is altered in prostate cancer and leads to changes the presence/absence of different PTMs. This analysis was used to generate Figure 4.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecting PTMs onto SpliceSeq Exons\n",
    "\n",
    "Here, we used data from the genomic coordinates of different ptms obtained from the projection pipeline to determine which PTMs are present in SpliceSeq splicegraph exons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load splicegraph from SpliceSeq\n",
    "splicegraph = pd.read_csv(database_dir + '/TCGA/TCGASpliceSeq_splicegraph.txt', delim_whitespace=True)\n",
    "\n",
    "\n",
    "splicegraph_ptms = None\n",
    "#iterate through all ptms and project them onto the splicegraph (breaking up the data by chromosome and strand)\n",
    "for chromosome in mapper.ptm_coordinates['Chromosome/scaffold name'].unique():\n",
    "    for strand in mapper.ptm_coordinates['Strand'].unique():\n",
    "        if strand == -1:\n",
    "            sg_strand = '-'\n",
    "        else:\n",
    "            sg_strand = '+'\n",
    "        #grab splicegraph exons and ptms associated with the same chromosome/strand as the ptm\n",
    "        trim_sg = splicegraph[(splicegraph['Chromosome'] == chromosome) & (splicegraph['Strand'] == sg_strand)]\n",
    "        trim_ptms = mapper.ptm_coordinates[(mapper.ptm_coordinates['Chromosome/scaffold name'] == chromosome) & (mapper.ptm_coordinates['Strand'] == strand)]\n",
    "        #iterate through all ptms on the chromosome/strand and project the ptms onto the splicegraph exons\n",
    "        for i,row in trim_ptms.iterrows():\n",
    "            sg_exons = trim_sg[(trim_sg['Chr_Start'] <= row['HG19 Location']) & (trim_sg['Chr_Stop'] >= row['HG19 Location'])].copy()\n",
    "            sg_exons['PTM'] = row['Source of PTM']\n",
    "            if splicegraph_ptms is None:\n",
    "                splicegraph_ptms = sg_exons.copy()\n",
    "            else:\n",
    "                splicegraph_ptms = pd.concat([splicegraph_ptms, sg_exons])\n",
    "\n",
    "\n",
    "#save data\n",
    "splicegraph_ptms.to_csv(analysis_dir + '/TCGA/splicegraph_PTMs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify differentially included PTM-containing exons\n",
    "\n",
    "Using percent spliced in (PSI) data downloaded from TCGASpliceSeq, we identified exons that are differentially included in ESRP1-high or ESRP1-low prostate cancer samples. We then determined which of these exons contain PTMs.  \n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_58072\\1945944182.py:21: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mapped_ptms = pd.read_csv(analysis_dir + '/TCGA/splicegraph_PTMs.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ESRP1 low patients:  61\n",
      "Number of ESRP1 high patients:  69\n"
     ]
    }
   ],
   "source": [
    "tissue = 'PRAD'\n",
    "#load ESRP1 expression data\n",
    "ESRP1 = pd.read_csv(database_dir + f\"/TCGA/{tissue}/{tissue}_ESRP1_expression.txt\", sep = '\\t') # Z-score of ESPR1 \n",
    "ESRP1 = ESRP1.dropna(subset = 'ESRP1')\n",
    "\n",
    "#load percent spliced in data from TCGA SpliceSeq, restrict to exon skipping and alternative splice site events with PSI variation of at least 0.25 across all patients\n",
    "PRAD = pd.read_csv(database_dir + f\"/TCGA/{tissue}/PSI_download_{tissue}.txt\", sep = '\\t') # PSI data\n",
    "PRAD = PRAD[PRAD['splice_type'].isin(['ES','RI','AD','AA'])].copy()\n",
    "PRAD = PRAD[PRAD['psi_range'] > 0.25].copy()\n",
    "\n",
    "#remove patients with no measured ESRP1 mRNA from splice data, or vice versa\n",
    "ESRP1['Edited Patient ID'] = ESRP1['SAMPLE_ID'].apply(lambda x: '_'.join(x.split('-')[0:3])).to_list()\n",
    "patients_to_drop = [col for col in PRAD.columns if col not in ESRP1['Edited Patient ID'].values and 'TCGA' in col]\n",
    "PRAD = PRAD.drop(patients_to_drop, axis = 1)\n",
    "\n",
    "#remove patients with no measured splice data from ESRP1 data\n",
    "patients_to_drop = [col for col in ESRP1['Edited Patient ID'] if col not in PRAD.columns]\n",
    "ESRP1 = ESRP1[~ESRP1['Edited Patient ID'].isin(patients_to_drop)].copy()\n",
    "\n",
    "#grab PTMs mapped onto SpliceSeq splicegraph\n",
    "mapped_ptms = pd.read_csv(analysis_dir + '/TCGA/splicegraph_PTMs.csv')\n",
    "#Percent Spliced In data\n",
    "spliceseq = pd.read_csv(database_dir + \"/TCGA/TCGASpliceSeq_splicegraph.txt\", delim_whitespace=True) \n",
    "\n",
    "\n",
    "## Identify patients with high or low ESRP1 expression\n",
    "ESPR_low = ESRP1[ESRP1[\"ESRP1\"] < -1]\n",
    "ESPR_low_id = ESPR_low[\"SAMPLE_ID\"].str.split(\"-\").apply(lambda x: x[0:3]).apply(lambda x: '_'.join(x)).to_list()\n",
    "ESPR_high = ESRP1[ESRP1[\"ESRP1\"] > 1]\n",
    "ESPR_high_id = ESPR_high[\"SAMPLE_ID\"].str.split(\"-\").apply(lambda x: x[0:3]).apply(lambda x: '_'.join(x)).to_list()\n",
    "print('Number of ESRP1 low patients: ', len(ESPR_low_id))\n",
    "print('Number of ESRP1 high patients: ', len(ESPR_high_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold indexes of PSI data where values are statistically significant + if mean is higher than other group place it in that group. \n",
    "direction = [] \n",
    "p_list = []\n",
    "effect_list =[]\n",
    "for index, row in PRAD.iterrows():\n",
    "    #get list of ESRP1-high and ESRP1-low samples\n",
    "    high_sample = PRAD.loc[index, ESPR_high_id].values\n",
    "    high_sample = list(high_sample[~pd.isnull(high_sample)])\n",
    "    low_sample = PRAD.loc[index, ESPR_low_id].values\n",
    "    low_sample = list(low_sample[~pd.isnull(low_sample)])\n",
    "    \n",
    "    #calculate Mann Whitney p-value and effect size comparing ESRP1-high and low PSI values\n",
    "    if len(low_sample) > 1 and len(high_sample) > 1:\n",
    "        p_value, effect_size = stat_utils.calculateMW_EffectSize(high_sample, low_sample)\n",
    "    else:\n",
    "        p_value = np.nan\n",
    "    p_list.append(p_value)\n",
    "    effect_list.append(effect_size)\n",
    "    \n",
    "    #Determine whether ESRP1-high or low samples have higher PSI values (based on mean)\n",
    "    if p_value != p_value:\n",
    "        direction.append(np.nan)\n",
    "    elif np.mean(high_sample) > np.mean(low_sample):\n",
    "        direction.append('High')\n",
    "    else: \n",
    "        direction.append('Low')\n",
    "        \n",
    "#save results to dataframe\n",
    "PRAD['ESRP1'] = direction\n",
    "PRAD['p'] = p_list\n",
    "PRAD['Effect Size'] = effect_list\n",
    "PRAD = PRAD.dropna(subset = 'p')\n",
    "\n",
    "#adjust p-values using Benjamini-Hochberg method\n",
    "PRAD = PRAD.sort_values(by = 'p', ascending = True)\n",
    "PRAD['Adj p'] = stat_utils.adjustP(PRAD['p'].values)\n",
    "\n",
    "#add PTMs to differentially included exons\n",
    "PRAD_ptms = PRAD.copy()\n",
    "#remove mutually exclusive exon events from analysis\n",
    "PRAD_ptms = PRAD_ptms[~PRAD_ptms['exons'].apply(lambda x: '|' in x)]\n",
    "#separate exons in events with multiple exons\n",
    "PRAD_ptms['exons'] = PRAD_ptms[\"exons\"].apply(lambda x: x.split(':'))\n",
    "PRAD_ptms = PRAD_ptms.explode('exons').drop_duplicates(subset = ['symbol','exons','ESRP1','p'])\n",
    "PRAD_ptms['exons'] = PRAD_ptms['exons'].astype(float)\n",
    "#merge with mapped PTMs\n",
    "PRAD_ptms = PRAD_ptms.merge(mapped_ptms, left_on = ['symbol','exons'], right_on = ['Symbol', 'Exon'])\n",
    "PRAD_ptms = PRAD_ptms.sort_values(by = 'Adj p')\n",
    "PRAD_ptms = PRAD_ptms.drop_duplicates(subset = ['PTM', 'ESRP1'])\n",
    "\n",
    "#save data\n",
    "PRAD_ptms.to_csv(analysis_dir + f'/TCGA/{tissue}_ESRP1_PTMs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene set enrichment of ESRP1-correlated genes\n",
    "\n",
    "To assess the general impact of ESRP1 on gene splicing/biological pathways, we used the gseapy package and the enrichr api to perform gene set enrichment analysis (esrp1-related genes vs. all genes in the prostate dataset). This data was used for Supplementary Figure 12.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gseapy import enrichr\n",
    "\n",
    "#load prostate data\n",
    "PRAD_ptms = pd.read_csv(analysis_dir + f'/TCGA/PRAD_ESRP1_PTMs.csv')\n",
    "sig_ptms = PRAD_ptms[(PRAD_ptms['Adj p'] <= 0.05) & (PRAD_ptms['Effect Size'] >= 0.25)].copy()\n",
    "sig_ptms = sig_ptms.drop_duplicates(subset = ['PTM', 'ESRP1'])\n",
    "sig_ptms = sig_ptms.drop_duplicates(subset = 'PTM', keep = False) #remove PTMs that are significant in both directions\n",
    "\n",
    "#run enrichr analysis\n",
    "gene_set_names = {'GO_Cellular_Component_2023':'GO Cellular Component', 'GO_Molecular_Function_2023':'GO Molecular Function', 'GO_Biological_Process_2023':'GO Biological Process', 'KEGG_2021_Human':'KEGG Pathways'}\n",
    "enrichr_results = enrichr(list(sig_ptms['symbol'].unique()), background = list(PRAD_ptms['symbol'].unique()), gene_sets = list(gene_set_names.keys()), organism='human').results\n",
    "enrichr_results['Gene Set Title'] = enrichr_results['Gene_set'].apply(lambda x: gene_set_names[x])\n",
    "\n",
    "#save data\n",
    "if not os.path.exists(analysis_dir + '/TCGA/Enrichment'):\n",
    "    os.mkdir(analysis_dir + '/TCGA/Enrichment')\n",
    "enrichr_results.to_csv(analysis_dir + '/TCGA/Enrichment/Gene_Set_Enrichr.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site enrichment of ESRP1-correlated PTMs\n",
    "\n",
    "To determine whether ESRP1-correlated PTMs are enriched in PTM sites with specific functions or are involved in specific processes, we obtained PhosphoSitePlus annotations of PTM function and performed enrichment analysis using a Fishers Exact test (esrp1-related PTMs vs. all PTMs in the prostate dataset). This data was used for Supplementary Figure 13.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load annotation data\n",
    "annotations = pd.read_csv(database_dir + '/PhosphoSitePlus/Regulatory_sites.gz', sep = '\\t',compression = 'gzip', on_bad_lines='skip', header = 2)\n",
    "annotations['Substrate'] = annotations['ACC_ID'] + '_' + annotations['MOD_RSD'].apply(lambda x: x.split('-')[0])\n",
    "\n",
    "\n",
    "#load prostate data\n",
    "PRAD_ptms = pd.read_csv(analysis_dir + f'/TCGA/PRAD_ESRP1_PTMs.csv')\n",
    "sig_ptms = PRAD_ptms[(PRAD_ptms['Adj p'] <= 0.05) & (PRAD_ptms['Effect Size'] >= 0.25)].copy()\n",
    "sig_ptms = sig_ptms.drop_duplicates(subset = ['PTM', 'ESRP1'])\n",
    "sig_ptms = sig_ptms.drop_duplicates(subset = 'PTM', keep = False) #remove PTMs that are significant in both directions\n",
    "\n",
    "#get function enrichment\n",
    "functions = stat_utils.constructPivotTable(PRAD_ptms, annotations, reference_col = 'ON_FUNCTION', collapse_on_similar=True)\n",
    "function_enrichment = stat_utils.generate_site_enrichment(sig_ptms['PTM'].unique(), functions, subset_name = 'ESRP1-Regulated', type = 'Function')\n",
    "processes = stat_utils.constructPivotTable(PRAD_ptms, annotations, reference_col = 'ON_PROCESS', collapse_on_similar=True)\n",
    "process_enrichment = stat_utils.generate_site_enrichment(sig_ptms['PTM'].unique(), processes, subset_name = 'ESRP1-Regulated', type = 'Process')\n",
    "\n",
    "\n",
    "#save data\n",
    "if not os.path.exists(analysis_dir + '/TCGA/Enrichment'):\n",
    "    os.mkdir(analysis_dir + '/TCGA/Enrichment')\n",
    "\n",
    "function_enrichment.to_csv(analysis_dir + '/TCGA/Enrichment/Site_Function_Enrichment.csv')\n",
    "process_enrichment.to_csv(analysis_dir + '/TCGA/Enrichment/Site_Process_Enrichment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kinase Enrichment of ESRP1-correlated Substrates\n",
    "\n",
    "To determine if cell signaling might be altered by splicing-controlled phosphorylation sites in ESRP1-high prostate cancer, we tested for enrichment of different kinase's substrates, based on either known substrates annotated in PhosphoSitePlus or predicted substrates from the ensemble of kinase-substrates in KSTAR, a kinase activity inference tool. This data was used for Supplementary Figure 16.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run hypergeometric test\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "#load splice seq data\n",
    "prostate = pd.read_csv(analysis_dir + '/TCGA/Prad_ESRP1_PTMs.csv')\n",
    "\n",
    "#add modification information\n",
    "prostate = prostate.merge(mapper.ptm_info['Modification'].reset_index(), on='PTM')\n",
    "\n",
    "#get significant prostate\n",
    "sig_prostate = prostate[(prostate['Adj p'] < 0.05) & (prostate['Effect Size'] >= 0.25)]\n",
    "\n",
    "#separate unique modifications into unique rows so that data can be restricted to phosphotyrosine or phosphoserine/threonine\n",
    "exploded_prostate = prostate.copy()\n",
    "exploded_prostate['Modification'] = exploded_prostate['Modification'].str.split(';')\n",
    "exploded_prostate = exploded_prostate.explode('Modification')\n",
    "\n",
    "#get sig\n",
    "exploded_sig_prostate = exploded_prostate[(exploded_prostate['Adj p'] < 0.05) & (exploded_prostate['Effect Size'] >= 0.25)]\n",
    "\n",
    "#restrict to phosphotyrosine data\n",
    "sig_prostate_y = exploded_sig_prostate[exploded_sig_prostate['Modification'] == 'Phosphotyrosine']\n",
    "prostate_y = exploded_prostate[exploded_prostate['Modification'] == 'Phosphotyrosine']\n",
    "\n",
    "#restrict to phosphoserine/threonine data\n",
    "sig_prostate_st = exploded_sig_prostate[exploded_sig_prostate['Modification'].isin(['Phosphoserine', 'Phosphothreonine'])]\n",
    "prostate_st = exploded_prostate[exploded_prostate['Modification'].isin(['Phosphoserine', 'Phosphothreonine'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Known Substrates from PhosphoSitePlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load known kinases from PhosphoSitePlus\n",
    "ks_dataset = pd.read_csv(database_dir + '/PhosphoSitePlus/Kinase_Substrate_Dataset.tsv', sep ='\\t')\n",
    "ks_dataset = ks_dataset[(ks_dataset['KIN_ORGANISM'] == 'human') & (ks_dataset['KIN_ORGANISM'] == 'human')]\n",
    "ks_dataset['PTM'] = ks_dataset['SUB_ACC_ID']+'_'+ks_dataset['SUB_MOD_RSD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phosphotyrosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add annotations info to esrp1-regulated phosphotyrosines\n",
    "prostate_known = prostate_y.merge(ks_dataset[['GENE','PTM']], on = 'PTM')\n",
    "sig_prostate_known = sig_prostate_y.merge(ks_dataset[['GENE','PTM']], on = 'PTM')\n",
    "\n",
    "#iterate through each kinase and perform enrichment for substrates using hypergeometric test\n",
    "results = pd.DataFrame(np.nan, index = sig_prostate_known['GENE'].unique(), columns = ['k','n','M','N','p'])\n",
    "for kinase in sig_prostate_known['GENE'].unique():\n",
    "    #get numbers for a hypergeometric test to look for enrichment of kinase substrates\n",
    "    k = sig_prostate_known[sig_prostate_known['GENE'] == kinase].shape[0]\n",
    "    n = prostate_known[prostate_known['GENE'] == kinase].shape[0]\n",
    "    M = prostate_y.shape[0]\n",
    "    N = sig_prostate_y.shape[0]\n",
    "\n",
    "\n",
    "    results.loc[kinase,'p'] = hypergeom.sf(k-1, M, n, N)\n",
    "    results.loc[kinase, 'M'] = M\n",
    "    results.loc[kinase, 'N'] = N\n",
    "    results.loc[kinase, 'k'] = k\n",
    "    results.loc[kinase, 'n'] = n\n",
    "\n",
    "results.to_csv(analysis_dir + '/TCGA/Enrichment/tyrosine_kinase_enrichment_known.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phosphoserines/threonines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restrict to phosphotyrosine data\n",
    "prostate_known = prostate_st.merge(ks_dataset[['GENE','PTM']], on = 'PTM')\n",
    "sig_prostate_known = sig_prostate_st.merge(ks_dataset[['GENE','PTM']], on = 'PTM')\n",
    "\n",
    "results = pd.DataFrame(np.nan, index = sig_prostate_known['GENE'].unique(), columns = ['k','n','M','N','p'])\n",
    "for kinase in sig_prostate_known['GENE'].unique():\n",
    "    #get numbers for a hypergeometric test to look for enrichment of kinase substrates\n",
    "    k = sig_prostate_known[sig_prostate_known['GENE'] == kinase].shape[0]\n",
    "    n = prostate_known[prostate_known['GENE'] == kinase].shape[0]\n",
    "    M = prostate_st.shape[0]\n",
    "    N = sig_prostate_st.shape[0]\n",
    "\n",
    "\n",
    "    results.loc[kinase,'p'] = hypergeom.sf(k-1, M, n, N)\n",
    "    results.loc[kinase, 'M'] = M\n",
    "    results.loc[kinase, 'N'] = N\n",
    "    results.loc[kinase, 'k'] = k\n",
    "    results.loc[kinase, 'n'] = n\n",
    "\n",
    "results = results.sort_values(by = 'p', ascending = False)\n",
    "results.to_csv(analysis_dir + '/TCGA/Enrichment/st_kinase_enrichment_known.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KSTAR Predicted Kinase Substrate Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "from kstar import config\n",
    "\n",
    "#location of figshare data\n",
    "figshare_dir = 'C:/Users/Sam/OneDrive/Documents/GradSchool/Research/Splicing/Paper_Prep/PTM_Splicing_FigShare/'\n",
    "#where to find projected PTMs\n",
    "ptm_data_dir = figshare_dir + 'PTM_Projection_Data/'\n",
    "#where to find information from different databases\n",
    "database_dir = figshare_dir + 'External_Data/'\n",
    "#where analysis data will be saved\n",
    "analysis_dir = figshare_dir + 'Analysis_For_Paper/'\n",
    "\n",
    "#load ptm info\n",
    "ptm_info = pd.read_csv(ptm_data_dir + '/processed_data_dir/ptm_info.csv', index_col = 0)\n",
    "\n",
    "#load splice seq data\n",
    "prostate = pd.read_csv(analysis_dir + '/TCGA/Prad_ESRP1_PTMs.csv')\n",
    "\n",
    "#add modification information\n",
    "prostate = prostate.merge(ptm_info['Modification'].reset_index(), on='PTM')\n",
    "\n",
    "#get significant prostate\n",
    "sig_prostate = prostate[(prostate['Adj p'] < 0.05) & (prostate['Effect Size'] >= 0.25)]\n",
    "\n",
    "#separate unique modifications into unique rows so that data can be restricted to phosphotyrosine or phosphoserine/threonine\n",
    "exploded_prostate = prostate.copy()\n",
    "exploded_prostate['Modification'] = exploded_prostate['Modification'].str.split(';')\n",
    "exploded_prostate = exploded_prostate.explode('Modification')\n",
    "\n",
    "#get sig\n",
    "exploded_sig_prostate = exploded_prostate[(exploded_prostate['Adj p'] < 0.05) & (exploded_prostate['Effect Size'] >= 0.25)]\n",
    "\n",
    "#restrict to phosphotyrosine data\n",
    "sig_prostate_y = exploded_sig_prostate[exploded_sig_prostate['Modification'] == 'Phosphotyrosine']\n",
    "prostate_y = exploded_prostate[exploded_prostate['Modification'] == 'Phosphotyrosine']\n",
    "\n",
    "#restrict to phosphoserine/threonine data\n",
    "sig_prostate_st = exploded_sig_prostate[exploded_sig_prostate['Modification'].isin(['Phosphoserine', 'Phosphothreonine'])]\n",
    "prostate_st = exploded_prostate[exploded_prostate['Modification'].isin(['Phosphoserine', 'Phosphothreonine'])]\n",
    "\n",
    "#grab networks \n",
    "networks = {}\n",
    "networks['Y'] =pickle.load(open(config.NETWORK_Y_PICKLE, \"rb\" ) )\n",
    "networks['ST'] = pickle.load(open(config.NETWORK_ST_PICKLE, \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions for calculating enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enrichment_single_network(network, prostate, sig_prostate, type = 'All'):\n",
    "    \"\"\"\n",
    "    Given prostate data and a single kstar network, get enrichment for each kinase in the network in the prostate data. Assumes the prostate data has already been reduced to the modification of interest (phosphotyrosine or phoshoserine/threonine)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network : pandas dataframe\n",
    "        kstar network\n",
    "    prostate : pandas dataframe\n",
    "        all PTMs identified in tCGA prostate data, regardless of significance (reduced to only include mods of interest)\n",
    "    sig_prostate : pandas dataframe\n",
    "        significant PTMs identified in tCGA prostate data, p < 0.05 and effect size > 0.25 (reduced to only include mods of interest)\n",
    "    \"\"\"\n",
    "    network['PTM'] = network['KSTAR_ACCESSION'] + '_' + network['KSTAR_SITE']\n",
    "    #if focusing high or low groups restrict to those, otherwise add network informatin to sig prostate without changing\n",
    "    if type == 'All':\n",
    "        sig_prostate_kstar = sig_prostate.merge(network[['KSTAR_KINASE','PTM']], on = 'PTM')\n",
    "    elif type == 'High':\n",
    "        sig_prostate = sig_prostate[sig_prostate['ESRP1'] == 'High']\n",
    "        sig_prostate_kstar = sig_prostate.merge(network[['KSTAR_KINASE','PTM']], on = 'PTM')\n",
    "    elif type == 'Low':\n",
    "        sig_prostate = sig_prostate[sig_prostate['ESRP1'] == 'Low']\n",
    "        sig_prostate_kstar = sig_prostate.merge(network[['KSTAR_KINASE','PTM']], on = 'PTM')\n",
    "\n",
    "    #add network information to all prostate data\n",
    "    prostate_kstar = prostate.merge(network[['KSTAR_KINASE','PTM']], on = 'PTM')\n",
    "\n",
    "    results = pd.DataFrame(np.nan, index = sig_prostate_kstar['KSTAR_KINASE'].unique(), columns = ['k','n','M','N','p'])\n",
    "    for kinase in sig_prostate_kstar['KSTAR_KINASE'].unique():\n",
    "        #get numbers for a hypergeometric test to look for enrichment of kinase substrates\n",
    "        k = sig_prostate_kstar[sig_prostate_kstar['KSTAR_KINASE'] == kinase].shape[0]\n",
    "        n = prostate_kstar[prostate_kstar['KSTAR_KINASE'] == kinase].shape[0]\n",
    "        M = prostate.shape[0]\n",
    "        N = sig_prostate.shape[0]\n",
    "\n",
    "        #run hypergeometric test\n",
    "        results.loc[kinase,'p'] = hypergeom.sf(k-1, M, n, N)\n",
    "        results.loc[kinase, 'M'] = M\n",
    "        results.loc[kinase, 'N'] = N\n",
    "        results.loc[kinase, 'k'] = k\n",
    "        results.loc[kinase, 'n'] = n\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_enrichment_all_networks(networks, prostate, sig_prostate, type = 'All'):\n",
    "    \"\"\"\n",
    "    Given prostate data and a dictionary of kstar networks, get enrichment for each kinase in each network in the prostate data. Assumes the prostate data has already been reduced to the modification of interest (phosphotyrosine or phoshoserine/threonine)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    networks : dict\n",
    "        dictionary of kstar networks\n",
    "    prostate : pandas dataframe\n",
    "        all PTMs identified in tCGA prostate data, regardless of significance (reduced to only include mods of interest)\n",
    "    sig_prostate : pandas dataframe\n",
    "        significant PTMs identified in tCGA prostate data, p < 0.05 and effect size > 0.25 (reduced to only include mods of interest)\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for network in networks:\n",
    "        results[network] = get_enrichment_single_network(networks[network], prostate, sig_prostate, type = type)\n",
    "    return results\n",
    "\n",
    "def extract_enrichment(results):\n",
    "    \"\"\"\n",
    "    Given a dictionary of results from get_enrichment_all_networks, extract the p-values for each network and kinase, and then calculate the median p-value across all networks for each kinase\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : dict\n",
    "        dictionary of results from get_enrichment_all_networks\n",
    "    \"\"\"\n",
    "    enrichment = pd.DataFrame(index = results['nkin0'].index, columns = results.keys())\n",
    "    for network in results:\n",
    "        enrichment[network] = results[network]['p']\n",
    "    enrichment['median'] = enrichment.median(axis = 1)\n",
    "    return enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phosphotyrosines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restrict to phosphotyrosine data\n",
    "sig_prostate_y = exploded_sig_prostate[exploded_sig_prostate['Modification'] == 'Phosphotyrosine']\n",
    "prostate_y = exploded_prostate[exploded_prostate['Modification'] == 'Phosphotyrosine']\n",
    "\n",
    "\n",
    "#combined median values for each group\n",
    "median_y = pd.DataFrame(index = networks['Y']['nkin0'][\"KSTAR_KINASE\"].unique(), columns = ['All','High','Low'])\n",
    "\n",
    "#run enrichment on all networks\n",
    "for type in ['All', 'High', 'Low']:\n",
    "    results_y = get_enrichment_all_networks(networks['Y'], prostate_y, sig_prostate_y, type = type)\n",
    "\n",
    "    #extract enrichment\n",
    "    enrichment_y = extract_enrichment(results_y)\n",
    "    median_y[type] = enrichment_y['median']\n",
    "\n",
    "median_y.to_csv(analysis_dir + '/TCGA/Enrichment/tyrosine_kinase_enrichment_predicted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serine/threonines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_prostate_st = exploded_sig_prostate[exploded_sig_prostate['Modification'].isin(['Phosphoserine', 'Phosphothreonine'])]\n",
    "prostate_st = exploded_prostate[exploded_prostate['Modification'].isin(['Phosphoserine', 'Phosphothreonine'])]\n",
    "\n",
    "#combined median values for each group\n",
    "median_st = pd.DataFrame(index = networks['ST']['nkin0'][\"KSTAR_KINASE\"].unique(), columns = ['All','High','Low'])\n",
    "\n",
    "#run enrichment on all networks\n",
    "for type in ['All', 'High', 'Low']:\n",
    "    results_st = get_enrichment_all_networks(networks['ST'], prostate_st, sig_prostate_st, type = type)\n",
    "\n",
    "    #extract enrichment\n",
    "    enrichment_st = extract_enrichment(results_st)\n",
    "    median_st[type] = enrichment_st['median']\n",
    "\n",
    "median_st.to_csv(analysis_dir + '/TCGA/Enrichment/st_kinase_enrichment_predicted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate ESRP1-Regulated SGK substrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kstar.analysis import interactions\n",
    "\n",
    "# load known kinases from PhosphoSitePlus\n",
    "ks_dataset = pd.read_csv(database_dir + '/PhosphoSitePlus/Kinase_Substrate_Dataset.tsv', sep ='\\t')\n",
    "ks_dataset = ks_dataset[(ks_dataset['KIN_ORGANISM'] == 'human') & (ks_dataset['KIN_ORGANISM'] == 'human')]\n",
    "ks_dataset['PTM'] = ks_dataset['SUB_ACC_ID']+'_'+ks_dataset['SUB_MOD_RSD']\n",
    "\n",
    "#extract phosphoserines with higher inclusion in ESRP1-high patients\n",
    "high_sig = sig_prostate_st[sig_prostate_st['ESRP1'] == 'High'].copy()\n",
    "high_sig['data:sig_ptms'] = 1\n",
    "high_sig.rename({'PTM':'KSTAR_SUBSTRATE'},  axis = 1, inplace = True)\n",
    "high_sig['KSTAR_SITE'] = high_sig['KSTAR_SUBSTRATE'].apply(lambda x: x.split('_')[1])\n",
    "high_sig['KSTAR_ACCESSION'] = high_sig['KSTAR_SUBSTRATE'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "#get substrate influence on prediction\n",
    "kinase = 'SGK1'\n",
    "experiment_influence = interactions.getSubstrateInfluence_inExperiment(networks['ST'], high_sig, kinase)\n",
    "\n",
    "#process and annotate known substrates\n",
    "known_kin = ks_dataset[ks_dataset['GENE'] == kinase]\n",
    "sub_data = experiment_influence['data:sig_ptms'].reset_index()\n",
    "sub_data['UniProt_ID'] = sub_data['index'].apply(lambda x: x.split('_')[0])\n",
    "sub_data['Site'] = sub_data['index'].apply(lambda x: x.split('_')[1])\n",
    "sub_data = sub_data.merge(known_kin['PTM'], left_on = ['index'], right_on = ['PTM'], how = 'left')\n",
    "sub_data[\"Known\"] = sub_data[\"PTM\"].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "sub_data = sub_data.drop('PTM', axis = 1)\n",
    "\n",
    "#save data\n",
    "sub_data.to_csv(analysis_dir + f'/TCGA/Enrichment/ESRP1_Regulated_SGK1_Substrates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of PTMs in Canonical and Alternative UniProt Isoforms\n",
    "\n",
    "Using data from ProteomeScout, assessed how many PTMs are annotated in the canonical and alternative UniProtKB isoform. This data was used in Supplementary Figure 2.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ptms(isoform_id, transcript_id):\n",
    "        \"\"\"\n",
    "        Given a transcript id, find all PTMs present in the protein\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        transcript_id: strings\n",
    "            Ensemble transcript for the protein of interest\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        ptm_df: pandas dataframe\n",
    "            Dataframe containing gene id, transcript id, protein id, residue modified, location of residue and modification type. Each row\n",
    "                corresponds to a unique ptm\n",
    "        \"\"\"\n",
    "        ptms = config.ps_api.get_PTMs(isoform_id)\n",
    "        \n",
    "        #extract ptm position\n",
    "        if isinstance(ptms, int) or ptms == '-1':\n",
    "            ptm_df = None\n",
    "        else: \n",
    "            ptm_df = pd.DataFrame(ptms)\n",
    "            ptm_df.columns = ['PTM Location (AA)', 'Residue', 'Modification']\n",
    "            ptm_df.insert(0, 'Isoform', isoform_id)\n",
    "            ptm_df.insert(0, 'Transcript', transcript_id)\n",
    "            \n",
    "        return ptm_df\n",
    "    \n",
    "def findIsoformInfo(ptm_df, isoform_id, transcript_id):\n",
    "    \"\"\"\n",
    "    Given a dataframe of ptm information associated with a specific isoform and transcript (such as one obtained from findPTMs()), find information regarding that isoform, including number of ptms, length, etc.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ptm_df: pandas dataframe\n",
    "        Dataframe containing gene id, transcript id, protein id, residue modified, location of residue and modification type. Each row\n",
    "    isoform_id: string\n",
    "        Uniprot Isoform ID\n",
    "    transcript_id: string\n",
    "        Ensemble transcript for the isoform of interest\n",
    "    \"\"\"\n",
    "    #get sequence length and number of ptms\n",
    "    if ptm_df is None:\n",
    "        num_ptms = 0\n",
    "    else:\n",
    "        num_ptms = ptm_df.shape[0]\n",
    "\n",
    "\n",
    "    prot_length = config.ps_api.get_sequence(isoform_id)\n",
    "    if isinstance(prot_length, int) or prot_length == '-1':\n",
    "        prot_length = None\n",
    "    else:\n",
    "        prot_length = len(prot_length)\n",
    "\n",
    "    isoform_info = pd.DataFrame({'Transcript':transcript_id,'Isoform': isoform_id, \n",
    "                                 'Protein Length': prot_length, 'Number of PTMs': num_ptms}, index = [isoform_id])\n",
    "    return isoform_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "isoform_info_dict = {}\n",
    "isoform_ptm_dict = {}\n",
    "\n",
    "for type in ['Canonical', 'Alternative']:\n",
    "    isoforms = config.translator[config.translator['Uniprot Canonical'] == type]\n",
    "    info_list = []\n",
    "    df_list = []\n",
    "    for i, row in isoforms.iterrows():\n",
    "        #if canonical, use normal uniprot id (i.e no '-1' at end)\n",
    "        if type == 'Canonical':\n",
    "            isoform_id = row['UniProtKB/Swiss-Prot ID']\n",
    "        else:\n",
    "            isoform_id = row['UniProtKB isoform ID']\n",
    "            \n",
    "        transcript_id = row['Transcript stable ID']\n",
    "        #find ptms associated with isoform\n",
    "        ptm_df = find_ptms(isoform_id, transcript_id)\n",
    "\n",
    "        #get summary info about each isoform\n",
    "        isoform_info = findIsoformInfo(ptm_df, isoform_id, transcript_id)\n",
    "        if isoform_info is not None:\n",
    "            info_list.append(isoform_info)\n",
    "\n",
    "        #if desired save info about each ptm in isoforms\n",
    "        if ptm_df is not None:\n",
    "            df_list.append(ptm_df)\n",
    "\n",
    "    info_df = pd.concat(info_list)\n",
    "    info_df['UniProt ID'] = info_df['Isoform'].str.split('-').str[0]\n",
    "    info_df['Type'] = type\n",
    "    isoform_info_dict[type] = info_df\n",
    "    isoform_ptm_dict[type] = pd.concat(df_list)\n",
    "\n",
    "#calculate ratio of canonical to alternative isoforms\n",
    "    #combine canonical and alternative info\n",
    "ratio_data = isoform_info_dict['Canonical'].merge(isoform_info_dict['Alternative'], on = 'UniProt ID')\n",
    "#calculate the ratio of ptms in the alternative isoform to the canonical isoform\n",
    "ratio_list = []\n",
    "for i, row in ratio_data.iterrows():\n",
    "    if row['Number of PTMs_x'] == 0:\n",
    "        ratio_list.append(row['Number of PTMs_y'])\n",
    "    else:\n",
    "        ratio_list.append(row['Number of PTMs_y']/row['Number of PTMs_x'])\n",
    "ratio_data['Ratio'] = ratio_list\n",
    "ratio_data = ratio_data.rename({'Transcript_x': 'Canonical Transcript', 'Isoform_x':'Canonical Isoform', 'Protein Length_x':'Canonical Protein Length', 'Number of PTMs_x':'Number of PTMs in Canonical', 'Transcript_y':'Alternative Transcript', 'Isoform_y':'Alternative Isoform', 'Protein Length_y':'Alternative Protein Length', 'Number of PTMs_y':'Number of PTMs in Alternative'}, axis = 1)\n",
    "ratio_data = ratio_data.drop(['UniProt ID', 'Type_x', 'Type_y'], axis = 1)\n",
    "ratio_data = ratio_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "isoform_ptm_dict['Alternative'].to_csv(analysis_dir + '/PTMs_in_Isoforms/uniprot_alt_isoform_ptms.csv', index = False)\n",
    "ratio_data.to_csv(analysis_dir + '/PTMs_in_Isoforms/alternative_to_canonical_ratio.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
