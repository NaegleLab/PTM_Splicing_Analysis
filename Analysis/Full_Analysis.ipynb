{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of PTMs and Splicing\n",
    "\n",
    "This notebook contains all analysis used to generate data for the analysis of PTMs and Splicing (detailed in our manuscript here). To run this, notebook, you must have the resulting files from a complete mapping run of the [ExonPTMapper](https://github.com/NaegleLab/ExonPTMapper/tree/main) python package.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Load Data](#load-data)\n",
    "2. [Exclusion of PTMs (Figure 2)](#ptm-exclusion)\n",
    "    1. [Constitutive PTM Rates (Figure 2A/B, Supplementary Figure 5)](#constitutive-ptm-rate)\n",
    "    2. [Splice Events Responsible for Exclusion](#splice-events-responsible-for-ptm-exclusion) \n",
    "    3. [Density of PTMs in Tissue Specific Exons](#density-of-ptms-in-tissue-specific-exons)\n",
    "3. [Altered Flanking Sequences of PTMs (Figure 3)](#altered-flanking-sequences)\n",
    "    1. [Modification specific flanking sequence alteration rates (Figure 3C)](#mod-specific-rates-of-alteration)\n",
    "    2. [Events Causing Altered Flanking Sequences (Figure 3D)](#events-causing-altered-flanking-sequences)\n",
    "    3. [Sequence Similarity Between Canonical and Alternative Flanking Sequences (Figure 3E)](#sequence-similarity-between-flanking-sequences-in-canonical-and-alternative)\n",
    "    4. [Kinase Library Analysis (Figure 3F-G)](#kinase-library-analysis)\n",
    "4. [ESRP1-mediated Splicing in Prostate Cancer (Figure 4)](#esrp1-mediated-splicing-in-prostate-cancer)\n",
    "    1. [Project PTMs onto the SpliceSeq splicegraph](#projecting-ptms-onto-spliceseq-exons)\n",
    "    2. [Identifying differentially included PTMs in ESRP1-High Prostate Cancer Patients](#identify-differentially-included-ptm-containing-exons)\n",
    "    3. [Gene set enrichment of ESRP1-correlated genes](#gene-set-enrichment-of-esrp1-correlated-genes)\n",
    "    4. [Site-specific set enrichment of ESRP1-correlated PTMs](#site-enrichment-of-esrp1-correlated-ptms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mapper object from .tsv files\n",
      "Loading exon-specific data\n",
      "Loading transcript-specific data\n",
      "Loading gene-specific info\n",
      "Loading unique protein isoforms\n",
      "Loading protein-specific info\n",
      "Loading information on PTMs on canonical proteins\n",
      "Loading genomic coordinates of PTMs associated with canonical proteins\n",
      "Loading information on PTMs on alternative proteins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_68328\\3664408709.py:29: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mapper.isoform_ptms = pd.read_csv(config.processed_data_dir + 'isoform_ptms.csv', header = 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from Bio import pairwise2\n",
    "from ExonPTMapper import mapping, config\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import custom statistic functions\n",
    "import stat_utils\n",
    "\n",
    "#location of figshare data\n",
    "figshare_dir = 'C:/Users/Sam/OneDrive/Documents/GradSchool/Research/Splicing/Paper_Prep/PTM_Splicing_FigShare/'\n",
    "#where to find projected PTMs\n",
    "ptm_data_dir = figshare_dir + 'PTM_Projection_Data/'\n",
    "#where to find information from different databases\n",
    "database_dir = figshare_dir + 'External_Data/'\n",
    "#where analysis data will be saved\n",
    "analysis_dir = figshare_dir + 'Analysis_For_Paper/'\n",
    "\n",
    "\n",
    "\n",
    "#set global figure parameters\n",
    "min_mods = 150\n",
    "\n",
    "\n",
    "\n",
    "#load and process mapping data\n",
    "mapper = mapping.PTM_mapper()\n",
    "if os.path.exists(config.processed_data_dir + 'isoform_ptms.csv'):\n",
    "    mapper.isoform_ptms = pd.read_csv(config.processed_data_dir + 'isoform_ptms.csv', header = 0)\n",
    "\n",
    "\n",
    "#get modification class names and subtypes (converting between classes and subtypes)\n",
    "mod_groups = pd.read_csv(database_dir + '/modification_conversion.csv', header = 0)\n",
    "\n",
    "\n",
    "#separate ptm_info into unique exon/PTM pairs\n",
    "exploded_ptms = mapper.explode_PTMinfo()\n",
    "exploded_ptms = exploded_ptms.dropna(subset = ['Exon stable ID'])\n",
    "\n",
    "\n",
    "#separate based on modifications (unique PTM/modification class pairs)\n",
    "exploded_mods = mapper.ptm_info.copy()\n",
    "exploded_mods[\"Modification\"] = exploded_mods['Modification'].apply(lambda x: x.split(';'))\n",
    "exploded_mods = exploded_mods.explode('Modification').reset_index()\n",
    "exploded_mods = exploded_mods.rename({'index':'PTM'}, axis = 1)\n",
    "exploded_mods = exploded_mods.drop_duplicates(subset = ['Modification', 'PTM'])\n",
    "exploded_mods = exploded_mods.merge(mod_groups[['Mod Name', 'Mod Class']], left_on = 'Modification', right_on = 'Mod Name')\n",
    "exploded_mods = exploded_mods.drop(['Mod Name', 'Modification'], axis = 1)\n",
    "exploded_mods = exploded_mods.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get isoform-specific PTM information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 676143/676143 [00:10<00:00, 64311.31it/s]\n"
     ]
    }
   ],
   "source": [
    "#collapse alternative ptms dataframe to only include unique protein isoforms\n",
    "mapper.getIsoformSpecificPTMs()\n",
    "#calculate fraction of isoforms containing the a given ptm\n",
    "mapper.calculate_PTMconservation()\n",
    "\n",
    "#get flanking sequence changes\n",
    "for size in range(1,11):\n",
    "    mapper.isoform_ptms[f'Conserved Flank (Size = {size})'] = mapper.compareAllFlankSeqs(flank_size=size)\n",
    "\n",
    "#get tryptic fragments\n",
    "mapper.isoform_ptms['Conserved Fragment'] = mapper.compareAllTrypticFragments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper.isoform_ptms.to_csv(ptm_data_dir + 'processed_data_dir/isoform_ptms.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTM Exclusion\n",
    "\n",
    "The following code was used to generate data for Figure 2, -------.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constitutive PTM Rate\n",
    "\n",
    "The first analysis we performed after projecting PTMs onto alternative isoforms was to determine the fraction of PTMs that could be defined as constitutive (found in all isoforms of a given gene). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall PTM Constitutive Rate: 0.6962162997097382\n"
     ]
    }
   ],
   "source": [
    "overall_rate, num_isoforms = mapper.calculate_PTMconservation(return_score = True)\n",
    "print('Overall PTM Constitutive Rate: ' + str(overall_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Alternative Isoforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupings = ['Mod Class', 'Modification']\n",
    "fname = ['ByModificationClass', 'ByModificationSubtype']\n",
    "\n",
    "for group, f in zip(groupings, fname):\n",
    "    #get non-duplicate data for the group type\n",
    "    if group == 'Mod Class':\n",
    "        mod_data = exploded_mods.copy()\n",
    "    elif group == 'Modification':\n",
    "        exploded_subtype = mapper.ptm_info.copy()\n",
    "        exploded_subtype[\"Modification\"] = exploded_subtype['Modification'].apply(lambda x: x.split(';'))\n",
    "        exploded_subtype = exploded_subtype.explode('Modification').reset_index()\n",
    "        exploded_subtype = exploded_subtype.rename({'index':'PTM'}, axis = 1)\n",
    "        exploded_subtype = exploded_subtype.drop_duplicates(subset = ['Modification', 'PTM'])\n",
    "        mod_data = exploded_subtype.copy()\n",
    "\n",
    "    #get number of modifications\n",
    "    sizes = mod_data.groupby(group).size()\n",
    "    sizes = sizes.sort_values(ascending = False)\n",
    "    #get the number of constitutive ptms, then add in any mod types that don't have any constitutive ptms\n",
    "    constitutive_ptms = mod_data[mod_data['PTM Conservation Score'] == 1]\n",
    "    grouped_conserved = constitutive_ptms.groupby(group).size()\n",
    "    #add in any modification types that don't have any constitutive ptms\n",
    "    for mod in sizes.index:\n",
    "        if mod not in grouped_conserved.index.values:\n",
    "            grouped_conserved[mod] = 0\n",
    "    rate_data = grouped_conserved[sizes.index]/sizes\n",
    "    rate_data = pd.concat([sizes, rate_data], axis = 1)\n",
    "    rate_data.columns = ['Number of Instances in Proteome', 'Rate']\n",
    "    \n",
    "    #save data\n",
    "    if not os.path.exists(analysis_dir + '/Constitutive_Rates'):\n",
    "        os.makedirs(analysis_dir + '/Constitutive_Rates')\n",
    "    rate_data.to_csv(analysis_dir + f'/Constitutive_Rates/{f}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering out potentially non-functional transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50897/50897 [01:56<00:00, 436.32it/s]\n",
      "100%|██████████| 50897/50897 [00:54<00:00, 936.58it/s] \n",
      "100%|██████████| 50897/50897 [05:16<00:00, 160.74it/s]\n",
      "100%|██████████| 50897/50897 [04:47<00:00, 177.20it/s]\n",
      "100%|██████████| 50897/50897 [04:12<00:00, 201.29it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "num_isoforms = {}\n",
    "label = 'Ensembl (All)'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(return_score = True)\n",
    "\n",
    "label = 'UniProt'\n",
    "uniprot_isoforms = config.translator.loc[config.translator['Uniprot Canonical'] == 'Alternative', 'Transcript stable ID'].values\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = uniprot_isoforms, save_col = 'UniProt Isoform Score', return_score = True)\n",
    "\n",
    "appris_isoforms = mapper.transcripts.dropna(subset = 'APPRIS annotation').index.values\n",
    "label = 'APPRIS'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = appris_isoforms, save_col = 'APPRIS Score', return_score = True)\n",
    "\n",
    "label = 'CCDS'\n",
    "ccds_isoforms = config.translator.dropna(subset = 'CCDS ID')['Transcript stable ID'].values\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = ccds_isoforms, save_col = 'CCDS Isoform Score', return_score = True)\n",
    "\n",
    "label = 'PDB'\n",
    "pdb_isoforms = config.translator.dropna(subset = 'PDB ID')['Transcript stable ID'].values\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = pdb_isoforms, save_col = 'PDB Isoform Score', return_score = True)\n",
    "\n",
    "label = 'RefSeq'\n",
    "refseq_isoforms = config.translator.dropna(subset = 'RefSeq mRNA ID')['Transcript stable ID'].values\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = pdb_isoforms, save_col = 'Refseq Isoform Score', return_score = True)\n",
    "\n",
    "#combine data and save\n",
    "scores = pd.Series(scores, name = 'Constitutive Rate')\n",
    "num_isoforms = pd.Series(num_isoforms, name = 'Number of Isoforms')\n",
    "scores = pd.concat([scores, num_isoforms], axis = 1)  \n",
    "\n",
    "if not os.path.exists(analysis_dir + '/Constitutive_Rates/Filtered'):\n",
    "    os.makedirs(analysis_dir + '/Constitutive_Rates/Filtered')\n",
    "scores.to_csv(analysis_dir + '/Constitutive_Rates/Filtered/ByDatabase.csv')\n",
    "\n",
    "\n",
    "#save mapper ptm info with added rate columns\n",
    "mapper.ptm_info.to_csv(ptm_data_dir + 'processed_data_dir/ptm_info.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper.ptm_info.to_csv(ptm_data_dir + 'processed_data_dir/ptm_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By Transcript Support Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50897/50897 [01:16<00:00, 669.02it/s]\n",
      "100%|██████████| 50897/50897 [01:00<00:00, 835.50it/s] \n",
      "100%|██████████| 50897/50897 [01:03<00:00, 803.75it/s]\n",
      "100%|██████████| 50897/50897 [01:04<00:00, 787.07it/s]\n",
      "100%|██████████| 50897/50897 [00:46<00:00, 1101.13it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "num_isoforms = {}\n",
    "\n",
    "#all isoforms\n",
    "label = 'All'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(return_score = True)\n",
    "\n",
    "#transcript support level\n",
    "tsl_transcripts = mapper.transcripts.dropna(subset = 'Transcript support level (TSL)').copy()\n",
    "tsl1_isoforms = tsl_transcripts.loc[tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl1')].index.values\n",
    "tsl1_2_isoforms = tsl_transcripts.loc[tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl1') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl2')].index.values\n",
    "tsl1_2_3_isoforms = tsl_transcripts.loc[tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl1') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl2') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl3')].index.values\n",
    "tsl1_2_3_4_isoforms = tsl_transcripts.loc[tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl1') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl2') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl3')| tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl4')].index.values\n",
    "tsl1_2_3_4_5_isoforms = tsl_transcripts.loc[tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl1') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl2') | tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl3')| tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl4')| tsl_transcripts['Transcript support level (TSL)'].str.contains('tsl5')].index.values\n",
    "label = 'TSL1/2/3/4/5'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = tsl1_2_3_4_5_isoforms, save_col = 'TSL1/2/3/4/5 Score', return_score = True)\n",
    "label = 'TSL1/2/3/4'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = tsl1_2_3_4_isoforms, save_col = 'TSL1/2/3/4/5 Score', return_score = True)\n",
    "label = 'TSL1/2/3'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = tsl1_2_3_isoforms, save_col = 'TSL1/2/3 Score', return_score = True)\n",
    "label = 'TSL1/2'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = tsl1_2_isoforms, save_col = 'TSL1/2 Score', return_score = True)\n",
    "label = 'TSL1'\n",
    "scores[label], num_isoforms[label] = mapper.calculate_PTMconservation(transcript_subset = tsl1_isoforms, save_col = 'TSL1 Score', return_score = True)\n",
    "\n",
    "\n",
    "#combine data and save\n",
    "scores = pd.Series(scores, name = 'Constitutive Rate')\n",
    "num_isoforms = pd.Series(num_isoforms, name = 'Number of Isoforms')\n",
    "scores = pd.concat([scores, num_isoforms], axis = 1)  \n",
    "\n",
    "if not os.path.exists(analysis_dir + '/Constitutive_Rates/Filtered'):\n",
    "    os.makedirs(analysis_dir + '/Constitutive_Rates/Filtered')\n",
    "scores.to_csv(analysis_dir + '/Constitutive_Rates/Filtered/ByTranscriptSupportLevel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By TRIFID Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50897/50897 [01:34<00:00, 538.59it/s]\n",
      "100%|██████████| 50897/50897 [01:18<00:00, 646.57it/s]\n",
      "100%|██████████| 50897/50897 [01:13<00:00, 696.56it/s]\n",
      "100%|██████████| 50897/50897 [01:08<00:00, 740.63it/s]\n",
      "100%|██████████| 50897/50897 [01:06<00:00, 766.64it/s]\n",
      "100%|██████████| 50897/50897 [01:01<00:00, 833.29it/s]\n",
      "100%|██████████| 50897/50897 [01:02<00:00, 813.88it/s]\n",
      "100%|██████████| 50897/50897 [00:59<00:00, 853.82it/s]\n",
      "100%|██████████| 50897/50897 [01:02<00:00, 811.56it/s]\n",
      "100%|██████████| 50897/50897 [00:57<00:00, 878.82it/s]\n",
      "100%|██████████| 50897/50897 [00:56<00:00, 899.86it/s]\n",
      "100%|██████████| 50897/50897 [00:54<00:00, 941.57it/s]\n",
      "100%|██████████| 50897/50897 [00:51<00:00, 987.32it/s] \n",
      "100%|██████████| 50897/50897 [00:51<00:00, 995.66it/s] \n",
      "100%|██████████| 50897/50897 [00:48<00:00, 1043.88it/s]\n",
      "100%|██████████| 50897/50897 [00:42<00:00, 1200.45it/s]\n",
      "100%|██████████| 50897/50897 [00:41<00:00, 1218.76it/s]\n",
      "100%|██████████| 50897/50897 [00:39<00:00, 1282.72it/s]\n",
      "100%|██████████| 50897/50897 [00:39<00:00, 1288.53it/s]\n",
      "100%|██████████| 50897/50897 [00:37<00:00, 1373.50it/s]\n",
      "100%|██████████| 20/20 [21:32<00:00, 64.62s/it]\n"
     ]
    }
   ],
   "source": [
    "scores ={}\n",
    "num_isoforms = {}\n",
    "for cutoff in tqdm(np.arange(0, 1, 0.05)):\n",
    "    alt_transcripts = mapper.transcripts[mapper.transcripts['TRIFID Score'] > cutoff].index.values\n",
    "    scores[cutoff], num_isoforms[cutoff] = mapper.calculate_PTMconservation(transcript_subset = alt_transcripts, save_col = 'Tmp TRIFID Col', return_score = True)\n",
    "\n",
    "#combine data and save\n",
    "scores = pd.Series(scores, name = 'Constitutive Rate')\n",
    "num_isoforms = pd.Series(num_isoforms, name = 'Number of Isoforms')\n",
    "scores = pd.concat([scores, num_isoforms], axis = 1)  \n",
    "\n",
    "if not os.path.exists(analysis_dir + '/Constitutive_Rates/Filtered'):\n",
    "    os.makedirs(analysis_dir + '/Constitutive_Rates/Filtered')\n",
    "scores.to_csv(analysis_dir + '/Constitutive_Rates/Filtered/ByTRIFID.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological Process and Function Enrichment of Splicing-Controlled PTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting enrichment of function for all ptms\n"
     ]
    }
   ],
   "source": [
    "#annotations from phosphositeplus\n",
    "annotations = pd.read_csv(database_dir + '/PhosphoSitePlus/Regulatory_sites.gz', sep = '\\t',compression = 'gzip', on_bad_lines='skip', header = 2)\n",
    "annotations['Substrate'] = annotations['ACC_ID'] + '_' + annotations['MOD_RSD'].apply(lambda x: x.split('-')[0])\n",
    "\n",
    "print('Getting enrichment of function for all ptms')\n",
    "#get list of constitutive and non-constitutive ptms\n",
    "constitutive_ptms = mapper.ptm_info[mapper.ptm_info['PTM Conservation Score'] == 1]\n",
    "non_constitutive_ptms = mapper.ptm_info[mapper.ptm_info['PTM Conservation Score'] != 1]\n",
    "\n",
    "\n",
    "function_table = stat_utils.constructPivotTable(mapper.ptm_info.reset_index(), annotations, reference_col='ON_FUNCTION', collapse_on_similar = True, include_unknown=True)\n",
    "process_table = stat_utils.constructPivotTable(mapper.ptm_info.reset_index(),annotations, reference_col='ON_PROCESS', collapse_on_similar = True, include_unknown=True)\n",
    "\n",
    "function_enrichment = stat_utils.generate_site_enrichment(constitutive_ptms.index.values, function_table, subset_name = 'Constitutive', type = 'Function', fishers = True)\n",
    "process_enrichment = stat_utils.generate_site_enrichment(constitutive_ptms.index.values, process_table, subset_name = 'Constitutive', type = 'Process', fishers = True)\n",
    "\n",
    "function_enrichment.to_csv(analysis_dir + '/Constitutive_Rates/Enrichment/Function_Enrichment.csv')\n",
    "process_enrichment.to_csv(analysis_dir + '/Constitutive_Rates/Enrichment/Process_Enrichment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splice events responsible for PTM exclusion\n",
    "\n",
    "Given splice event data obtained from ExonPTMapper package, calculate the fraction of PTM exclusion events that are caused by skipped exon events, alternative splice sites, and mutually exclusive exons.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab ptms in alternative isoforms\n",
    "alternative_ptms = mapper.alternative_ptms.copy()\n",
    "\n",
    "#extract events causing loss of PTMs\n",
    "alternative_ptms = alternative_ptms[alternative_ptms['Mapping Result'] == 'Not Found']\n",
    "alternative_ptms['Event Type'] = alternative_ptms['Event Type'].apply(lambda x: x.split(';'))\n",
    "alternative_ptms = alternative_ptms.explode('Event Type').dropna(subset = 'Event Type')\n",
    "\n",
    "#separate based on modifications (unique PTM/modification class pairs)\n",
    "exploded_res = alternative_ptms.copy()\n",
    "exploded_res['Modification'] = exploded_res['Modification'].apply(lambda x: x.split(';'))\n",
    "exploded_res = exploded_res.explode('Modification')\n",
    "exploded_res = exploded_res.merge(mod_groups[['Mod Name', 'Mod Class']], left_on = 'Modification', right_on = 'Mod Name')\n",
    "\n",
    "#extract only true splice events (ignore alternative promoters, etc.)\n",
    "events_to_keep = [\"3' ASS\", \"3' and 5' ASS\", \"5' ASS\", 'Skipped', 'Mutually Exclusive']\n",
    "exploded_res = exploded_res[exploded_res['Event Type'].isin(events_to_keep)]\n",
    "\t\n",
    "#group by modification type and event type\n",
    "grouped_res = exploded_res.groupby(['Mod Class','Event Type'])\n",
    "grouped_res = grouped_res.size().reset_index()\n",
    "\n",
    "#count number of events for each modification\n",
    "sizes = grouped_res.groupby('Mod Class')[0].sum().sort_values(ascending = False)\n",
    "mods_to_keep = sizes.index\n",
    "\n",
    "total_events = {}\n",
    "for mod in grouped_res['Mod Class'].unique():\n",
    "\tmod_grouped = grouped_res[grouped_res['Mod Class'] == mod]\n",
    "\ttotal_events[mod] = mod_grouped[0].sum()\n",
    "\t\n",
    "possible_events = grouped_res['Event Type'].unique()\n",
    "plt_data = []\n",
    "mods = mods_to_keep\n",
    "for event in possible_events:\n",
    "\tevent_data = []\n",
    "\tevent_grouped = grouped_res[grouped_res['Event Type'] == event]\n",
    "\tfor mod in mods:\n",
    "\t\tif mod in event_grouped['Mod Class'].values:\n",
    "\t\t\tevent_data.append(int(event_grouped.loc[event_grouped['Mod Class'] == mod, 0].values[0])/total_events[mod])\n",
    "\t\telse:\n",
    "\t\t\tevent_data.append(0)\n",
    "\tplt_data.append(event_data)\n",
    "\t\n",
    "event_data = pd.DataFrame(plt_data, index = possible_events, columns = mods_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data.to_csv(analysis_dir + '/Constitutive_Rates/Splice_Event_Fractions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density of PTMs in tissue specific exons\n",
    "\n",
    "Tissue-specific exons were extracted from three publications, and our projected PTM data was used to determine the density of PTMs in these exons.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting PTM Density across the entire proteome\n",
      "Getting PTMs in tissue specific exons from Buljan et al. (2012)\n",
      "Getting PTMs in tissue specific exons from Rodriguez et al. (2020)\n",
      "Getting PTMs in tissue specific exons from Gonzalez-Porta et al. (2013)\n",
      "Calculating PTM density in tissue-specific exons\n"
     ]
    }
   ],
   "source": [
    "import tissue_specificity\n",
    "all_data, densities = tissue_specificity.getTSData(mapper, exploded_ptms, exploded_mods, mod_groups, figshare_dir = figshare_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(analysis_dir + '/Tissue_Specificity'):\n",
    "    os.mkdir(analysis_dir + '/Tissue_Specificity')\n",
    "densities.to_csv(analysis_dir + '/Tissue_Specificity/PTM_Densities.csv')\n",
    "all_data.to_csv(analysis_dir + '/Tissue_Specificity/PTMs_in_TissueSpecificExons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altered Flanking Sequences (Figure 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mod specific rates of alteration\n",
    "\n",
    "Here, we sought to look at the rate of alteration considering different window sizes (number of residues on either side of the PTM), broken down by modification type. This data was used for Figure4C.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModSpecificChanges(mapper, mod_groups, flank_size = 5, return_fraction_only = True):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of ptms with altered flanking sequence of the given flank size for each modification group\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mapper: PTMmapper object\n",
    "        PTMmapper object containing alternative and canonical flanking sequence data\n",
    "    mod_groups: pandas dataframe\n",
    "        dataframe for conversion from modification subtypes ('Mod Name') to modification classes ('Mod Class)\n",
    "    flank_size: int\n",
    "        size of the flanking sequence to compare. IMPORTANT, this should not be larger than the available flanking sequence in the ptm_info dataframe\n",
    "    return_fraction_only: bool\n",
    "        If True, return only the fraction of ptms with altered flanking sequence. If False, return the fraction of ptms with altered flanking sequence and the total number of ptms altered + total number of ptms\n",
    "    unique_isoforms: bool\n",
    "        If True, compare ptms found in unique isoforms only. If False, compare ptms found in all transcripts, regardless of if there is redundant protein sequences\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    If return_fraction_only is True:\n",
    "        fraction_altered: pandas Series\n",
    "            Series containing the fraction of ptms with altered flanking sequence for each modification group\n",
    "    If return_fraction_only is False:\n",
    "        results: pandas dataframe\n",
    "            dataframe containing the fraction of ptms with altered flanking sequence and the total number of ptms altered + total number of ptms for each modification group\n",
    "\n",
    "    \"\"\"\n",
    "    conserved = mapper.isoform_ptms[mapper.isoform_ptms['Mapping Result'] == 'Success']\n",
    "    conserved = conserved.drop_duplicates()\n",
    "\n",
    "    #separate into mod specific rows\n",
    "    conserved['Modification'] = conserved['Modification'].apply(lambda x: x.split(';'))\n",
    "    conserved = conserved.explode('Modification')\n",
    "    conserved = conserved.merge(mod_groups[['Mod Name', 'Mod Class']], left_on = 'Modification', right_on = 'Mod Name', how = 'left')\n",
    "    conserved = conserved.drop(['Mod Name', 'Modification'], axis = 1)\n",
    "    conserved = conserved.drop_duplicates()\n",
    "    #calculate number of each modification type that are conserved\n",
    "    num_single_mods_conserved = conserved.groupby('Mod Class').size()\n",
    "    #calculate number of each modification type that are conserved AND have conserved flank\n",
    "    num_single_mods_conserved_flank = conserved[conserved[f'Conserved Flank (Size = {flank_size})'] == 1].groupby('Mod Class').size()\n",
    "    #calculate number of each modification type that are conserved AND have altered flank\n",
    "    num_single_mods_altered_flank = conserved[conserved[f'Conserved Flank (Size = {flank_size})'] == 0].groupby('Mod Class').size()\n",
    "\n",
    "    #fill in any mods without a conserved or altered flank\n",
    "    for mod in num_single_mods_conserved.index:\n",
    "        if mod not in num_single_mods_altered_flank.index.values:\n",
    "            num_single_mods_altered_flank[mod] = 0\n",
    "        if mod not in num_single_mods_conserved_flank.index.values:\n",
    "            num_single_mods_conserved_flank[mod] = 0\n",
    "    fraction_of_mod_with_altered_flank = num_single_mods_altered_flank/num_single_mods_conserved\n",
    "\n",
    "    if return_fraction_only:\n",
    "        fraction_of_mod_with_altered_flank.name = flank_size\n",
    "        return fraction_of_mod_with_altered_flank\n",
    "    else:\n",
    "        results = pd.concat([num_single_mods_conserved, num_single_mods_conserved_flank, num_single_mods_altered_flank, fraction_of_mod_with_altered_flank], axis = 1)\n",
    "        results.columns = ['Number of Conserved PTMs', 'Number of PTMs with Matching Flanking Sequence', 'Number of PTMs with Altered Flanking Sequence', 'Fraction of PTMs with Altered Flanking Sequence']\n",
    "        return results\n",
    "    \n",
    "def alteredByWindowSize(mapper, mod_groups, flank_size = list(range(1,6)), unique_isoforms = True):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of ptms with altered flanking sequence for each modification group for each flank size\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mapper: PTMmapper object\n",
    "        PTMmapper object containing alternative and canonical flanking sequence data\n",
    "    mod_groups: pandas dataframe\n",
    "        dataframe for conversion from modification subtypes ('Mod Name') to modification classes ('Mod Class)\n",
    "    flank_size: list\n",
    "        list of flank sizes to compare. IMPORTANT, maximum value should not be larger than the available flanking sequence in the ptm_info dataframe\n",
    "    unique_isoforms: bool\n",
    "        If True, compare ptms found in unique isoforms only. If False, compare ptms found in all transcripts, regardless of if there is redundant protein sequences\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fractions: pandas dataframe\n",
    "        dataframe containing the fraction of ptms with altered flanking sequence for each modification group for each flank size\n",
    "    \"\"\"\n",
    "    fractions = None\n",
    "    for flank in flank_size:\n",
    "        if flank == 5:\n",
    "            return_fraction_only = False\n",
    "        else:\n",
    "            return_fraction_only = True\n",
    "\n",
    "        if fractions is None:\n",
    "            fractions = getModSpecificChanges(mapper, mod_groups, flank, return_fraction_only = True)\n",
    "        elif flank == 5:\n",
    "            results = getModSpecificChanges(mapper, mod_groups, flank, return_fraction_only=False)\n",
    "            tmp_fraction = results['Fraction of PTMs with Altered Flanking Sequence']\n",
    "            tmp_fraction.name = 5\n",
    "            fractions = pd.concat([fractions, tmp_fraction], axis = 1)\n",
    "\n",
    "        else:\n",
    "            fractions = pd.concat([fractions, getModSpecificChanges(mapper, mod_groups, flank, return_fraction_only=True)], axis = 1)\n",
    "    return fractions, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions, window5_flanks = alteredByWindowSize(mapper, mod_groups)\n",
    "fractions.to_csv(figshare_dir + '/Analysis_For_Paper/FlankingSequences/Mod_Specific_Alteration_Rates.csv')\n",
    "window5_flanks.to_csv(figshare_dir + '/Analysis_For_Paper/FlankingSequences/Window5_FlankingSequences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events Causing Altered Flanking Sequences\n",
    "\n",
    "Analysis of the splice events that are impacting flanking sequences and whether they are caused by the PTM-containing exon or an adjacent exon. Data used in Figure 4D.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upstream_test(mapper, sevents, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript):\n",
    "    #look at what is happening in upstream exon\n",
    "    rank = int(canonical_ptm_info['Exon rank in transcript'])\n",
    "    if rank != 1:\n",
    "        upstream_rank = rank - 1\n",
    "        upstream_exon = mapper.exons[(mapper.exons['Exon rank in transcript'] == upstream_rank) \n",
    "                                     & (mapper.exons['Transcript stable ID'] == canonical_transcript)].squeeze()\n",
    "        #check for inserted exon\n",
    "        if mapper.genes.loc[canonical_exon_info['Gene stable ID'], 'Strand'] == 1:\n",
    "            upstream_end = upstream_exon['Exon End (Gene)']\n",
    "            canonical_start = canonical_exon_info['Exon Start (Gene)']\n",
    "            alt_exons = mapper.exons[mapper.exons['Transcript stable ID'] == alt_transcript]\n",
    "            alt_exons = alt_exons[(alt_exons['Exon Start (Gene)'] > upstream_end) &\n",
    "                                    (alt_exons['Exon End (Gene)'] < canonical_start)]\n",
    "            if alt_exons.shape[0] > 0:\n",
    "                return 'Inserted Exon (Upstream Exon)'\n",
    "\n",
    "        else:\n",
    "            upstream_start = upstream_exon['Exon Start (Gene)']\n",
    "            canonical_end = canonical_exon_info['Exon End (Gene)']\n",
    "            alt_exons = mapper.exons[mapper.exons['Transcript stable ID'] == alt_transcript]\n",
    "            alt_exons = alt_exons[(alt_exons['Exon Start (Gene)'] > canonical_end) &\n",
    "                                    (alt_exons['Exon End (Gene)'] < upstream_start)]\n",
    "            if alt_exons.shape[0] > 0:\n",
    "                return 'Inserted Exon (Upstream Exon)'\n",
    "\n",
    "\n",
    "        sevent_of_interest = sevents[(sevents['Exon ID (Canonical)'] == upstream_exon['Exon stable ID'])\n",
    "                                            & (sevents['Canonical Transcript'] == canonical_transcript)]\n",
    "        if sevent_of_interest.shape[0] ==0:\n",
    "            return 'missing sevent'\n",
    "        else:\n",
    "            sevent_of_interest = sevent_of_interest.iloc[0]\n",
    "\n",
    "        if sevent_of_interest['Event Type'] == 'Skipped':\n",
    "            return 'Skipped (Upstream Exon)'\n",
    "        elif sevent_of_interest['Event Type'] == \"3' ASS\" or sevent_of_interest['Event Type'] == \"3' and 5' ASS\":\n",
    "            return 'ASS (Upstream Exon)'\n",
    "        elif sevent_of_interest['Event Type'] == 'Mutually Exclusive':\n",
    "            return 'MXE (Upstream Exon)'\n",
    "        elif sevent_of_interest['Event Type'] == 'Conserved':\n",
    "            return None\n",
    "        else:\n",
    "            return 'unclear'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def downstream_test(mapper, sevents, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript):\n",
    "    #look at what is happening in upstream exon\n",
    "    rank = int(canonical_ptm_info['Exon rank in transcript'])\n",
    "    canonical_transcript = canonical_ptm_info['Transcripts']\n",
    "    downstream_rank = rank + 1\n",
    "    downstream_exon = mapper.exons[(mapper.exons['Exon rank in transcript'] == downstream_rank) \n",
    "                                 & (mapper.exons['Transcript stable ID'] == canonical_transcript)].squeeze()\n",
    "\n",
    "    #check for inserted exon\n",
    "    if mapper.genes.loc[canonical_exon_info['Gene stable ID'], 'Strand'] == -1:\n",
    "        downstream_end = downstream_exon['Exon End (Gene)']\n",
    "        canonical_start = canonical_exon_info['Exon Start (Gene)']\n",
    "        alt_exons = mapper.exons[mapper.exons['Transcript stable ID'] == alt_transcript]\n",
    "        alt_exons = alt_exons[(alt_exons['Exon Start (Gene)'] > downstream_end) &\n",
    "                                (alt_exons['Exon End (Gene)'] < canonical_start)]\n",
    "        if alt_exons.shape[0] > 0:\n",
    "            return 'Inserted Exon (Downstream Exon)'\n",
    "\n",
    "    else:\n",
    "        downstream_start = downstream_exon['Exon Start (Gene)']\n",
    "        canonical_end = canonical_exon_info['Exon End (Gene)']\n",
    "        alt_exons = mapper.exons[mapper.exons['Transcript stable ID'] == alt_transcript]\n",
    "        alt_exons = alt_exons[(alt_exons['Exon Start (Gene)'] > canonical_end) &\n",
    "                                (alt_exons['Exon End (Gene)'] < downstream_start)]\n",
    "        if alt_exons.shape[0] > 0:\n",
    "            return 'Inserted Exon (Downstream Exon)' \n",
    "\n",
    "    sevent_of_interest = sevents[(sevents['Exon ID (Canonical)'] == downstream_exon['Exon stable ID'])\n",
    "                                        & (sevents['Canonical Transcript'] == canonical_transcript)]\n",
    "\n",
    "    if sevent_of_interest.shape[0] == 0:\n",
    "        return 'missing sevent'\n",
    "    else:\n",
    "        sevent_of_interest = sevent_of_interest.iloc[0]\n",
    "        \n",
    "    if sevent_of_interest['Event Type'] == 'Skipped':\n",
    "        return 'Skipped (Downstream Exon)'\n",
    "    elif sevent_of_interest['Event Type'] == \"5' ASS\" or sevent_of_interest['Event Type'] == \"3' and 5' ASS\":\n",
    "        return 'ASS (Downstream Exon)'\n",
    "    elif sevent_of_interest['Event Type'] == 'Mutually Exclusive':\n",
    "        return 'MXE (Downstream Exon)'\n",
    "    elif sevent_of_interest['Event Type'] == 'Conserved':\n",
    "        return None\n",
    "    else:\n",
    "        return 'unclear'\n",
    "    \n",
    "def complete_test_forConserved(mapper, sevents, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript, flank_size = 5):\n",
    "    if int(canonical_ptm_info['Distance to C-terminal Splice Boundary (NC)']) <= flank_size*3:\n",
    "        downstream_result = downstream_test(mapper, sevents, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript)\n",
    "    else:\n",
    "        downstream_result = None\n",
    "        \n",
    "    if int(canonical_ptm_info['Distance to N-terminal Splice Boundary (NC)']) <= flank_size*3:\n",
    "        upstream_result = upstream_test(mapper, sevents, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript)\n",
    "    else:\n",
    "        upstream_result = None\n",
    "        \n",
    "    if upstream_result is not None and downstream_result is not None:\n",
    "        return ','.join([upstream_result,downstream_result])\n",
    "    elif upstream_result is not None:\n",
    "        return upstream_result\n",
    "    elif downstream_result is not None:\n",
    "        return downstream_result\n",
    "    else:\n",
    "        return 'unclear'\n",
    "    \n",
    "    \n",
    "\n",
    "def complete_test_forASS(mapper, sevents, event_type, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript,alt_exon_id, flank_size = 5):\n",
    "    alt_exon = mapper.exons[(mapper.exons['Transcript stable ID'] == alt_transcript) &\n",
    "             (mapper.exons['Exon stable ID'] == alt_exon_id)].squeeze()\n",
    "    if event_type == \"3' ASS\":\n",
    "        distance_to_altered_boundary = alt_exon['Exon End (Gene)'] -int(canonical_ptm_info['Gene Location (NC)'])\n",
    "    elif event_type == \"5' ASS\":\n",
    "        distance_to_altered_boundary = alt_exon['Exon End (Gene)'] -int(canonical_ptm_info['Gene Location (NC)'])\n",
    "    else:\n",
    "        distance_to_altered_boundary = np.min([alt_exon['Exon End (Gene)'] -int(canonical_ptm_info['Gene Location (NC)']), alt_exon['Exon End (Gene)'] -int(canonical_ptm_info['Gene Location (NC)'])])\n",
    "    \n",
    "    if distance_to_altered_boundary <= flank_size*3:\n",
    "        return 'ASS (Exon with PTM)'\n",
    "    else:\n",
    "        relevant_events = sevents[sevents['Alternative Transcript'] == alt_transcript]\n",
    "        return complete_test_forConserved(mapper, relevant_events, canonical_ptm_info, canonical_exon_info, canonical_transcript, alt_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load splice event information\n",
    "sevents = pd.read_csv(config.processed_data_dir + 'splice_events.csv').drop_duplicates()\n",
    "#grab flanking sequences that are different from canonical, separate by event and canonical exon id\n",
    "altered_flanks = mapper.alternative_ptms[mapper.alternative_ptms['Conserved Flank'] == 0].copy()\n",
    "altered_flanks['Event Type'] = altered_flanks['Event Type'].apply(lambda x: x.split(';'))\n",
    "altered_flanks['Exon ID (Canonical)'] = altered_flanks['Exon ID (Canonical)'].apply(lambda x: x.split(';'))\n",
    "altered_flanks = altered_flanks.explode(['Event Type'])\n",
    "\n",
    "test = altered_flanks.copy()\n",
    "cause = []\n",
    "for i, row in tqdm.tqdm(test.iterrows()):\n",
    "       #get distance to boundary\n",
    "    ptm = row['Source of PTM']\n",
    "    canonical_exon_id = row['Exon ID (Canonical)']\n",
    "    relevant_events = sevents[sevents['Alternative Transcript'] == row['Alternative Transcript']]\n",
    "    canonical_ptm_info = exploded_ptms[(exploded_ptms['PTM'] == ptm) & (exploded_ptms['Exon stable ID'].isin(canonical_exon_id))]\n",
    "    #grab first relevant entry (if only one, will just convert to series)\n",
    "    if canonical_ptm_info.shape[0] == 0:\n",
    "        cause.append('PTM not found')\n",
    "    else:\n",
    "        canonical_ptm_info = canonical_ptm_info.iloc[0]\n",
    "        canonical_transcript = canonical_ptm_info['Transcripts']\n",
    "        canonical_exon_info = mapper.exons[(mapper.exons['Exon stable ID'].isin(canonical_exon_id))\n",
    "                                         & (mapper.exons['Transcript stable ID'] == canonical_transcript)].squeeze()\n",
    "        if row['Event Type'] == 'Conserved' or row['Event Type'] == 'No Difference':\n",
    "            cause.append(complete_test_forConserved(mapper, relevant_events, canonical_ptm_info, canonical_exon_info, canonical_transcript, row['Alternative Transcript']))\n",
    "        elif 'ASS' in row['Event Type']:\n",
    "            cause.append(complete_test_forASS(mapper, sevents, row['Event Type'], canonical_ptm_info, canonical_exon_info, canonical_transcript, row['Alternative Transcript'], row['Exon ID (Alternative)'], flank_size = 5))\n",
    "        elif row['Event Type'] == 'Mutually Exclusive':\n",
    "            cause.append('MXE (Exon with PTM)')\n",
    "        else:\n",
    "            cause.append(row['Event Type'])\n",
    "\n",
    "altered_flanks['Cause'] = cause\n",
    "\n",
    "cause_breakdown = altered_flanks.groupby('Cause').size()\n",
    "cause_breakdown.name = 'Number of Instances'\n",
    "cause_breakdown.to_csv(analysis_dir + '/FlankingSequences/EventsCausingAlteration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Similarity Between Flanking Sequences in Canonical and Alternative Isoforms\n",
    "\n",
    "Compare sequence similarity between the flanking sequence in the canonical isoform to the altered flanking sequence in the alternative isoform. Data used for Figure 4E.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequenceSimilarity(can_flank, alt_flank):\n",
    "    \"\"\"\n",
    "    Given two flanking sequences, calculate the sequence similarity between them using Biopython and criteria definded by Pillman et al. BMC Bioinformatics 2011\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    can_flank: str\n",
    "        flanking sequence for PTM in canonical protein isoform\n",
    "    alt_flank: str\n",
    "        flanking sequence for PTM in alternative protein isoform\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    normalized_score: float\n",
    "        normalized score of sequence similarity between flanking sequences (calculated similarity/max possible similarity)\n",
    "    \"\"\"\n",
    "    #align canonical and alternative flanks, return only the score\n",
    "    actual_similarity = pairwise2.align.globalxs(can_flank, alt_flank, -10, -2, score_only = True)\n",
    "    #aling the canonical flank to itself, return only the score\n",
    "    control_similarity = pairwise2.align.globalxs(can_flank, can_flank, -10, -2, score_only = True)\n",
    "    #normalize score\n",
    "    normalized_score = actual_similarity/control_similarity\n",
    "    return normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option where we consider regulatory region for each flanking sequence size\n",
    "isoform_ptms = mapper.isoform_ptms.copy()\n",
    "similarity = defaultdict(list)\n",
    "flank_sizes = [3, 5, 7, 10]\n",
    "for size in flank_sizes:\n",
    "    altered_flanks = isoform_ptms[(isoform_ptms[f'Conserved Flank (Size = {size})'] == 0) & (isoform_ptms['Mapping Result'] == 'Success')].copy()\n",
    "    for i,row in altered_flanks.iterrows():\n",
    "        ptm = row['Source of PTM']\n",
    "        if ';' in ptm:\n",
    "            ptm = ptm.split(';')[0]\n",
    "        alt_flank = row['Flanking Sequence'][10-size:10+size+1]\n",
    "        can_flank = mapper.ptm_info.loc[ptm, 'Flanking Sequence'][10-size:10+size+1]\n",
    "        similarity[size].append(getSequenceSimilarity(can_flank, alt_flank))\n",
    "\n",
    "#construct dataframe from dictionary, adding column indicating window size\n",
    "similarity_data = []\n",
    "for size in [3,5,7,10]:\n",
    "    subset = pd.DataFrame(similarity[size], columns = ['Similarity'])\n",
    "    subset['Window Size'] = size\n",
    "    similarity_data.append(subset)\n",
    "similarity_data = pd.concat(similarity_data)\n",
    "\n",
    "#multiply similarity by 100 to get percentage\n",
    "similarity_data['Similarity'] = similarity_data['Similarity']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_data.to_csv(figshare_dir + '/Analysis_For_Paper/FlankingSequences/SequenceSimilarity.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position of Altered Residues in Flanking Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAlteredPositions(seq1, seq2, desired_seq_size = 21):\n",
    "    \"\"\"\n",
    "    Given two sequences, identify the location of positions that have changed\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seq1, seq2: str\n",
    "        sequences to compare (order does not matter)\n",
    "    desired_seq_size: int\n",
    "        size of the flanking sequence to compare. IMPORTANT, this should not be larger than the available flanking sequence in the ptm_info dataframe\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    altered_positions: list\n",
    "        list of positions that have changed\n",
    "    residue_change: list\n",
    "        list of residues that have changed associated with that position\n",
    "    flank_side: str\n",
    "        indicates which side of the flanking sequence the change has occurred (N-term, C-term, or Both)\n",
    "    \"\"\"\n",
    "    altered_positions = []\n",
    "    residue_change = []\n",
    "    flank_side = []\n",
    "    seq_size = len(seq1)\n",
    "    flank_size = (seq_size -1)/2\n",
    "    if seq_size == len(seq2) and seq_size == desired_seq_size:\n",
    "        for i in range(seq_size):\n",
    "            if seq1[i] != seq2[i]:\n",
    "                altered_positions.append(i-(flank_size))\n",
    "                residue_change.append(f'{seq1[i]}->{seq2[i]}')\n",
    "        #check to see which side flanking sequence\n",
    "        altered_positions = np.array(altered_positions)\n",
    "        n_term = any(altered_positions < 0)\n",
    "        c_term = any(altered_positions > 0)\n",
    "        if n_term and c_term:\n",
    "            flank_side = 'Both'\n",
    "        elif n_term:\n",
    "            flank_side = 'N-term only'\n",
    "        elif c_term:\n",
    "            flank_side = 'C-term only'\n",
    "        else:\n",
    "            flank_side = 'Unclear'\n",
    "        return altered_positions, residue_change, flank_side\n",
    "    else:\n",
    "        return np.nan, np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "altered_flanks = mapper.isoform_ptms[(mapper.isoform_ptms['Conserved Flank (Size = 10)'] == 0) & (mapper.isoform_ptms['Mapping Result'] == 'Success')].copy()\n",
    "altered_flanks = altered_flanks.dropna(subset = 'Alternative Residue')\n",
    "\n",
    "altered_positions = []\n",
    "residue_changes = []\n",
    "flank_side = []\n",
    "for i, row in altered_flanks.iterrows():\n",
    "    alt_flank = row['Flanking Sequence']\n",
    "    ptm = row['Source of PTM']\n",
    "    if ';' in ptm:\n",
    "        ptm = ptm.split(';')[0]\n",
    "    can_flank = mapper.ptm_info.loc[ptm, 'Flanking Sequence']\n",
    "    results = findAlteredPositions(can_flank, alt_flank)\n",
    "    altered_positions.append(results[0])\n",
    "    residue_changes.append(results[1])\n",
    "    flank_side.append(results[2])\n",
    "altered_flanks['Altered_Positions'] = altered_positions\n",
    "altered_flanks['Residue Changes'] = residue_changes\n",
    "altered_flanks[\"Location of Altered Flank\"] = flank_side\n",
    "\n",
    "altered_flanks = altered_flanks[['Isoform ID', 'Source of PTM', 'Flanking Sequence', 'Altered_Positions', 'Residue Changes', 'Location of Altered Flank']]\n",
    "altered_flanks.to_csv(analysis_dir + '/FlankingSequences/PositionOfAlteredFlanks.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_positions = altered_flanks.explode('Altered_Positions')\n",
    "exploded_positions = exploded_positions.groupby('Altered_Positions').size()\n",
    "exploded_positions.name = 'Number of PTMs'\n",
    "exploded_positions.to_csv(analysis_dir + '/FlankingSequences/PositionBreakdown.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kinase Library Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary for converting from kinase library kinase names to kinase names in phosphositeplus\n",
    "kinase_conversion = {'AURKA':'AURA','AURKB':'AURA','AURKC':'AURC','CHEK2':'CHK2','CHEK1':'CHK1','CSNK1A1':'CK1A','CSNK2A1':'CK2A1', 'CSNK2A2':'CK2A2', 'PRKACA':'PKACA',\n",
    "                     'PRKACB':'PKACB','PRKCA':'PKCA','PRKCB':'PKCB','PRKCE':'PKCE','PRKCI': 'PKCI','PRKG2':'PKG2', 'TRPM7':'CHAK1', 'MAPK14':'P38A',\n",
    "                     'MAPK1':'ERK2','MAPK3':'ERK1','RPS6KA1':'P90RSK','PRKCQ':'PKCT','PDPK1':'PDK1', 'PRKAA1':'AMPKA1','PRKAA2':'AMPKA2', 'EIF2AK2':'PKR'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing for Kinase Library Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editSequence(seq):\n",
    "    \"\"\"\n",
    "    Convert flanking sequence to version accepted by kinase library (modified residue denoted by asterick)\n",
    "    \"\"\"\n",
    "    seq = seq.replace('t','t*')\n",
    "    seq = seq.replace('s','s*')\n",
    "    return seq\n",
    "\n",
    "def identify_flanks_for_KinaseLibrary(mapper, ks_dataset):\n",
    "    \"\"\"\n",
    "    Using the mapper object data, identify PTMs with altered flanking sequences, which by default will restrict to ptms with at least one known kinase interaction and a conserved tryptic fragment (would be missed by MS)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mapper : PTMmapper.Mapper\n",
    "        Mapper object with data already processed\n",
    "    ks_dataset : pandas.DataFrame\n",
    "        Dataframe with kinase-substrate interactions, downloaded from phosphositeplus\n",
    "    \"\"\"\n",
    "    if 'Conserved Flank' not in mapper.isoform_ptms.columns:\n",
    "        mapper.isoform_ptms['Conserved Flank'] = mapper.compareAllFlankSeqs(flank_size = 5)\n",
    "    if 'Conserved Fragment' not in mapper.isoform_ptms.columns:\n",
    "        mapper.isoform_ptms['Conserved Fragment'] = mapper.compareAllTrypticFragments()\n",
    "\n",
    "    #extract ptms with altered flank sequences\n",
    "    conserved = mapper.isoform_ptms[mapping.isoform_ptms['Mapping Result'] == 'Success']\n",
    "\n",
    "    conserved = conserved[(conserved['Conserved Fragment'] == 1) & (conserved['Conserved Flank (Size = 5)'] == 0)]\n",
    "\n",
    "\n",
    "    #restrict to phosphorylation sites\n",
    "    conserved = conserved[(conserved['Modification'].str.contains('Phospho'))]\n",
    "    conserved = conserved.drop_duplicates(subset = ['Source of PTM', 'Flanking Sequence'])\n",
    "\n",
    "    #if requested, restrict to known kinase-substrate interactions\n",
    "\n",
    "    #restrict to human interactions\n",
    "    ks_dataset = ks_dataset[(ks_dataset['KIN_ORGANISM'] == 'human') & (ks_dataset['SUB_ORGANISM'] == 'human')].copy()\n",
    "    #inner merge kinase-substrate info with conserved flank info\n",
    "    ks_dataset['Source of PTM'] = ks_dataset['SUB_ACC_ID']+'_'+ks_dataset['SUB_MOD_RSD']\n",
    "    conserved = conserved.merge(ks_dataset, on = 'Source of PTM')\n",
    "\n",
    "    #extract only the columns with relevant info\n",
    "    conserved = conserved[['Isoform ID', 'Source of PTM', 'GENE', 'Flanking Sequence']].drop_duplicates()\n",
    "    conserved = conserved.rename({'Flanking Sequence':'Alternative Sequence'}, axis = 1)\n",
    "    #add canonical flanking sequence to data\n",
    "    canonical_sequence = mapper.ptm_info['Flanking Sequence'].reset_index().rename({'index':'PTM', 'Flanking Sequence':'Canonical Sequence'}, axis = 1)\n",
    "    conserved = conserved.merge(canonical_sequence, right_on = 'PTM', left_on = 'Source of PTM', how = 'left')\n",
    "    \n",
    "    return conserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load kinase-substrate interactions\n",
    "ks_dataset = pd.read_csv(figshare_dir + '/External_Data/PhosphoSitePlus/Kinase_Substrate_Dataset.tsv', sep = '\\t')\n",
    "\n",
    "#get flanking sequences to use for kinase library analysis \n",
    "flanking_sequences = identify_flanks_for_KinaseLibrary(mapper, ks_dataset)\n",
    "\n",
    "#save data\n",
    "if not os.path.exists(figshare_dir + '/Analysis_For_Paper/FlankingSequences/Kinase_Library'):\n",
    "    os.mkdir(figshare_dir + '/Analysis_For_Paper/FlankingSequences/Kinase_Library')\n",
    "flanking_sequences.to_csv(figshare_dir + '/Analysis_For_Paper/FlankingSequences/Kinase_Library/sequences_to_analyze.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Kinase Library Results\n",
    "\n",
    "Kinase library analysis outputs a single file for each flanking sequence, containing scores for all kinases for the given flanking sequence. We processed these files in order to merge the information into a single file. \n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "flanking_sequences = pd.read_csv(figshare_dir + '/Analysis_For_Paper/FlankingSequences/Kinase_Library/sequences_to_analyze.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = figshare_dir + '/Analysis_For_Paper/FlankingSequences/Kinase_Library/Results/'\n",
    "\n",
    "#initialize empty dataframe\n",
    "kl_data = pd.DataFrame()\n",
    "#iterate through all ptms analzyed\n",
    "for _, row in flanking_sequences.iterrows():\n",
    "    kinase = row['GENE']\n",
    "    ptm = row['Source of PTM']\n",
    "    isoform = row['Isoform ID']\n",
    "    if os.path.isfile(f'{path}/{ptm}/{ptm}_Can.tsv') and os.path.isfile(f'{path}/{ptm}/{isoform}_{row[\"Source of PTM\"].split(\"_\")[1]}_Alt.tsv'):\n",
    "        #get canonical information\n",
    "        canonical = pd.read_csv(f'{path}/{ptm}/{ptm}_Can.tsv', sep = '\\t',index_col = 0)\n",
    "        #add additional context\n",
    "        canonical['PTM'] = ptm\n",
    "        canonical['Type'] = 'Canonical'\n",
    "        canonical['Known Interaction'] = 'No'\n",
    "        #reset index\n",
    "        canonical = canonical.reset_index()\n",
    "        \n",
    "        #get alternative isoform\n",
    "        alternative = pd.read_csv(f'{path}/{ptm}/{isoform}_{row[\"Source of PTM\"].split(\"_\")[1]}_Alt.tsv', sep = '\\t', index_col = 0)\n",
    "        #add additional context\n",
    "        alternative['PTM'] = ptm\n",
    "        alternative['Type'] = 'Alternative'\n",
    "        alternative['ID'] = isoform\n",
    "        alternative['Known Interaction'] = 'No'\n",
    "        #reset index\n",
    "        alternative = alternative.reset_index()\n",
    "        \n",
    "        #combine canonical and alternative data\n",
    "        kl_data = pd.concat([kl_data, canonical, alternative])\n",
    "\n",
    "#remove rows\n",
    "\n",
    "#add whether the ptm/kinase pair is known interaction (based on phosphositeplus data)\n",
    "for i, row in flanking_sequences.iterrows():\n",
    "    ptm = row['Source of PTM']\n",
    "    kinase = row['GENE']\n",
    "    if kinase not in kl_data['kinase'].unique() and ptm.split('_')[1][0] != 'Y':\n",
    "        kinase = kinase_conversion[kinase]\n",
    "        \n",
    "    kl_data.loc[(kl_data['PTM'] == ptm) & (kl_data['kinase'] == kinase), 'Known Interaction'] = 'Yes'\n",
    "    \n",
    "kl_data = kl_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'site_percentile'\n",
    "#scores\n",
    "canonical_scores = kl_data.loc[kl_data['Type'] == 'Canonical', ['PTM','kinase', metric, 'Known Interaction']]\n",
    "canonical_scores = canonical_scores.rename({metric: 'Canonical Percentile'}, axis = 1)\n",
    "    \n",
    "alternative_scores = kl_data.loc[kl_data['Type'] == 'Alternative', ['ID', 'PTM', 'kinase', metric, 'Known Interaction']]\n",
    "alternative_scores = alternative_scores.rename({metric: 'Alternative Percentile'}, axis = 1)\n",
    "\n",
    "scores = canonical_scores.merge(alternative_scores, on = ['kinase', 'PTM', 'Known Interaction'], how = 'outer')\n",
    "scores['Change'] = scores['Alternative Percentile'] - scores['Canonical Percentile']\n",
    "\n",
    "scores.to_csv(figshare_dir + '/Analysis_For_Paper/FlankingSequences/Kinase_Library/kinase_library_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESRP1-mediated Splicing in Prostate Cancer\n",
    "\n",
    "The following code was used in the analysis of how ESRP1-mediated splicing is altered in prostate cancer and leads to changes the presence/absence of different PTMs. This analysis was used to generate Figure 4.\n",
    "\n",
    "[Return to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecting PTMs onto SpliceSeq Exons\n",
    "\n",
    "Here, we used data from the genomic coordinates of different ptms obtained from the projection pipeline to determine which PTMs are present in SpliceSeq splicegraph exons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load splicegraph from SpliceSeq\n",
    "splicegraph = pd.read_csv(database_dir + '/TCGA/TCGASpliceSeq_splicegraph.txt', delim_whitespace=True)\n",
    "\n",
    "\n",
    "splicegraph_ptms = None\n",
    "#iterate through all ptms and project them onto the splicegraph (breaking up the data by chromosome and strand)\n",
    "for chromosome in mapper.ptm_coordinates['Chromosome/scaffold name'].unique():\n",
    "    for strand in mapper.ptm_coordinates['Strand'].unique():\n",
    "        if strand == -1:\n",
    "            sg_strand = '-'\n",
    "        else:\n",
    "            sg_strand = '+'\n",
    "        #grab splicegraph exons and ptms associated with the same chromosome/strand as the ptm\n",
    "        trim_sg = splicegraph[(splicegraph['Chromosome'] == chromosome) & (splicegraph['Strand'] == sg_strand)]\n",
    "        trim_ptms = mapper.ptm_coordinates[(mapper.ptm_coordinates['Chromosome/scaffold name'] == chromosome) & (mapper.ptm_coordinates['Strand'] == strand)]\n",
    "        #iterate through all ptms on the chromosome/strand and project the ptms onto the splicegraph exons\n",
    "        for i,row in trim_ptms.iterrows():\n",
    "            sg_exons = trim_sg[(trim_sg['Chr_Start'] <= row['HG19 Location']) & (trim_sg['Chr_Stop'] >= row['HG19 Location'])].copy()\n",
    "            sg_exons['PTM'] = row['Source of PTM']\n",
    "            if splicegraph_ptms is None:\n",
    "                splicegraph_ptms = sg_exons.copy()\n",
    "            else:\n",
    "                splicegraph_ptms = pd.concat([splicegraph_ptms, sg_exons])\n",
    "\n",
    "\n",
    "#save data\n",
    "splicegraph_ptms.to_csv(analysis_dir + '/TCGA/splicegraph_PTMs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify differentially included PTM-containing exons\n",
    "\n",
    "Using percent spliced in (PSI) data downloaded from TCGASpliceSeq, we identified exons that are differentially included in ESRP1-high or ESRP1-low prostate cancer samples. We then determined which of these exons contain PTMs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_58072\\1945944182.py:21: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mapped_ptms = pd.read_csv(analysis_dir + '/TCGA/splicegraph_PTMs.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ESRP1 low patients:  61\n",
      "Number of ESRP1 high patients:  69\n"
     ]
    }
   ],
   "source": [
    "tissue = 'PRAD'\n",
    "#load ESRP1 expression data\n",
    "ESRP1 = pd.read_csv(database_dir + f\"/TCGA/{tissue}/{tissue}_ESRP1_expression.txt\", sep = '\\t') # Z-score of ESPR1 \n",
    "ESRP1 = ESRP1.dropna(subset = 'ESRP1')\n",
    "\n",
    "#load percent spliced in data from TCGA SpliceSeq, restrict to exon skipping and alternative splice site events with PSI variation of at least 0.25 across all patients\n",
    "PRAD = pd.read_csv(database_dir + f\"/TCGA/{tissue}/PSI_download_{tissue}.txt\", sep = '\\t') # PSI data\n",
    "PRAD = PRAD[PRAD['splice_type'].isin(['ES','RI','AD','AA'])].copy()\n",
    "PRAD = PRAD[PRAD['psi_range'] > 0.25].copy()\n",
    "\n",
    "#remove patients with no measured ESRP1 mRNA from splice data, or vice versa\n",
    "ESRP1['Edited Patient ID'] = ESRP1['SAMPLE_ID'].apply(lambda x: '_'.join(x.split('-')[0:3])).to_list()\n",
    "patients_to_drop = [col for col in PRAD.columns if col not in ESRP1['Edited Patient ID'].values and 'TCGA' in col]\n",
    "PRAD = PRAD.drop(patients_to_drop, axis = 1)\n",
    "\n",
    "#remove patients with no measured splice data from ESRP1 data\n",
    "patients_to_drop = [col for col in ESRP1['Edited Patient ID'] if col not in PRAD.columns]\n",
    "ESRP1 = ESRP1[~ESRP1['Edited Patient ID'].isin(patients_to_drop)].copy()\n",
    "\n",
    "#grab PTMs mapped onto SpliceSeq splicegraph\n",
    "mapped_ptms = pd.read_csv(analysis_dir + '/TCGA/splicegraph_PTMs.csv')\n",
    "#Percent Spliced In data\n",
    "spliceseq = pd.read_csv(database_dir + \"/TCGA/TCGASpliceSeq_splicegraph.txt\", delim_whitespace=True) \n",
    "\n",
    "\n",
    "## Identify patients with high or low ESRP1 expression\n",
    "ESPR_low = ESRP1[ESRP1[\"ESRP1\"] < -1]\n",
    "ESPR_low_id = ESPR_low[\"SAMPLE_ID\"].str.split(\"-\").apply(lambda x: x[0:3]).apply(lambda x: '_'.join(x)).to_list()\n",
    "ESPR_high = ESRP1[ESRP1[\"ESRP1\"] > 1]\n",
    "ESPR_high_id = ESPR_high[\"SAMPLE_ID\"].str.split(\"-\").apply(lambda x: x[0:3]).apply(lambda x: '_'.join(x)).to_list()\n",
    "print('Number of ESRP1 low patients: ', len(ESPR_low_id))\n",
    "print('Number of ESRP1 high patients: ', len(ESPR_high_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold indexes of PSI data where values are statistically significant + if mean is higher than other group place it in that group. \n",
    "direction = [] \n",
    "p_list = []\n",
    "effect_list =[]\n",
    "for index, row in PRAD.iterrows():\n",
    "    #get list of ESRP1-high and ESRP1-low samples\n",
    "    high_sample = PRAD.loc[index, ESPR_high_id].values\n",
    "    high_sample = list(high_sample[~pd.isnull(high_sample)])\n",
    "    low_sample = PRAD.loc[index, ESPR_low_id].values\n",
    "    low_sample = list(low_sample[~pd.isnull(low_sample)])\n",
    "    \n",
    "    #calculate Mann Whitney p-value and effect size comparing ESRP1-high and low PSI values\n",
    "    if len(low_sample) > 1 and len(high_sample) > 1:\n",
    "        p_value, effect_size = stat_utils.calculateMW_EffectSize(high_sample, low_sample)\n",
    "    else:\n",
    "        p_value = np.nan\n",
    "    p_list.append(p_value)\n",
    "    effect_list.append(effect_size)\n",
    "    \n",
    "    #Determine whether ESRP1-high or low samples have higher PSI values (based on mean)\n",
    "    if p_value != p_value:\n",
    "        direction.append(np.nan)\n",
    "    elif np.mean(high_sample) > np.mean(low_sample):\n",
    "        direction.append('High')\n",
    "    else: \n",
    "        direction.append('Low')\n",
    "        \n",
    "#save results to dataframe\n",
    "PRAD['ESRP1'] = direction\n",
    "PRAD['p'] = p_list\n",
    "PRAD['Effect Size'] = effect_list\n",
    "PRAD = PRAD.dropna(subset = 'p')\n",
    "\n",
    "#adjust p-values using Benjamini-Hochberg method\n",
    "PRAD = PRAD.sort_values(by = 'p', ascending = True)\n",
    "PRAD['Adj p'] = stat_utils.adjustP(PRAD['p'].values)\n",
    "\n",
    "#add PTMs to differentially included exons\n",
    "PRAD_ptms = PRAD.copy()\n",
    "#remove mutually exclusive exon events from analysis\n",
    "PRAD_ptms = PRAD_ptms[~PRAD_ptms['exons'].apply(lambda x: '|' in x)]\n",
    "#separate exons in events with multiple exons\n",
    "PRAD_ptms['exons'] = PRAD_ptms[\"exons\"].apply(lambda x: x.split(':'))\n",
    "PRAD_ptms = PRAD_ptms.explode('exons').drop_duplicates(subset = ['symbol','exons','ESRP1','p'])\n",
    "PRAD_ptms['exons'] = PRAD_ptms['exons'].astype(float)\n",
    "#merge with mapped PTMs\n",
    "PRAD_ptms = PRAD_ptms.merge(mapped_ptms, left_on = ['symbol','exons'], right_on = ['Symbol', 'Exon'])\n",
    "PRAD_ptms = PRAD_ptms.sort_values(by = 'Adj p')\n",
    "PRAD_ptms = PRAD_ptms.drop_duplicates(subset = ['PTM', 'ESRP1'])\n",
    "\n",
    "#save data\n",
    "PRAD_ptms.to_csv(analysis_dir + f'/TCGA/{tissue}_ESRP1_PTMs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene set enrichment of ESRP1-correlated genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gseapy\n",
    "from gseapy import enrichr\n",
    "\n",
    "#load prostate data\n",
    "PRAD_ptms = pd.read_csv(analysis_dir + f'/TCGA/PRAD_ESRP1_PTMs.csv')\n",
    "sig_ptms = PRAD_ptms[(PRAD_ptms['Adj p'] <= 0.05) & (PRAD_ptms['Effect Size'] >= 0.25)].copy()\n",
    "sig_ptms = sig_ptms.drop_duplicates(subset = ['PTM', 'ESRP1'])\n",
    "sig_ptms = sig_ptms.drop_duplicates(subset = 'PTM', keep = False) #remove PTMs that are significant in both directions\n",
    "\n",
    "#run enrichr analysis\n",
    "gene_set_names = {'GO_Cellular_Component_2023':'GO Cellular Component', 'GO_Molecular_Function_2023':'GO Molecular Function', 'GO_Biological_Process_2023':'GO Biological Process', 'KEGG_2021_Human':'KEGG Pathways'}\n",
    "enrichr_results = enrichr(list(sig_ptms['symbol'].unique()), background = list(PRAD_ptms['symbol'].unique()), gene_sets = list(gene_set_names.keys()), organism='human').results\n",
    "enrichr_results['Gene Set Title'] = enrichr_results['Gene_set'].apply(lambda x: gene_set_names[x])\n",
    "\n",
    "#save data\n",
    "if not os.path.exists(analysis_dir + '/TCGA/Enrichment'):\n",
    "    os.mkdir(analysis_dir + '/TCGA/Enrichment')\n",
    "enrichr_results.to_csv(analysis_dir + '/TCGA/Enrichment/Gene_Set_Enrichr.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site enrichment of ESRP1-correlated PTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load annotation data\n",
    "annotations = pd.read_csv(database_dir + '/PhosphoSitePlus/Regulatory_sites.gz', sep = '\\t',compression = 'gzip', on_bad_lines='skip', header = 2)\n",
    "annotations['Substrate'] = annotations['ACC_ID'] + '_' + annotations['MOD_RSD'].apply(lambda x: x.split('-')[0])\n",
    "\n",
    "\n",
    "#load prostate data\n",
    "PRAD_ptms = pd.read_csv(analysis_dir + f'/TCGA/PRAD_ESRP1_PTMs.csv')\n",
    "sig_ptms = PRAD_ptms[(PRAD_ptms['Adj p'] <= 0.05) & (PRAD_ptms['Effect Size'] >= 0.25)].copy()\n",
    "sig_ptms = sig_ptms.drop_duplicates(subset = ['PTM', 'ESRP1'])\n",
    "sig_ptms = sig_ptms.drop_duplicates(subset = 'PTM', keep = False) #remove PTMs that are significant in both directions\n",
    "\n",
    "#get function enrichment\n",
    "functions = stat_utils.constructPivotTable(PRAD_ptms, annotations, reference_col = 'ON_FUNCTION', collapse_on_similar=True)\n",
    "function_enrichment = stat_utils.generate_site_enrichment(sig_ptms['PTM'].unique(), functions, subset_name = 'ESRP1-Regulated', type = 'Function')\n",
    "processes = stat_utils.constructPivotTable(PRAD_ptms, annotations, reference_col = 'ON_PROCESS', collapse_on_similar=True)\n",
    "process_enrichment = stat_utils.generate_site_enrichment(sig_ptms['PTM'].unique(), processes, subset_name = 'ESRP1-Regulated', type = 'Process')\n",
    "\n",
    "\n",
    "#save data\n",
    "if not os.path.exists(analysis_dir + '/TCGA/Enrichment'):\n",
    "    os.mkdir(analysis_dir + '/TCGA/Enrichment')\n",
    "\n",
    "function_enrichment.to_csv(analysis_dir + '/TCGA/Enrichment/Site_Function_Enrichment.csv')\n",
    "process_enrichment.to_csv(analysis_dir + '/TCGA/Enrichment/Site_Process_Enrichment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kinase Enrichment of ESRP1-correlated Substrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load splice seq data\n",
    "prostate = pd.read_csv(analysis_dir + '/TCGA/Prad_ESRP1_PTMs.csv')\n",
    "\n",
    "#add modification information\n",
    "prostate = prostate.merge(mapper.ptm_info['Modification'].reset_index(), on='PTM')\n",
    "\n",
    "#get significant prostate\n",
    "sig_prostate = prostate[(prostate['Adj p'] < 0.05) & (prostate['Effect Size'] >= 0.25)]\n",
    "\n",
    "#separate unique modifications into unique rows so that data can be restricted to phosphotyrosine or phosphoserine/threonine\n",
    "exploded_prostate = prostate.copy()\n",
    "exploded_prostate['Modification'] = exploded_prostate['Modification'].str.split(';')\n",
    "exploded_prostate = exploded_prostate.explode('Modification')\n",
    "\n",
    "#get sig\n",
    "exploded_sig_prostate = exploded_prostate[(exploded_prostate['Adj p'] < 0.05) & (exploded_prostate['Effect Size'] >= 0.25)]\n",
    "\n",
    "#restrict to phosphotyrosine data\n",
    "sig_prostate_y = exploded_sig_prostate[exploded_sig_prostate['Modification'] == 'Phosphotyrosine']\n",
    "prostate_y = exploded_prostate[exploded_prostate['Modification'] == 'Phosphotyrosine']\n",
    "\n",
    "#restrict to phosphoserine/threonine data\n",
    "sig_prostate_st = exploded_sig_prostate[exploded_sig_prostate['Modification'].isin(['Phosphoserine', 'Phosphothreonine'])]\n",
    "prostate_st = exploded_prostate[exploded_prostate['Modification'].isin(['Phosphoserine', 'Phosphothreonine'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Known Substrates from PhosphoSitePlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load known kinases from PhosphoSitePlus\n",
    "ks_dataset = pd.read_csv(database_dir + '/PhosphoSitePlus/Kinase_Substrate_Dataset.tsv', sep ='\\t')\n",
    "ks_dataset = ks_dataset[(ks_dataset['KIN_ORGANISM'] == 'human') & (ks_dataset['KIN_ORGANISM'] == 'human')]\n",
    "ks_dataset['PTM'] = ks_dataset['SUB_ACC_ID']+'_'+ks_dataset['SUB_MOD_RSD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phosphotyrosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add annotations info to esrp1-regulated phosphotyrosines\n",
    "prostate_known = prostate_y.merge(ks_dataset[['GENE','PTM']], on = 'PTM')\n",
    "sig_prostate_known = sig_prostate_y.merge(ks_dataset[['GENE','PTM']], on = 'PTM')\n",
    "\n",
    "#iterate through each kinase and perform enrichment for substrates using hypergeometric test\n",
    "results = pd.DataFrame(np.nan, index = sig_prostate_known['GENE'].unique(), columns = ['k','n','M','N','p'])\n",
    "for kinase in sig_prostate_known['GENE'].unique():\n",
    "    #get numbers for a hypergeometric test to look for enrichment of kinase substrates\n",
    "    k = sig_prostate_known[sig_prostate_known['GENE'] == kinase].shape[0]\n",
    "    n = prostate_known[prostate_known['GENE'] == kinase].shape[0]\n",
    "    M = prostate_y.shape[0]\n",
    "    N = sig_prostate_y.shape[0]\n",
    "\n",
    "    #run hypergeometric test\n",
    "    from scipy.stats import hypergeom\n",
    "    results.loc[kinase,'p'] = hypergeom.sf(k-1, M, n, N)\n",
    "    results.loc[kinase, 'M'] = M\n",
    "    results.loc[kinase, 'N'] = N\n",
    "    results.loc[kinase, 'k'] = k\n",
    "    results.loc[kinase, 'n'] = n\n",
    "\n",
    "results.to_csv(analysis_dir + '/TCGA/Enrichment/tyrosine_kinase_enrichment_known.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phosphoserines/threonines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restrict to phosphotyrosine data\n",
    "prostate_known = prostate_st.merge(ks_dataset[['GENE','PTM']], on = 'PTM')\n",
    "sig_prostate_known = sig_prostate_st.merge(ks_dataset[['GENE','PTM']], on = 'PTM')\n",
    "\n",
    "results = pd.DataFrame(np.nan, index = sig_prostate_known['GENE'].unique(), columns = ['k','n','M','N','p'])\n",
    "for kinase in sig_prostate_known['GENE'].unique():\n",
    "    #get numbers for a hypergeometric test to look for enrichment of kinase substrates\n",
    "    k = sig_prostate_known[sig_prostate_known['GENE'] == kinase].shape[0]\n",
    "    n = prostate_known[prostate_known['GENE'] == kinase].shape[0]\n",
    "    M = prostate_st.shape[0]\n",
    "    N = sig_prostate_st.shape[0]\n",
    "\n",
    "    #run hypergeometric test\n",
    "    from scipy.stats import hypergeom\n",
    "    results.loc[kinase,'p'] = hypergeom.sf(k-1, M, n, N)\n",
    "    results.loc[kinase, 'M'] = M\n",
    "    results.loc[kinase, 'N'] = N\n",
    "    results.loc[kinase, 'k'] = k\n",
    "    results.loc[kinase, 'n'] = n\n",
    "\n",
    "results = results.sort_values(by = 'p', ascending = False)\n",
    "results.to_csv(analysis_dir + '/TCGA/Enrichment/st_kinase_enrichment_known.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KSTAR Predicted Kinase Substrate Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "from kstar import config\n",
    "\n",
    "#location of figshare data\n",
    "figshare_dir = 'C:/Users/Sam/OneDrive/Documents/GradSchool/Research/Splicing/Paper_Prep/PTM_Splicing_FigShare/'\n",
    "#where to find projected PTMs\n",
    "ptm_data_dir = figshare_dir + 'PTM_Projection_Data/'\n",
    "#where to find information from different databases\n",
    "database_dir = figshare_dir + 'External_Data/'\n",
    "#where analysis data will be saved\n",
    "analysis_dir = figshare_dir + 'Analysis_For_Paper/'\n",
    "\n",
    "#load ptm info\n",
    "ptm_info = pd.read_csv(ptm_data_dir + '/processed_data_dir/ptm_info.csv', index_col = 0)\n",
    "\n",
    "#load splice seq data\n",
    "prostate = pd.read_csv(analysis_dir + '/TCGA/Prad_ESRP1_PTMs.csv')\n",
    "\n",
    "#add modification information\n",
    "prostate = prostate.merge(ptm_info['Modification'].reset_index(), on='PTM')\n",
    "\n",
    "#get significant prostate\n",
    "sig_prostate = prostate[(prostate['Adj p'] < 0.05) & (prostate['Effect Size'] >= 0.25)]\n",
    "\n",
    "#separate unique modifications into unique rows so that data can be restricted to phosphotyrosine or phosphoserine/threonine\n",
    "exploded_prostate = prostate.copy()\n",
    "exploded_prostate['Modification'] = exploded_prostate['Modification'].str.split(';')\n",
    "exploded_prostate = exploded_prostate.explode('Modification')\n",
    "\n",
    "#get sig\n",
    "exploded_sig_prostate = exploded_prostate[(exploded_prostate['Adj p'] < 0.05) & (exploded_prostate['Effect Size'] >= 0.25)]\n",
    "\n",
    "#restrict to phosphotyrosine data\n",
    "sig_prostate_y = exploded_sig_prostate[exploded_sig_prostate['Modification'] == 'Phosphotyrosine']\n",
    "prostate_y = exploded_prostate[exploded_prostate['Modification'] == 'Phosphotyrosine']\n",
    "\n",
    "#restrict to phosphoserine/threonine data\n",
    "sig_prostate_st = exploded_sig_prostate[exploded_sig_prostate['Modification'].isin(['Phosphoserine', 'Phosphothreonine'])]\n",
    "prostate_st = exploded_prostate[exploded_prostate['Modification'].isin(['Phosphoserine', 'Phosphothreonine'])]\n",
    "\n",
    "#grab networks \n",
    "networks = {}\n",
    "networks['Y'] =pickle.load(open(config.NETWORK_Y_PICKLE, \"rb\" ) )\n",
    "networks['ST'] = pickle.load(open(config.NETWORK_ST_PICKLE, \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions for calculating enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enrichment_single_network(network, prostate, sig_prostate, type = 'All'):\n",
    "    \"\"\"\n",
    "    Given prostate data and a single kstar network, get enrichment for each kinase in the network in the prostate data. Assumes the prostate data has already been reduced to the modification of interest (phosphotyrosine or phoshoserine/threonine)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    network : pandas dataframe\n",
    "        kstar network\n",
    "    prostate : pandas dataframe\n",
    "        all PTMs identified in tCGA prostate data, regardless of significance (reduced to only include mods of interest)\n",
    "    sig_prostate : pandas dataframe\n",
    "        significant PTMs identified in tCGA prostate data, p < 0.05 and effect size > 0.25 (reduced to only include mods of interest)\n",
    "    \"\"\"\n",
    "    network['PTM'] = network['KSTAR_ACCESSION'] + '_' + network['KSTAR_SITE']\n",
    "    #if focusing high or low groups restrict to those, otherwise add network informatin to sig prostate without changing\n",
    "    if type == 'All':\n",
    "        sig_prostate_kstar = sig_prostate.merge(network[['KSTAR_KINASE','PTM']], on = 'PTM')\n",
    "    elif type == 'High':\n",
    "        sig_prostate = sig_prostate[sig_prostate['ESRP1'] == 'High']\n",
    "        sig_prostate_kstar = sig_prostate.merge(network[['KSTAR_KINASE','PTM']], on = 'PTM')\n",
    "    elif type == 'Low':\n",
    "        sig_prostate = sig_prostate[sig_prostate['ESRP1'] == 'Low']\n",
    "        sig_prostate_kstar = sig_prostate.merge(network[['KSTAR_KINASE','PTM']], on = 'PTM')\n",
    "\n",
    "    #add network information to all prostate data\n",
    "    prostate_kstar = prostate.merge(network[['KSTAR_KINASE','PTM']], on = 'PTM')\n",
    "\n",
    "    results = pd.DataFrame(np.nan, index = sig_prostate_kstar['KSTAR_KINASE'].unique(), columns = ['k','n','M','N','p'])\n",
    "    for kinase in sig_prostate_kstar['KSTAR_KINASE'].unique():\n",
    "        #get numbers for a hypergeometric test to look for enrichment of kinase substrates\n",
    "        k = sig_prostate_kstar[sig_prostate_kstar['KSTAR_KINASE'] == kinase].shape[0]\n",
    "        n = prostate_kstar[prostate_kstar['KSTAR_KINASE'] == kinase].shape[0]\n",
    "        M = prostate.shape[0]\n",
    "        N = sig_prostate.shape[0]\n",
    "\n",
    "        #run hypergeometric test\n",
    "        results.loc[kinase,'p'] = hypergeom.sf(k-1, M, n, N)\n",
    "        results.loc[kinase, 'M'] = M\n",
    "        results.loc[kinase, 'N'] = N\n",
    "        results.loc[kinase, 'k'] = k\n",
    "        results.loc[kinase, 'n'] = n\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_enrichment_all_networks(networks, prostate, sig_prostate, type = 'All'):\n",
    "    \"\"\"\n",
    "    Given prostate data and a dictionary of kstar networks, get enrichment for each kinase in each network in the prostate data. Assumes the prostate data has already been reduced to the modification of interest (phosphotyrosine or phoshoserine/threonine)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    networks : dict\n",
    "        dictionary of kstar networks\n",
    "    prostate : pandas dataframe\n",
    "        all PTMs identified in tCGA prostate data, regardless of significance (reduced to only include mods of interest)\n",
    "    sig_prostate : pandas dataframe\n",
    "        significant PTMs identified in tCGA prostate data, p < 0.05 and effect size > 0.25 (reduced to only include mods of interest)\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for network in networks:\n",
    "        results[network] = get_enrichment_single_network(networks[network], prostate, sig_prostate, type = type)\n",
    "    return results\n",
    "\n",
    "def extract_enrichment(results):\n",
    "    \"\"\"\n",
    "    Given a dictionary of results from get_enrichment_all_networks, extract the p-values for each network and kinase, and then calculate the median p-value across all networks for each kinase\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : dict\n",
    "        dictionary of results from get_enrichment_all_networks\n",
    "    \"\"\"\n",
    "    enrichment = pd.DataFrame(index = results['nkin0'].index, columns = results.keys())\n",
    "    for network in results:\n",
    "        enrichment[network] = results[network]['p']\n",
    "    enrichment['median'] = enrichment.median(axis = 1)\n",
    "    return enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phosphotyrosines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restrict to phosphotyrosine data\n",
    "sig_prostate_y = exploded_sig_prostate[exploded_sig_prostate['Modification'] == 'Phosphotyrosine']\n",
    "prostate_y = exploded_prostate[exploded_prostate['Modification'] == 'Phosphotyrosine']\n",
    "\n",
    "\n",
    "#combined median values for each group\n",
    "median_y = pd.DataFrame(index = networks['Y']['nkin0'][\"KSTAR_KINASE\"].unique(), columns = ['All','High','Low'])\n",
    "\n",
    "#run enrichment on all networks\n",
    "for type in ['All', 'High', 'Low']:\n",
    "    results_y = get_enrichment_all_networks(networks['Y'], prostate_y, sig_prostate_y, type = type)\n",
    "\n",
    "    #extract enrichment\n",
    "    enrichment_y = extract_enrichment(results_y)\n",
    "    median_y[type] = enrichment_y['median']\n",
    "\n",
    "median_y.to_csv(analysis_dir + '/TCGA/Enrichment/tyrosine_kinase_enrichment_predicted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serine/threonines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_prostate_st = exploded_sig_prostate[exploded_sig_prostate['Modification'].isin(['Phosphoserine', 'Phosphothreonine'])]\n",
    "prostate_st = exploded_prostate[exploded_prostate['Modification'].isin(['Phosphoserine', 'Phosphothreonine'])]\n",
    "\n",
    "#combined median values for each group\n",
    "median_st = pd.DataFrame(index = networks['ST']['nkin0'][\"KSTAR_KINASE\"].unique(), columns = ['All','High','Low'])\n",
    "\n",
    "#run enrichment on all networks\n",
    "for type in ['All', 'High', 'Low']:\n",
    "    results_st = get_enrichment_all_networks(networks['ST'], prostate_st, sig_prostate_st, type = type)\n",
    "\n",
    "    #extract enrichment\n",
    "    enrichment_st = extract_enrichment(results_st)\n",
    "    median_st[type] = enrichment_st['median']\n",
    "\n",
    "median_st.to_csv(analysis_dir + '/TCGA/Enrichment/st_kinase_enrichment_predicted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate ESRP1-Regulated SGK substrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kstar.analysis import interactions\n",
    "\n",
    "# load known kinases from PhosphoSitePlus\n",
    "ks_dataset = pd.read_csv(database_dir + '/PhosphoSitePlus/Kinase_Substrate_Dataset.tsv', sep ='\\t')\n",
    "ks_dataset = ks_dataset[(ks_dataset['KIN_ORGANISM'] == 'human') & (ks_dataset['KIN_ORGANISM'] == 'human')]\n",
    "ks_dataset['PTM'] = ks_dataset['SUB_ACC_ID']+'_'+ks_dataset['SUB_MOD_RSD']\n",
    "\n",
    "#extract phosphoserines with higher inclusion in ESRP1-high patients\n",
    "high_sig = sig_prostate_st[sig_prostate_st['ESRP1'] == 'High'].copy()\n",
    "high_sig['data:sig_ptms'] = 1\n",
    "high_sig.rename({'PTM':'KSTAR_SUBSTRATE'},  axis = 1, inplace = True)\n",
    "high_sig['KSTAR_SITE'] = high_sig['KSTAR_SUBSTRATE'].apply(lambda x: x.split('_')[1])\n",
    "high_sig['KSTAR_ACCESSION'] = high_sig['KSTAR_SUBSTRATE'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "#get substrate influence on prediction\n",
    "kinase = 'SGK1'\n",
    "experiment_influence = interactions.getSubstrateInfluence_inExperiment(networks['ST'], high_sig, kinase)\n",
    "\n",
    "#process and annotate known substrates\n",
    "known_kin = ks_dataset[ks_dataset['GENE'] == kinase]\n",
    "sub_data = experiment_influence['data:sig_ptms'].reset_index()\n",
    "sub_data['UniProt_ID'] = sub_data['index'].apply(lambda x: x.split('_')[0])\n",
    "sub_data['Site'] = sub_data['index'].apply(lambda x: x.split('_')[1])\n",
    "sub_data = sub_data.merge(known_kin['PTM'], left_on = ['index'], right_on = ['PTM'], how = 'left')\n",
    "sub_data[\"Known\"] = sub_data[\"PTM\"].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "sub_data = sub_data.drop('PTM', axis = 1)\n",
    "\n",
    "#save data\n",
    "sub_data.to_csv(analysis_dir + f'/TCGA/Enrichment/ESRP1_Regulated_SGK1_Substrates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of PTMs in Canonical and Alternative UniProt Isoforms\n",
    "\n",
    "Using data from ProteomeScout, assessed how many PTMs are annotated in the canonical and alternative UniProtKB isoform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isoforms = config.translator[config.translator['Uniprot Canonical'] == type]\n",
    "\n",
    "isoform_info = {}\n",
    "isoform_ptms = {}\n",
    "\n",
    "for type in ['Canonical', 'Alternative']:\n",
    "    info_list = []\n",
    "    df_list = []\n",
    "    for i, row in isoforms.iterrows():\n",
    "        #if canonical, use normal uniprot id (i.e no '-1' at end)\n",
    "        if type == 'Canonical':\n",
    "            isoform_id = row['UniProtKB/Swiss-Prot ID']\n",
    "        else:\n",
    "            isoform_id = row['UniProtKB isoform ID']\n",
    "            \n",
    "        transcript_id = row['Transcript stable ID']\n",
    "        #find ptms associated with isoform\n",
    "        ptm_df = find_ptms(isoform_id, transcript_id)\n",
    "\n",
    "        #get summary info about each isoform\n",
    "        isoform_info = findIsoformInfo(ptm_df, isoform_id, transcript_id)\n",
    "        if isoform_info is not None:\n",
    "            info_list.append(isoform_info)\n",
    "\n",
    "        #if desired save info about each ptm in isoforms\n",
    "        if ptm_df is not None:\n",
    "            df_list.append(ptm_df)\n",
    "\n",
    "    info_df = pd.concat(info_list)\n",
    "    info_df['UniProt ID'] = info_df['Isoform'].str.split('-').str[0]\n",
    "    info_df['Type'] = type\n",
    "    isoform_info[type] = info_df\n",
    "    ptm_df[type] = pd.concat(df_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
