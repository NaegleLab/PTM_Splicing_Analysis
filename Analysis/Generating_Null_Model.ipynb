{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the null model for comparison to modification data\n",
    "\n",
    "In this file, we will generate a null model consisting of random residues, rather than modifiable ones, meant to represent the impact splicing would have on residues if they are randomly selected from the proteome. To do so, we will first perform the mapping and projection process for all residues in the protoeme, and then randomly select a subset of these residues to define as a \"modifiable\". With this null model, we can then calculate constitutive rates and altered flank rates for each residue, and compare these to the rates observed in the modification data.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Load Data](#load-data)\n",
    "2. [Mapping and Projection of Residues to the Genome](#construct-null-residue-dataframes)\n",
    "3. [Generate null model distributions of constitutive and altered flank rates](#generate-null-model-distributions)\n",
    "    1. [Constitutive rates](#generate-null-model-distributions-for-constitutive-rates)\n",
    "    2. [Altered flank rates](#generate-null-model-distributions-for-altered-flank-rates)\n",
    "\n",
    "\n",
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam\\miniconda3\\envs\\splice\\Lib\\site-packages\\Bio\\pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Canonical UniProt isoforms\n",
      "Downloading ID translator file\n",
      "Loading mapper object from .tsv files\n",
      "Loading exon-specific data\n",
      "Loading transcript-specific data\n",
      "Loading gene-specific info\n",
      "Loading unique protein isoforms\n",
      "Loading protein-specific info\n",
      "Loading information on PTMs on canonical proteins\n",
      "Loading genomic coordinates of PTMs associated with canonical proteins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\OneDrive\\Documents\\GradSchool\\Research\\Splicing\\ExonPTMapper\\ExonPTMapper\\mapping.py:1726: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.ptm_coordinates = pd.read_csv(config.processed_data_dir + 'ptm_coordinates.csv',index_col = 0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading information on PTMs on alternative proteins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\OneDrive\\Documents\\GradSchool\\Research\\Splicing\\ExonPTMapper\\ExonPTMapper\\mapping.py:1734: DtypeWarning: Columns (5,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.alternative_ptms = pd.read_csv(config.processed_data_dir + 'alternative_ptms.csv', dtype = {'Exon ID (Alternative)':str, 'Chromosome/scaffold name': str, 'Ragged':str, 'Genomic Coordinates':str, 'Second Exon': str, 'Alternative Residue': str, 'Protein':str})\n"
     ]
    }
   ],
   "source": [
    "from ExonPTMapper import mapping, config\n",
    "import os\n",
    "import pandas as pd\n",
    "import tqdm \n",
    "import numpy as np\n",
    "\n",
    "#store figshare directory\n",
    "figshare_dir = './'\n",
    "\n",
    "#load mapping data\n",
    "mapper = mapping.PTM_mapper()\n",
    "#get rid of ptm information stored by mapper object\n",
    "mapper.ptm_info = None\n",
    "mapper.ptm_coordinates = None\n",
    "mapper.isoform_ptms = None\n",
    "mapper.alternative_ptms = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct null residue dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "def find_residues_one_protein(mapper, uniprot_id):\n",
    "    \"\"\"\n",
    "    Given a uniprot ID, find all PTMs present in the protein and save to dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    unip_id: strings\n",
    "        Ensemble transcript for the protein of interest\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ptm_df: pandas dataframe\n",
    "        Dataframe containing gene id, transcript id, protein id, residue modified, location of residue and modification type. Each row\n",
    "            corresponds to a unique ptm\n",
    "    \"\"\"\n",
    "    gene_id = mapper.proteins.loc[uniprot_id, 'Gene stable ID']\n",
    "    transcript_id = mapper.proteins.loc[uniprot_id, 'Associated Matched Transcripts']\n",
    "    iso_type = mapper.proteins.loc[uniprot_id, 'UniProt Isoform Type']\n",
    "\n",
    "    trans_info = mapper.transcripts.loc[transcript_id.split(';')[0]]\n",
    "\n",
    "    #iterate through transcript sequence and add each residue to the lists, using same structure as residue_info dataframe\n",
    "    seq = trans_info['Amino Acid Sequence']\n",
    "    protein_list, type_list, ptm_list, pos_list, residue_list, gene_name_list, gene_id_list, transcripts = [],[],[],[],[],[],[],[]\n",
    "    for pos, residue in zip(range(1,len(seq)+1),seq):\n",
    "        ptm_list.append(uniprot_id+residue+str(pos))\n",
    "        pos_list.append(pos)\n",
    "        residue_list.append(residue)\n",
    "\n",
    "\n",
    "    residue_df = pd.DataFrame({'Gene name':mapper.genes.loc[gene_id.split(';')[0], 'Gene name'], 'Genes': gene_id, 'Transcripts': transcript_id,'Protein':uniprot_id,'Isoform Type':iso_type, 'Residue': residue_list, \n",
    "                'PTM Location (AA)':pos_list, 'Modification': 'Null', 'Modification Class':'Null'})\n",
    "\n",
    "    residue_df.index = ptm_list\n",
    "\n",
    "    return residue_df\n",
    "    \n",
    "def find_residues_list(mapper, uniprot_ids):\n",
    "    num_ptms = {}\n",
    "    df_list = []\n",
    "    for prot in uniprot_ids:\n",
    "        #check to make sure transcript has appropriate information\n",
    "        info = find_residues_one_protein(mapper, prot)\n",
    "        if info.empty:\n",
    "            num_ptms[prot] = 0\n",
    "        else:\n",
    "            df_list.append(info)\t\n",
    "\n",
    "    residue_df = pd.concat(df_list).dropna(axis = 1, how = 'all')\n",
    "    residue_df['PTM Location (AA)'] = residue_df['PTM Location (AA)'].astype(int)\n",
    "    return residue_df, num_ptms\n",
    "        \n",
    "\n",
    "\n",
    "def find_residues(mapper, fname = 'residue_info.csv', PROCESSES = 4):\n",
    "    #remove proteins without matched transcripts\n",
    "    trim_proteins = mapper.proteins.dropna(subset = 'Associated Matched Transcripts').copy()\n",
    "    print('Constructing initial residue info dataframe')\n",
    "    if PROCESSES == 1:\n",
    "        residue_info, num_residues = find_residues_list(mapper, trim_proteins.index.values)\n",
    "    else:\n",
    "        #check num_cpus available, if greater than number of cores - 1 (to avoid freezing machine), then set to PROCESSES to 1 less than total number of cores\n",
    "        num_cores = multiprocessing.cpu_count()\n",
    "        if PROCESSES > num_cores - 1:\n",
    "            PROCESSES = num_cores - 1\n",
    "            \n",
    "        protein_data_split = np.array_split(trim_proteins.index.values, PROCESSES)\n",
    "        pool = multiprocessing.Pool(PROCESSES)\n",
    "        #run with multiprocessing\n",
    "        results = pool.starmap(find_residues_list, [(mapper, protein_data_split[i]) for i in range(PROCESSES)])\n",
    "        \n",
    "        #extract info from run\n",
    "        residue_info = pd.concat([res[0] for res in results])\n",
    "        num_ptms_list = [res[1] for res in results]\n",
    "        num_ptms = {}\n",
    "        for item in num_ptms_list:\n",
    "            num_ptms.update(item)\n",
    "\n",
    "\n",
    "    residue_info.to_csv(fname)\n",
    "    mapper.ptm_info = residue_info.copy()\n",
    "    return mapper\n",
    "\n",
    "def mapResidues(mapper, odir = './', PROCESSES = 4):\n",
    "    print('mapping residues to genomic location')\n",
    "    mapper.mapPTMs_all()\n",
    "    mapper.ptm_info.to_csv(odir + 'residue_info.csv')\n",
    "    mapper.ptm_coordinates.to_csv(odir + 'residue_coordinates.csv')\n",
    "    return mapper\n",
    "\n",
    "def annotateResidues(mapper, odir = './'):\n",
    "    print('annotating residues')\n",
    "    ####run additional analysis\n",
    "    if 'Tryptic Fragment' not in mapper.ptm_info.columns:\n",
    "        print('Getting tryptic fragments associated with canonical ptms')\n",
    "        mapper.getAllTrypticFragments()\n",
    "    if 'Flanking Sequence' not in mapper.ptm_info.columns:\n",
    "        print('Getting flanking sequences associated with canonical ptms')\n",
    "        mapper.getAllFlankingSeqs(flank_size = 10)\n",
    "    if 'inDomain' not in mapper.ptm_info.columns:\n",
    "        print('Identifying PTMs that are in protein domains')\n",
    "        mapper.findAllinDomains()\n",
    "\n",
    "    mapper.ptm_info.to_csv(odir + 'residue_info.csv')\n",
    "    return mapper\n",
    "\n",
    "def projectResidues(mapper, odir = './', PROCESSES = 4):\n",
    "    print('project residues')\n",
    "    mapper.projectPTMs_toIsoformExons(alternative_only = False, PROCESSES = PROCESSES)\n",
    "\n",
    "    mapper.alternative_ptms.to_csv(odir + 'alternative_ptms.csv', index = False)\n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = find_residues(mapper, fname = figshare_dir + '/Analysis_For_Paper/NullModel/residue_info.csv', PROCESSES = 4)\n",
    "mapper = mapResidues(mapper, odir = figshare_dir + '/Analysis_For_Paper/NullModel/')\n",
    "mapper = annotateResidues(mapper,odir = figshare_dir + '/Analysis_For_Paper/NullModel/')\n",
    "mapper = projectResidues(mapper, odir = figshare_dir + '/Analysis_For_Paper/NullModel/', PROCESSES = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate null model distributions\n",
    "\n",
    "To generate the null model distributions, we follow the same procedure as the true modification data, performing the following steps for each modification class:\n",
    "1. Sample a random subset of residues, matching the same number of residues for that modification.\n",
    "2. Extract the mapping and projection data for those residues, treating them as \"modified\".\n",
    "3. Calculate the constitutive rate and altered flank rate as done with true modifications.\n",
    "4. Save the calculated rates to a list. Repeat a total of 100 times.\n",
    "5. Save rates to a  text file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIsoformSpecificPTMs(alternative_ptms, isoforms, required_length = 20):\n",
    "    \"\"\"\n",
    "    Reduce alternative ptm dataframe to ptms that are unique to a specific protein sequence, rather than a specific transcript. This avoids issue in which multiple transcripts can code for the same protein isoform.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    required_length : int, optional\n",
    "        Minimum length of protein isoform to be considered. The default is 20 amino acids.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    isoform_ptms (as attribute of mapper object): dataframe\n",
    "        Dataframe of PTMs that are unique to a specific protein isoform, rather than a specific transcript.\n",
    "    \"\"\"\n",
    "    #get isoform data, then separate isoform data into unique rows for each transcript\n",
    "    isoforms = isoforms[isoforms['Isoform Type'] == 'Alternative'].copy()\n",
    "    isoforms = isoforms[['Isoform ID', 'Transcript stable ID', 'Isoform Length']]\n",
    "    isoforms['Transcript stable ID'] = isoforms['Transcript stable ID'].apply(lambda x: x.split(';'))\n",
    "    isoforms = isoforms.explode('Transcript stable ID')\n",
    "    isoforms = isoforms.rename({'Transcript stable ID': 'Alternative Transcript'}, axis = 1)\n",
    "    \n",
    "    #merge isoform and alternative ptm information\n",
    "    isoform_ptms = alternative_ptms.merge(isoforms, on = 'Alternative Transcript', how = 'left').copy()\n",
    "    \n",
    "    #split by PTM (for cases where isoform are annotated with PTM\n",
    "    isoform_ptms['Source of PTM'] = isoform_ptms['Source of PTM'].apply(lambda x: x.split(';'))\n",
    "    isoform_ptms = isoform_ptms.explode('Source of PTM')\n",
    "\n",
    "\n",
    "    #drop duplicate rows by isoform id\n",
    "    isoform_ptms = isoform_ptms.drop_duplicates(subset = ['Isoform ID', 'Source of PTM'])\n",
    "    isoform_ptms = isoform_ptms.drop('Alternative Transcript', axis = 1)\n",
    "\n",
    "    #drop isoforms shorter than 20 amino acids\n",
    "    isoform_ptms = isoform_ptms[isoform_ptms['Isoform Length'] >= required_length]\n",
    "    return isoform_ptms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary for converting between single letter and full names of amino acids\n",
    "residue_dict = {'A': 'Alanine', 'C': 'Cysteine', 'D':'AsparticAcid','E':'GlutamicAcid',\n",
    "                'F':'Phenylalanine','G':'Glycine','H':'Histidine','I':'Isoleucine', \n",
    "                'K':'Lysine', 'L':'Leucine','M':'Methionine', 'N':'Asparagine',\n",
    "                'P':'Proline','Q':'Glutamine','R':'Arginine','S':'Serine', 'T':'Threonine',\n",
    "                'V':'Valine','W':'Tryptophan','Y':'Tyrosine'}\n",
    "\n",
    "#load real ptm data\n",
    "mapper = mapping.PTM_mapper()\n",
    "#get isoform specific ptms (collapse to )\n",
    "mapper.isoform_ptms = pd.read_csv(figshare_dir + '/PTM_Projection_Data/processed_data_dir/isoform_ptms.csv', index_col = 0)\n",
    "\n",
    "#copy ptm info\n",
    "ptm_info = mapper.ptm_info.copy()\n",
    "\n",
    "#get file for converting modification types to their grouped classess (phosphotyrosine to phosphorylation, etc.)\n",
    "mod_groups = pd.read_csv(figshare_dir + '/External_Data/modification_conversion.csv', header = 0)\n",
    "\n",
    "\n",
    "#separate based on modifications, such that each row is a unique residue/modification type pair\n",
    "exploded_mods = ptm_info.copy()\n",
    "exploded_mods[\"Modification Class\"] = exploded_mods['Modification Class'].apply(lambda x: x.split(';'))\n",
    "exploded_mods = exploded_mods.explode('Modification Class').reset_index()\n",
    "exploded_mods = exploded_mods.rename({'index':'PTM'}, axis = 1)\n",
    "\n",
    "#load residue information\n",
    "residue_info = pd.read_csv(figshare_dir + '/Analysis_For_Paper/Null_Model/residue_info.csv')\n",
    "residue_info = residue_info[residue_info['Isoform Type'] == 'Canonical']\n",
    "residue_info['PTM'] = residue_info.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Null Distribution for Constitutive Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods_to_test = ['PHOS','UBIQ', 'ACET', 'GLCN', 'METH','SUMO', 'DIMETH', 'NTRY', 'HYDR', 'TRIMETH','SULF', 'PALM', 'CITR', 'GGLU']\n",
    "#mods_to_test = ['HYDR', 'TRIMETH','SULF', 'PALM', 'GGLU']\n",
    "#mods_to_test = ['CITR']\n",
    "mod_column = 'Mod Class'\n",
    "for mod in mods_to_test:\n",
    "    print(f'Getting null {mod} data')\n",
    "    tmp_mods = exploded_mods[exploded_mods[mod_column] == mod].copy()\n",
    "    #load toy mapped residues\n",
    "    residues = tmp_mods['Residue'].unique()\n",
    "    sizes = tmp_mods.groupby('Residue').size()\n",
    "    mapped_residues = {}\n",
    "    for res in residues:\n",
    "        try:\n",
    "            mapped_residues[res] = getIsoformSpecificPTMs(pd.read_csv(f'../MockModifications/mapped/{residue_dict[res]}.csv', dtype = {'Exon ID (Alternative)':str, \n",
    "                                                                        'Chromosome/scaffold name': str, 'Ragged':str, 'Genomic Coordinates':str, 'Exon ID (Canonical)': str, \n",
    "                                                                            'Alternative Residue': str, 'Protein':str, 'Canonical Protein Position (AA)': str, \n",
    "                                                                        'Alternative Protein Position (AA)':str,'Mapping Result':str, 'Second Exon': str}), isoforms)\n",
    "        except:\n",
    "            print(f'{residue_dict[res]} not found. {sizes[res]} with modification.')\n",
    "            \n",
    "    unique_res = tmp_mods['Residue'].unique()\n",
    "    num_mod = tmp_mods.groupby('Residue').size()[mapped_residues.keys()]\n",
    "    \n",
    "    np.random.seed(100)\n",
    "    rate_list = []\n",
    "    for i in tqdm.tqdm(range(100)):\n",
    "        #for each residue, randomly sample the number that matches that found within modification population\n",
    "        sampled_results = None\n",
    "        for residue in num_mod.index:\n",
    "            residue_list = residue_info.loc[residue_info['Residue'] == residue, \"PTM\"].unique()\n",
    "            sample = np.random.choice(residue_list, size = num_mod[residue], replace = False)\n",
    "            if sampled_results is None:\n",
    "                conservation_data = residue_info.loc[sample].copy()\n",
    "                sampled_results = mapped_residues[residue][mapped_residues[residue]['Source of PTM'].isin(sample)]\n",
    "            else:\n",
    "                conservation_data = pd.concat([conservation_data, residue_info.loc[sample]])\n",
    "                sampled_results = pd.concat([sampled_results,mapped_residues[residue][mapped_residues[residue]['Source of PTM'].isin(sample)]])\n",
    "\n",
    "        #get alternative isoforms for which the PTM is conserved (i.e. the PTM is present in the isoform and has residue data) or lost (i.e. the PTM is not present in the isoform)    \n",
    "        conserved_transcripts = sampled_results[sampled_results['Mapping Result'] == 'Success'].groupby('Source of PTM')['Isoform ID'].apply(list)\n",
    "        lost_transcripts = sampled_results[sampled_results['Mapping Result'] != 'Success'].groupby('Source of PTM')['Isoform ID'].apply(list)\n",
    "        \n",
    "\n",
    "        #calculate the number of conserved transcripts and collapse into a single string\n",
    "        num_conserved_transcripts = conserved_transcripts.apply(len)\n",
    "        conserved_transcripts = conserved_transcripts.apply(','.join)\n",
    "\n",
    "        #calculate the number of lost transcripts and collapse into a single string\n",
    "        num_lost_transcripts = lost_transcripts.apply(len)\n",
    "        lost_transcripts = lost_transcripts.apply(','.join)\n",
    "                                               \n",
    "\n",
    "        #conservation_data['Number of Conserved Transcripts'] = num_conserved\n",
    "        #conservation_data['Number of Lost Transcripts'] = num_lost                                    \n",
    "\n",
    "        conservation_score = []\n",
    "        for ptm in conservation_data.index:\n",
    "            num_conserved = num_conserved_transcripts[ptm] if ptm in num_conserved_transcripts else 0\n",
    "            num_lost = num_lost_transcripts[ptm] if ptm in num_lost_transcripts else 0\n",
    "            #check if there are any conserved transcripts (or if not and is NaN)\n",
    "            if num_conserved != num_conserved and num_lost == num_lost:\n",
    "                conservation_score.append(0)\n",
    "            elif num_conserved == 0 and num_lost == 0:\n",
    "                conservation_score.append(1)\n",
    "            elif num_conserved != num_conserved and num_lost != num_lost:\n",
    "                conservation_score.append(1)\n",
    "            #check if any lost transcripts: if not replace NaN with 0 when calculating\n",
    "            elif num_lost != num_lost and num_conserved == num_conserved:\n",
    "                conservation_score.append(1)\n",
    "            else:\n",
    "                conservation_score.append(num_conserved/(num_conserved+num_lost))\n",
    "\n",
    "        conservation_data['Score'] = conservation_score\n",
    "        conservation_data['Constitutive'] = (conservation_data['Score'] == 1)*1\n",
    "        rate = conservation_data[conservation_data['Constitutive'] == 1].shape[0]/conservation_data.shape[0]\n",
    "        rate_list.append(rate)\n",
    "        \n",
    "    # open file\n",
    "    with open(figshare_dir + f'/Analysis_For_Paper/Null_Model/Null_Constitutive_Rates/{mod}.txt', 'w+') as f:\n",
    "\n",
    "        # write elements of list\n",
    "        for items in rate_list:\n",
    "            f.write('%s\\n' %items)\n",
    "\n",
    "        print(\"File written successfully\")\n",
    "\n",
    "\n",
    "    # close the file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Null Model Distributions for Altered Flank Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def getFlankingSequences(isoforms, isoform_ptms, flank_size = 5):\n",
    "    flank_seq = []\n",
    "    for i, row in isoform_ptms.iterrows():\n",
    "        iso_id = row['Isoform ID']\n",
    "        protein_sequence = isoforms.get(iso_id)\n",
    "        if protein_sequence == protein_sequence:\n",
    "                #if multiple transcripts associated with protein, only use first transcript (should be same seq)\n",
    "            pos = row['Alternative Protein Position (AA)']\n",
    "            if pos==pos:\n",
    "                pos = int(float(pos))\n",
    "                seq_length = len(protein_sequence)\n",
    "                if pos <= flank_size:\n",
    "                    #if amino acid does not have long enough N-terminal flanking sequence, add spaces to cushion sequence\n",
    "                    spaces = ' ' * (flank_size - pos + 1)\n",
    "                    flank_seq.append(spaces + protein_sequence[0:pos-1]+protein_sequence[pos-1].lower()+protein_sequence[pos:pos+flank_size])\n",
    "                elif len(protein_sequence)-pos <= flank_size:\n",
    "                    #if amino acid does not have long enough C-terminal flanking sequence, add spaces to cushion sequence\n",
    "                    spaces = ' ' * (flank_size - (seq_length - pos))\n",
    "                    flank_seq.append(protein_sequence[pos-flank_size-1:pos-1]+protein_sequence[pos-1].lower()+protein_sequence[pos:]+spaces)\n",
    "                else:\n",
    "                    #full flanking sequence available\n",
    "                    flank_seq.append(protein_sequence[pos-flank_size-1:pos-1]+protein_sequence[pos-1].lower()+protein_sequence[pos:pos+flank_size])\n",
    "            else:\n",
    "                flank_seq.append(np.nan)\n",
    "        else:\n",
    "            flank_seq.append(np.nan)\n",
    "    return flank_seq\n",
    "\n",
    "\n",
    "def getFlankingSequences_can(transcripts, residue_info, flank_size = 5):\n",
    "    flank_seq = []\n",
    "    for i, row in residue_info.iterrows():\n",
    "        trans_id = row['Transcripts']\n",
    "        if ';' in trans_id:\n",
    "            trans_id = trans_id.split(';')[0]\n",
    "            \n",
    "        protein_sequence = transcripts.loc[trans_id]\n",
    "        if isinstance(protein_sequence, pd.Series):\n",
    "            protein_sequence = protein_sequence['Amino Acid Sequence']\n",
    "                #if multiple transcripts associated with protein, only use first transcript (should be same seq)\n",
    "            if row['PTM Location (AA)'] == row['PTM Location (AA)']:\n",
    "                pos = int(float(row['PTM Location (AA)']))\n",
    "                if pos <= flank_size:\n",
    "                    #if amino acid does not have long enough N-terminal flanking sequence, add spaces to cushion sequence\n",
    "                    spaces = ''.join([' ' for i in range(flank_size - pos + 1)])\n",
    "                    flank_seq.append(spaces + protein_sequence[0:pos-1]+protein_sequence[pos-1].lower()+protein_sequence[pos:pos+flank_size])\n",
    "                elif len(protein_sequence)-pos <= flank_size:\n",
    "                    #if amino acid does not have long enough C-terminal flanking sequence, add spaces to cushion sequence\n",
    "                    spaces = ''.join([' ' for i in range(flank_size - (len(protein_sequence)-pos))])\n",
    "                    flank_seq.append(protein_sequence[pos-flank_size-1:pos-1]+protein_sequence[pos-1].lower()+protein_sequence[pos:]+spaces)\n",
    "                else:\n",
    "                    #full flanking sequence available\n",
    "                    flank_seq.append(protein_sequence[pos-flank_size-1:pos-1]+protein_sequence[pos-1].lower()+protein_sequence[pos:pos+flank_size])\n",
    "            else:\n",
    "                flank_seq.append(np.nan)\n",
    "        else:\n",
    "            flank_seq.append(np.nan)\n",
    "    return flank_seq\n",
    "\n",
    "def matchedFlankSeq(seq1, seq2):\n",
    "    return (seq1 == seq2)*1\n",
    "\n",
    "def compareAllFlankSeqs(residue_info, res, flank_size = 5, unique_isoforms = True):\n",
    "    \"\"\"\n",
    "    Given the alternative ptms and canonical ptm data, compare flanking sequences and determine if they are identical. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    flank_size:\n",
    "        size of the flanking sequence to compare. IMPORTANT, this should not be larger than the available flanking sequence in the ptm_info dataframe\n",
    "    \"\"\"\n",
    "    conserved_flank = []\n",
    "    for i in res.index:\n",
    "        #check if alt flanking seq exists\n",
    "        alt_flank = res.loc[i, 'Flanking Sequence']\n",
    "        if alt_flank != alt_flank:\n",
    "            conserved_flank.append(np.nan)\n",
    "        else:\n",
    "            \n",
    "            ptm = res.loc[i, 'Source of PTM']\n",
    "            if ';' in ptm:\n",
    "                for p in ptm.split(';'):\n",
    "                    try:\n",
    "                        tmp_info = residue_info.loc[p]\n",
    "                        if isinstance(tmp_info, pd.DataFrame):\n",
    "                            iso_id = res.loc[i, 'Isoform ID']\n",
    "                            trans_id = isoforms.loc[iso_id, 'Transcript stable ID'].split(';')\n",
    "                            tmp_info = tmp_info[tmp_info['Transcripts'] == trans_id[0]]\n",
    "                            if tmp_info.shape[0] == 0:\n",
    "                                conserved_flank.append(np.nan)\n",
    "                            else:\n",
    "                                can_flank = tmp_info['Flanking Sequence'].values[0]\n",
    "                            can_flank = tmp_info['Flanking Sequence'].values[0]\n",
    "                        else:\n",
    "                            can_flank = tmp_info['Flanking Sequence']\n",
    "                        #can_flank = can_flank[n_term:c_term]\n",
    "                        conserved_flank.append(matchedFlankSeq(can_flank, alt_flank))\n",
    "                        success = True\n",
    "                    except:\n",
    "                        pass\n",
    "                if not success:\n",
    "                    conserved_flank.append(matchedFlankSeq(can_flank, alt_flank))\n",
    "            else:\n",
    "                \n",
    "                tmp_info = residue_info.loc[ptm]\n",
    "                if isinstance(tmp_info, pd.DataFrame):\n",
    "                    iso_id = res.loc[i, 'Isoform ID']\n",
    "                    trans_id = isoforms.loc[iso_id, 'Transcript stable ID'].split(';')\n",
    "                    tmp_info = tmp_info[tmp_info['Transcripts'] == trans_id[0]]\n",
    "                    if tmp_info.shape[0] == 0:\n",
    "                        conserved_flank.append(np.nan)\n",
    "                    else:\n",
    "                        can_flank = tmp_info['Flanking Sequence'].values[0]\n",
    "                else:\n",
    "                    can_flank = tmp_info['Flanking Sequence']\n",
    "                #can_flank = can_flank[n_term:c_term]\n",
    "                conserved_flank.append(matchedFlankSeq(can_flank, alt_flank))\n",
    "                \n",
    "                    #conserved_flank.append(np.nan)\n",
    "    return conserved_flank\n",
    "\n",
    "def compareAllFlankSeqs2(residue_info, res, flank_size = 5, unique_isoforms = True):\n",
    "    \"\"\"\n",
    "    Given the alternative ptms and canonical ptm data, compare flanking sequences and determine if they are identical. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    flank_size:\n",
    "        size of the flanking sequence to compare. IMPORTANT, this should not be larger than the available flanking sequence in the ptm_info dataframe\n",
    "    \"\"\"\n",
    "    conserved_flank = []\n",
    "    for i in res.index:\n",
    "        #check if alt flanking seq exists\n",
    "        alt_flank = res.loc[i, 'Flanking Sequence']\n",
    "        if alt_flank != alt_flank:\n",
    "            conserved_flank.append(np.nan)\n",
    "        else:\n",
    "            \n",
    "            ptm = res.loc[i, 'Source of PTM'].split(';')[0]\n",
    "            try:\n",
    "                tmp_info = residue_info.loc[ptm]\n",
    "                can_flank = tmp_info['Flanking Sequence']\n",
    "                #can_flank = can_flank[n_term:c_term]\n",
    "                conserved_flank.append(matchedFlankSeq(can_flank, alt_flank))\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                conserved_flank.append(np.nan)\n",
    "                \n",
    "                    #conserved_flank.append(np.nan)\n",
    "\n",
    "    return conserved_flank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residue_dict = {'A': 'Alanine', 'C': 'Cysteine', 'D':'AsparticAcid','E':'GlutamicAcid','F':'Phenylalanine','G':'Glycine','H':'Histidine','I':'Isoleucine','L':'Leucine',  'K':'Lysine','M':'Methionine', 'N':'Asparagine','P':'Proline','Q':'Glutamine','R':'Arginine','S':'Serine', 'T':'Threonine','V':'Valine','W':'Tryptophan','Y':'Tyrosine'}\n",
    "\n",
    "transcripts = pd.read_csv(config.processed_data_dir + 'transcripts.csv', index_col = 0)\n",
    "residue_info['Flanking Sequence'] = getFlankingSequences_can(transcripts, residue_info, flank_size = 5)\n",
    "\n",
    "mapper.isoforms  = mapper.isoforms.set_index('Isoform ID')\n",
    "isoforms = mapper.isoforms['Amino Acid Sequence'].to_dict()\n",
    "\n",
    "mods_to_test =  ['Phosphorylation','Ubiquitination', 'Acetylation', 'Glycosylation', 'Methylation','Sumoylation', 'Dimethylation', 'Nitrosylation', 'Hydroxylation', 'Trimethylation','Sulfation', 'Palmitoylation', 'Carboxylation', 'Crotonylation', 'Succinylation']\n",
    "mod_column = 'Mod Class'\n",
    "for mod in mods_to_test:\n",
    "    print(f'Getting null {mod} data')\n",
    "    tmp_mods = exploded_mods[exploded_mods[mod_column] == mod].copy()\n",
    "    #load toy mapped residues\n",
    "    residues = tmp_mods['Residue'].unique()\n",
    "    sizes = tmp_mods.groupby('Residue').size()\n",
    "    mapped_residues = {}\n",
    "    for res in residues:\n",
    "        try:\n",
    "            mapped_residues[res] = getIsoformSpecificPTMs(pd.read_csv(f'../MockModifications/mapped/{residue_dict[res]}.csv', dtype = {'Exon ID (Alternative)':str, \n",
    "                                                                        'Chromosome/scaffold name': str, 'Ragged':str, 'Genomic Coordinates':str, 'Exon ID (Canonical)': str, \n",
    "                                                                            'Alternative Residue': str, 'Protein':str, 'Canonical Protein Position (AA)': str, \n",
    "                                                                        'Alternative Protein Position (AA)':str,'Mapping Result':str, 'Second Exon':str}), isoforms)\n",
    "        except:\n",
    "            print(f'{residue_dict[res]} not found. {sizes[res]} with modification.')\n",
    "            \n",
    "    unique_res = tmp_mods['Residue'].unique()\n",
    "    num_mod = tmp_mods.groupby('Residue').size()[mapped_residues.keys()]\n",
    "    \n",
    "    np.random.seed(100)\n",
    "    flank_conservation_list = []\n",
    "    for i in tqdm.tqdm(range(100)):\n",
    "        #for each residue, randomly sample the number that matches that found within modification population\n",
    "        sampled_results = None\n",
    "        for residue in num_mod.index:\n",
    "            #residue_list = residue_info.loc[residue_info['Residue'] == residue, \"PTM\"].unique()\n",
    "            residue_list = np.unique(residue_info[residue_info['Residue'] == residue].index.values)\n",
    "            sample = np.random.choice(residue_list, size = num_mod[residue], replace = False)\n",
    "            if sampled_results is None:\n",
    "                conservation_data = residue_info.loc[sample].copy()\n",
    "                sampled_results = mapped_residues[residue][mapped_residues[residue]['Source of PTM'].isin(sample)]\n",
    "            else:\n",
    "                conservation_data = pd.concat([conservation_data, residue_info.loc[sample]])\n",
    "                sampled_results = pd.concat([sampled_results,mapped_residues[residue][mapped_residues[residue]['Source of PTM'].isin(sample)]])\n",
    "\n",
    "        #get flanking sequences\n",
    "        sampled_results = sampled_results[sampled_results['Mapping Result'] == 'Success']\n",
    "        sampled_results = sampled_results.reset_index()\n",
    "        sampled_results['Flanking Sequence'] = getFlankingSequences(isoforms, sampled_results)\n",
    "        sampled_results = sampled_results.dropna(subset = 'Flanking Sequence')\n",
    "        conserved_flanks = compareAllFlankSeqs2(residue_info, sampled_results)\n",
    "        conserved_flanks = [f for f in conserved_flanks if f == f]\n",
    "        #calculate fraction of ptms with conserved flank\n",
    "        flank_conservation_list.append(1- sum(conserved_flanks)/len(conserved_flanks))\n",
    "        \n",
    "                                               \n",
    "        \n",
    "    # open file\n",
    "    with open(figshare_dir + f'/Analysis_For_Paper/Null_Model/Null_Flank_Rates/{mod}.txt', 'w+') as f:\n",
    "\n",
    "        # write elements of list\n",
    "        for items in flank_conservation_list:\n",
    "            f.write('%s\\n' %items)\n",
    "\n",
    "        print(\"File written successfully\")\n",
    "\n",
    "\n",
    "    # close the file\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
