{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the null model for comparison to modification data\n",
    "\n",
    "In this file, we will generate a null model consisting of random residues, rather than modifiable ones, meant to represent the impact splicing would have on residues if they are randomly selected from the proteome. To do so, we will first perform the mapping and projection process for all residues in the protoeme, and then randomly select a subset of these residues to define as a \"modifiable\". With this null model, we can then calculate constitutive rates and altered flank rates for each residue, and compare these to the rates observed in the modification data.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Load Data](#load-data)\n",
    "2. [Mapping and Projection of Residues to the Genome](#construct-null-residue-dataframes)\n",
    "    1. [Mapping Residues to the Genome](#map-residues-to-genome)\n",
    "    2. [Projection of Residues to the Genome](#project-residues-to-alternative-transcripts)\n",
    "3. [Generate null model distributions of constitutive and altered flank rates](#generate-null-model-distributions)\n",
    "    1. [Constitutive rates](#generate-null-model-distributions-for-constitutive-rates)\n",
    "    2. [Altered flank rates](#generate-null-model-distributions-for-altered-flank-rates)\n",
    "\n",
    "\n",
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExonPTMapper import mapping, config\n",
    "import os\n",
    "import pandas as pd\n",
    "import tqdm \n",
    "import numpy as np\n",
    "\n",
    "#store figshare directory\n",
    "figshare_dir = 'C:/Users/Sam/OneDrive/Documents/GradSchool/Research/Splicing/Paper_Prep/PTM_Splicing_FigShare/'\n",
    "\n",
    "#load mapping data\n",
    "mapper = mapping.PTM_mapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct null residue dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_list = []\n",
    "ptm_list = []\n",
    "pos_list = []\n",
    "residue_list = []\n",
    "genes = []\n",
    "transcripts = []\n",
    "modifications = []\n",
    "\n",
    "#reduce translator to only the Uniprot and transcript IDs\n",
    "trim_translator = config.translator[['Transcript stable ID', 'UniProtKB/Swiss-Prot ID']].drop_duplicates()\n",
    "\n",
    "#for all transcripts with matching information in the mapper, get the amino acid sequence\n",
    "for transcript_id in tqdm.tqdm(config.available_transcripts):\n",
    "    #get transcript info\n",
    "    trans_info = mapper.transcripts.loc[transcript_id]\n",
    "    protein = config.translator.loc[config.translator['Transcript stable ID'] == transcript_id, 'UniProtKB/Swiss-Prot ID']\n",
    "    \n",
    "    #iterate through transcript sequence and add each residue to the lists, using same structure as residue_info dataframe\n",
    "    seq = trans_info['Amino Acid Sequence']\n",
    "    for pos, residue in zip(range(1,len(seq)+1),seq):\n",
    "        protein_list.append(protein.values[0])\n",
    "        ptm_list.append(protein+residue+str(pos))\n",
    "        pos_list.append(pos)\n",
    "        residue_list.append(residue)\n",
    "        genes.append(trans_info['Gene stable ID'])\n",
    "        transcripts.append(trans_info.name)\n",
    "        modifications.append('Null')\n",
    "        \n",
    "result = pd.DataFrame({'Gene': genes, 'Protein':protein_list,'Transcript': transcripts, 'Residue': residue_list, \n",
    "              'PTM Location (AA)':pos_list, 'Modification': 'No Mod'})\n",
    "result.to_csv(figshare_dir + '/Analysis_For_Paper/Null_Model/residue_info.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Residues to Genome \n",
    "\n",
    "Using the same mapping/projection procedure as with the true ptm data, we can map residues to their location in the genome and project them to alternative residues. Only difference is that we will not be collapsing the residue information into a single row (duplicates for the same residue if found in multiple canonical transcripts). This is a result of memory limitations but does not change the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get location of residue in transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create copy of existing residue_info dataframe\n",
    "residue_info = residue_info.rename({'Transcript':'Transcripts'}, axis = 1)\n",
    "#separate residue_info dataframe by unique transcripts\n",
    "#residue_info['Transcripts'] = residue_info['Transcripts'].apply(lambda x: x.split(';'))\n",
    "#residue_info = residue_info.explode('Transcripts')\n",
    "\n",
    "print('Getting location of PTMs in exon, transcript, and gene')\n",
    "\n",
    "#extract transcript level info required for mapping process (coding start and location of splice boundaries)\n",
    "transcript_data = mapper.transcripts[['Relative CDS Start (bp)', 'Exon cuts']].copy()\n",
    "#remove transcripts without necessary data (nan, or with error string)\n",
    "transcript_data = transcript_data.dropna(subset = ['Exon cuts', 'Relative CDS Start (bp)'])\n",
    "\n",
    "#convert exon cuts into list containing integers rather than a single string\n",
    "transcript_data['Exon cuts'] = transcript_data['Exon cuts'].apply(lambda cut: np.array([int(x) for x in cut.split(',')]))\n",
    "transcript_data = transcript_data.dropna(subset = ['Exon cuts', 'Relative CDS Start (bp)'])\n",
    "\n",
    "#add transcript data to ptm information\n",
    "residue_info = residue_info.merge(transcript_data, left_on = 'Transcripts', right_index = True, how = 'left')\n",
    "residue_info = residue_info.dropna(subset = 'Exon cuts')\n",
    "\n",
    "#get transcript location of PTMs\n",
    "residue_info['Transcript Location (NC)'] = ((residue_info['PTM Location (AA)']-1)*3 + residue_info['Relative CDS Start (bp)'])\n",
    "\n",
    "#get rank of exon in transcript, based on transcript location and exon cuts. To do so, find the first exon cut which is greater than transcript location.\n",
    "min_exon_rank = mapper.exons.groupby('Transcript stable ID')['Exon rank in transcript'].min()\n",
    "exon_rank = []\n",
    "n_dist_list = []\n",
    "c_dist_list = []\n",
    "min_dist_list = []\n",
    "ragged_list = []\n",
    "for i, row in tqdm.tqdm(residue_info.iterrows(), total = residue_info.shape[0], desc = 'Identify PTM-containing exons'):\n",
    "    #get minimum exon rank in transcript, for rare case when first exons don't have sequence info\n",
    "\n",
    "    #get distance of PTM from splice boundaries by subtracting PTM location in transcript by splice boundaries\n",
    "    normed_cuts = row['Transcript Location (NC)'] - row['Exon cuts']\n",
    "    #find the first negative number in normed_cuts (larger than transcript loc), which will indicate the correct exon rank\n",
    "    for c in range(len(normed_cuts)):\n",
    "        if normed_cuts[c] <  0:\n",
    "            #add 1, as currently in pythonic coordinates (if missing first exon ranks, add additional)\n",
    "            exon_rank.append(c+min_exon_rank[row['Transcripts']])\n",
    "\n",
    "            #record distance n-terminal boundary/start of exon (if exon rank is 1, this will be the same as the transcript location, else use the normed cuts)\n",
    "            if c == 0:\n",
    "                n_distance = row['Transcript Location (NC)']\n",
    "            else:\n",
    "                n_distance = normed_cuts[c-1]\n",
    "            \n",
    "            #record distance to c-terminal boundary/end of exon\n",
    "            c_distance = row['Exon cuts'][c] - (row['Transcript Location (NC)'] + 3)\n",
    "\n",
    "            #record the minimum distance to boundary\n",
    "            min_distance = min([n_distance, c_distance])\n",
    "\n",
    "            #assess if ptm is ragged (coded for by two exons, found at splice boundary)\n",
    "            ragged = min_distance < 0\n",
    "\n",
    "            #save data to lists\n",
    "            n_dist_list.append(n_distance)\n",
    "            c_dist_list.append(c_distance)\n",
    "            min_dist_list.append(min_distance)\n",
    "            ragged_list.append(ragged)\n",
    "            break\n",
    "\n",
    "#save data to columns in dataframe\n",
    "residue_info['Exon rank in transcript'] = exon_rank\n",
    "residue_info['Distance to N-terminal Splice Boundary (NC)'] = n_dist_list\n",
    "residue_info['Distance to C-terminal Splice Boundary (NC)'] = c_dist_list\n",
    "residue_info['Distance to Closest Boundary (NC)'] = min_dist_list\n",
    "residue_info['Ragged'] = ragged_list\n",
    "\n",
    "\n",
    "residue_info.to_csv(figshare_dir + '/Analysis_For_Paper/Null_Model/residue_info.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get location of residue in genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove exon cuts column, no longer needed\n",
    "residue_info = residue_info.drop('Exon cuts', axis = 1)\n",
    "\n",
    "#add exon level information required for rest of mapping process (mapping to genomic location)\n",
    "exon_info = mapper.exons[['Transcript stable ID', 'Exon stable ID', 'Exon rank in transcript', 'Exon Start (Gene)', 'Exon End (Gene)', 'Exon Start (Protein)', 'Exon End (Protein)', 'Warnings (AA Seq)']].copy()\n",
    "residue_info = residue_info.merge(exon_info, left_on = ['Transcripts', 'Exon rank in transcript'], right_on = ['Transcript stable ID', 'Exon rank in transcript'], how = 'left')\n",
    "\n",
    "\n",
    "#add gene info to ptm dataframe (which strand and chromosome ptm is located)\n",
    "residue_info = residue_info.merge(mapper.genes[['Chromosome/scaffold name', 'Strand']], left_on = 'Genes', right_index = True)\n",
    "\n",
    "#get genomic locatio of ptms and coordinates\n",
    "gene_loc = []\n",
    "coordinates = []\n",
    "second_exon = []\n",
    "ragged_loc_list = []\n",
    "for i, row in tqdm(residue_info.iterrows(), total = residue_info.shape[0], desc = 'Getting location of PTMs in genome'):\n",
    "    #check strand of gene, calculate location of ptm in gene based on which strand\n",
    "    if row['Strand'] == 1:  \n",
    "        loc = row['Distance to N-terminal Splice Boundary (NC)'] + row['Exon Start (Gene)']\n",
    "    else:\n",
    "        loc = row['Exon End (Gene)'] - row['Distance to N-terminal Splice Boundary (NC)']\n",
    "\n",
    "    #check if able to get location, if so convert to integer\n",
    "    if loc == loc:\n",
    "        loc = int(loc)\n",
    "    gene_loc.append(loc)\n",
    "        \n",
    "    #given gene location, get genomic coordinates in the following format (<chromosome>:<start>-<stop>:<strand>)\n",
    "    if not row['Ragged']:   #genomic coordinates when gene is not found at splice boundary\n",
    "        coordinates.append(mapping.getGenomicCoordinates(row['Chromosome/scaffold name'], loc, row['Strand']))\n",
    "        second_exon.append(np.nan)\n",
    "        ragged_loc_list.append(np.nan)\n",
    "    else:   #genomic coordinates when gene is found at splice boundary (ragged site)\n",
    "        #identify the other exon contributing to ragged PTM site, get start of this exon \n",
    "        next_rank = row['Exon rank in transcript'] + 1\n",
    "        transcript = mapper.exons[mapper.exons['Transcript stable ID'] == row['Transcripts']]\n",
    "        next_exon = transcript[transcript['Exon rank in transcript'] == next_rank].squeeze()\n",
    "\n",
    "        #get location of ragged ptm to feed into function\n",
    "        ragged_loc = int(next_exon['Exon Start (Gene)'] if row['Strand'] == 1 else next_exon['Exon End (Gene)'])\n",
    "        min_dist = row['Distance to Closest Boundary (NC)']\n",
    "        #get coordinates of ragged PTM, save exon id of second contributing exon\n",
    "        coordinates.append(mapping.getRaggedCoordinates(row['Chromosome/scaffold name'], loc, ragged_loc, min_dist, row['Strand']))\n",
    "        ragged_loc_list.append(ragged_loc)\n",
    "        second_exon.append(next_exon['Exon stable ID'])\n",
    "\n",
    "#save data to ptm dataframe\n",
    "residue_info['Gene Location (NC)'] = gene_loc\n",
    "residue_info['Genomic Coordinates'] = coordinates\n",
    "residue_info['Second Contributing Exon'] = second_exon\n",
    "residue_info['Ragged Genomic Location'] = ragged_loc_list\n",
    "residue_info = residue_info.drop(['Exon Start (Gene)', 'Exon End (Gene)'], axis = 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get location of residue in the exon, based on amino acid coordiantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ptm location in exon in amino acid coordinates\n",
    "exon_aa_loc = []\n",
    "for i, row in tqdm(residue_info.iterrows(), total = residue_info.shape[0], desc = 'Getting residue number within each exon'):\n",
    "    if row['Warnings (AA Seq)'] == row['Warnings (AA Seq)']:\n",
    "        exon_aa_loc.append(np.nan)\n",
    "    else:\n",
    "        loc = round(row['PTM Location (AA)'] - float(row['Exon Start (Protein)']), 2)\n",
    "        exon_aa_loc.append(loc)\n",
    "        \n",
    "residue_info['Exon Location (AA)'] = exon_aa_loc\n",
    "\n",
    "#add column with ptm name (<UniProtID>_<Residue><Position>)\n",
    "residue_info['PTM'] = residue_info['Protein'] + '_' + residue_info['Residue']+ residue_info['PTM Location (AA)'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct residue coordinates dataframe (collapse residue into location in genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Constructing residue coordinates dataframe')\n",
    "#save new dataframe which will be trimmed version of ptm info with each row containing a PTM mapped to unique genomic coordinates\n",
    "residue_coordinates = residue_info[['Genomic Coordinates', 'PTM','Residue', 'Modification', 'Chromosome/scaffold name', 'Strand','Gene Location (NC)', 'Ragged', 'Ragged Genomic Location', 'Exon stable ID']].copy()\n",
    "residue_coordinates = residue_coordinates.dropna(subset = 'Gene Location (NC)')\n",
    "residue_coordinates = residue_coordinates.drop_duplicates()\n",
    "residue_coordinates = residue_coordinates.astype({'Gene Location (NC)': int, 'Strand':int, 'Ragged':bool})\n",
    "\n",
    "#group modifications for the same ptm in the same row\n",
    "grouped = residue_coordinates.groupby(['Genomic Coordinates', 'Chromosome/scaffold name', 'Residue', 'Strand', 'Gene Location (NC)', 'Ragged'])\n",
    "residue_coordinates = pd.concat([grouped['PTM'].agg(lambda x: ';'.join(np.unique(x))), grouped['Ragged Genomic Location'].apply(lambda x: np.unique(x)[0]), grouped['Modification'].agg(lambda x: ';'.join(np.unique(x))), grouped['Exon stable ID'].agg(lambda x: ';'.join(np.unique(x)))], axis = 1)\n",
    "residue_coordinates = residue_coordinates.reset_index()\n",
    "residue_coordinates = residue_coordinates.rename({'PTM':'Source of PTM', 'Exon stable ID': 'Source Exons'}, axis = 1)\n",
    "\n",
    "#make genomic coordinates the index of dataframe\n",
    "residue_coordinates.index = residue_coordinates['Genomic Coordinates']\n",
    "residue_coordinates = residue_coordinates.drop('Genomic Coordinates', axis = 1)\n",
    "residue_coordinates = residue_coordinates.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved the residue coordinates dataframe to modification specific files to reduce memory load of running the projection onto genomic locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary for converting from single letter to full names of amino acids\n",
    "residue_dict = {'A': 'Alanine', 'C': 'Cysteine', 'D':'AsparticAcid','E':'GlutamicAcid',\n",
    "                'F':'Phenylalanine','G':'Glycine','H':'Histidine','I':'Isoleucine', \n",
    "                'K':'Lysine', 'L':'Leucine','M':'Methionine', 'N':'Asparagine',\n",
    "                'P':'Proline','Q':'Glutamine','R':'Arginine','S':'Serine', 'T':'Threonine',\n",
    "                'V':'Valine','W':'Tryptophan','Y':'Tyrosine'}\n",
    "\n",
    "for residue in residue_dict.keys():\n",
    "    subset = residue_coordinates[residue_coordinates['Residue'] == residue]\n",
    "    subset.to_csv(figshare_dir + f'/Analysis_For_Paper/Null_Model/residue_coordinates/{residue_dict[residue]}_coordinates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project residues to alternative transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = ['Serine','Threonine', 'Tyrosine', 'Phenylalanine', 'Glycine', 'Histidine', 'Isoleucine', 'Leucine', 'Proline', 'Glutamine', 'Valine', 'Tryptophan', 'Alanine', 'Cysteine', 'AsparticAcid', 'GlutamicAcid', 'Lysine', 'Methionine', 'Asparagine', 'Arginine']\n",
    "residues = ['S','T', 'Y', 'F', 'G', 'H', 'I', 'L', 'P', 'Q', 'V', 'W', 'A', 'C', 'D', 'E', 'K', 'M', 'N', 'R']\n",
    "\n",
    "#iterate through each residue and project ptms separately\n",
    "for mod, residue in zip(mods, residues):\n",
    "  if not os.path.exists(figshare_dir + f'/Analysis_For_Paper/Null_Model/residue_coordinates/{mod}.csv'):\n",
    "    #load residue coordinates and info into mapper object\n",
    "    mapper.ptm_coordinates = pd.read_csv(figshare_dir + f'/Analysis_For_Paper/Null_Model/residue_coordinates/{mod}.csv', index_col = 0, dtype = {'Source of PTM': str, 'Chromosome/scaffold name': str, 'Gene Location':int,\n",
    "                                                  'Ragged': str})\n",
    "    mapper.ptm_info = residue_info[residue_info['Residue'] == residue]\n",
    "    mapper.alternative_ptms = None\n",
    "    \n",
    "    #project residues to alternative exons as would do for real data\n",
    "    mapper.projectPTMs_toAlternativeExons()\n",
    "\n",
    "    #save project residues to save directory\n",
    "    if not os.path.exists(figshare_dir + f'/Analysis_For_Paper/Null_Model/projected_residues'):\n",
    "      os.mkdir(figshare_dir + f'/Analysis_For_Paper/Null_Model/projected_residues')\n",
    "    mapper.alternative_ptms.to_csv(figshare_dir + f'/Analysis_For_Paper/Null_Model/projected_residues/{mod}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate null model distributions\n",
    "\n",
    "To generate the null model distributions, we follow the same procedure as the true modification data, performing the following steps for each modification class:\n",
    "1. Sample a random subset of residues, matching the same number of residues for that modification.\n",
    "2. Extract the mapping and projection data for those residues, treating them as \"modified\".\n",
    "3. Calculate the constitutive rate and altered flank rate as done with true modifications.\n",
    "4. Save the calculated rates to a list. Repeat a total of 100 times.\n",
    "5. Save rates to a  text file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIsoformSpecificPTMs(alternative_ptms, isoforms, required_length = 20):\n",
    "    \"\"\"\n",
    "    Reduce alternative ptm dataframe to ptms that are unique to a specific protein sequence, rather than a specific transcript. This avoids issue in which multiple transcripts can code for the same protein isoform.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    required_length : int, optional\n",
    "        Minimum length of protein isoform to be considered. The default is 20 amino acids.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    isoform_ptms (as attribute of mapper object): dataframe\n",
    "        Dataframe of PTMs that are unique to a specific protein isoform, rather than a specific transcript.\n",
    "    \"\"\"\n",
    "    #get isoform data, then separate isoform data into unique rows for each transcript\n",
    "    isoforms = isoforms[isoforms['Isoform Type'] == 'Alternative'].copy()\n",
    "    isoforms = isoforms[['Isoform ID', 'Transcript stable ID', 'Isoform Length']]\n",
    "    isoforms['Transcript stable ID'] = isoforms['Transcript stable ID'].apply(lambda x: x.split(';'))\n",
    "    isoforms = isoforms.explode('Transcript stable ID')\n",
    "    isoforms = isoforms.rename({'Transcript stable ID': 'Alternative Transcript'}, axis = 1)\n",
    "\n",
    "    #merge isoform and alternative ptm information\n",
    "    isoform_ptms = alternative_ptms.merge(isoforms, on = 'Alternative Transcript', how = 'left').copy()\n",
    "\n",
    "\n",
    "    #drop duplicate rows by isoform id\n",
    "    isoform_ptms = isoform_ptms.drop_duplicates(subset = ['Isoform ID', 'Source of PTM'])\n",
    "    isoform_ptms = isoform_ptms.drop('Alternative Transcript', axis = 1)\n",
    "\n",
    "    #drop isoforms shorter than 20 amino acids\n",
    "    isoform_ptms = isoform_ptms[isoform_ptms['Isoform Length'] >= required_length]\n",
    "    return isoform_ptms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary for converting between single letter and full names of amino acids\n",
    "residue_dict = {'A': 'Alanine', 'C': 'Cysteine', 'D':'AsparticAcid','E':'GlutamicAcid',\n",
    "                'F':'Phenylalanine','G':'Glycine','H':'Histidine','I':'Isoleucine', \n",
    "                'K':'Lysine', 'L':'Leucine','M':'Methionine', 'N':'Asparagine',\n",
    "                'P':'Proline','Q':'Glutamine','R':'Arginine','S':'Serine', 'T':'Threonine',\n",
    "                'V':'Valine','W':'Tryptophan','Y':'Tyrosine'}\n",
    "\n",
    "#load real ptm data\n",
    "mapper = mapping.PTM_mapper()\n",
    "mapper.getAllFlankingSeqs(flank_size = 10)\n",
    "#get isoform specific ptms (collapse to )\n",
    "mapper.isoform_ptms = pd.read_csv(figshare_dir + '/PTM_Data/processed_data_dir/isoform_ptms.csv', index_col = 0)\n",
    "#calculate real ptm conservation\n",
    "mapper.calculate_PTMconservation()\n",
    "#copy ptm info\n",
    "ptm_info = mapper.ptm_info.copy()\n",
    "\n",
    "#get file for converting modification types to their grouped classess (phosphotyrosine to phosphorylation, etc.)\n",
    "mod_groups = pd.read_csv(figshare_dir + '/External_Data/modification_conversion.csv', header = 0)\n",
    "\n",
    "\n",
    "#separate based on modifications, such that each row is a unique residue/modification type pair\n",
    "exploded_mods = ptm_info.copy()\n",
    "exploded_mods[\"Modification\"] = exploded_mods['Modification'].apply(lambda x: x.split(';'))\n",
    "exploded_mods = exploded_mods.explode('Modification').reset_index()\n",
    "exploded_mods = exploded_mods.rename({'index':'PTM'}, axis = 1)\n",
    "exploded_mods = exploded_mods.drop_duplicates()\n",
    "exploded_mods = exploded_mods.merge(mod_groups[['Mod Name', 'Mod Class']], left_on = 'Modification', right_on = 'Mod Name')\n",
    "exploded_mods = exploded_mods.drop(['Mod Name', 'Modification'], axis = 1)\n",
    "exploded_mods = exploded_mods.drop_duplicates()\n",
    "\n",
    "#load residue information\n",
    "residue_info = pd.read_csv(figshare_dir + '/Analysis_For_Paper/Null_Model/residue_info.csv')\n",
    "residue_info['PTM'] = residue_info.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Null Distribution for Constitutive Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods_to_test = ['PHOS','UBIQ', 'ACET', 'GLCN', 'METH','SUMO', 'DIMETH', 'NTRY', 'HYDR', 'TRIMETH','SULF', 'PALM', 'CITR', 'GGLU']\n",
    "#mods_to_test = ['HYDR', 'TRIMETH','SULF', 'PALM', 'GGLU']\n",
    "#mods_to_test = ['CITR']\n",
    "mod_column = 'Mod Class'\n",
    "for mod in mods_to_test:\n",
    "    print(f'Getting null {mod} data')\n",
    "    tmp_mods = exploded_mods[exploded_mods[mod_column] == mod].copy()\n",
    "    #load toy mapped residues\n",
    "    residues = tmp_mods['Residue'].unique()\n",
    "    sizes = tmp_mods.groupby('Residue').size()\n",
    "    mapped_residues = {}\n",
    "    for res in residues:\n",
    "        try:\n",
    "            mapped_residues[res] = getIsoformSpecificPTMs(pd.read_csv(f'../MockModifications/mapped/{residue_dict[res]}.csv', dtype = {'Exon ID (Alternative)':str, \n",
    "                                                                        'Chromosome/scaffold name': str, 'Ragged':str, 'Genomic Coordinates':str, 'Exon ID (Canonical)': str, \n",
    "                                                                            'Alternative Residue': str, 'Protein':str, 'Canonical Protein Position (AA)': str, \n",
    "                                                                        'Alternative Protein Position (AA)':str,'Mapping Result':str, 'Second Exon': str}), isoforms)\n",
    "        except:\n",
    "            print(f'{residue_dict[res]} not found. {sizes[res]} with modification.')\n",
    "            \n",
    "    unique_res = tmp_mods['Residue'].unique()\n",
    "    num_mod = tmp_mods.groupby('Residue').size()[mapped_residues.keys()]\n",
    "    \n",
    "    np.random.seed(100)\n",
    "    rate_list = []\n",
    "    for i in tqdm.tqdm(range(100)):\n",
    "        #for each residue, randomly sample the number that matches that found within modification population\n",
    "        sampled_results = None\n",
    "        for residue in num_mod.index:\n",
    "            residue_list = residue_info.loc[residue_info['Residue'] == residue, \"PTM\"].unique()\n",
    "            sample = np.random.choice(residue_list, size = num_mod[residue], replace = False)\n",
    "            if sampled_results is None:\n",
    "                conservation_data = residue_info.loc[sample].copy()\n",
    "                sampled_results = mapped_residues[residue][mapped_residues[residue]['Source of PTM'].isin(sample)]\n",
    "            else:\n",
    "                conservation_data = pd.concat([conservation_data, residue_info.loc[sample]])\n",
    "                sampled_results = pd.concat([sampled_results,mapped_residues[residue][mapped_residues[residue]['Source of PTM'].isin(sample)]])\n",
    "\n",
    "        conserved_transcripts = sampled_results[sampled_results['Mapping Result'] == 'Success'].groupby('Source of PTM')['Isoform ID'].apply(list)\n",
    "        num_conserved = conserved_transcripts.apply(len)\n",
    "        num_conserved.name = 'Conserved'\n",
    "\n",
    "        lost_transcripts = sampled_results[sampled_results['Mapping Result'] != 'Success'].groupby('Source of PTM')['Isoform ID'].apply(list)\n",
    "        num_lost = lost_transcripts.apply(len)\n",
    "        num_lost.name = 'Lost'\n",
    "                                               \n",
    "\n",
    "        conservation_data['Number of Conserved Transcripts'] = num_conserved\n",
    "        conservation_data['Number of Lost Transcripts'] = num_lost                                    \n",
    "\n",
    "        conservation_score = []\n",
    "        for ptm in conservation_data.index:\n",
    "            num_conserved = conservation_data.loc[ptm, 'Number of Conserved Transcripts']\n",
    "            num_lost = conservation_data.loc[ptm, 'Number of Lost Transcripts']\n",
    "            #check if there are any conserved transcripts (or if not and is NaN)\n",
    "            if num_conserved != num_conserved and num_lost == num_lost:\n",
    "                conservation_score.append(0)\n",
    "            elif num_conserved != num_conserved and num_lost != num_lost:\n",
    "                conservation_score.append(1)\n",
    "            #check if any lost transcripts: if not replace NaN with 0 when calculating\n",
    "            elif num_lost != num_lost and num_conserved == num_conserved:\n",
    "                conservation_score.append(1)\n",
    "            else:\n",
    "                conservation_score.append(num_conserved/(num_conserved+num_lost))\n",
    "\n",
    "        conservation_data['Score'] = conservation_score\n",
    "        conservation_data['Constitutive'] = (conservation_data['Score'] == 1)*1\n",
    "        rate = conservation_data[conservation_data['Constitutive'] == 1].shape[0]/conservation_data.shape[0]\n",
    "        rate_list.append(rate)\n",
    "        \n",
    "    # open file\n",
    "    with open(figshare_dir + f'/Analysis_For_Paper/Null_Model/Null_Constitutive_Rates/{mod}.txt', 'w+') as f:\n",
    "\n",
    "        # write elements of list\n",
    "        for items in rate_list:\n",
    "            f.write('%s\\n' %items)\n",
    "\n",
    "        print(\"File written successfully\")\n",
    "\n",
    "\n",
    "    # close the file\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Null Model Distributions for Altered Flank Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def getFlankingSequences(isoforms, isoform_ptms, flank_size = 5):\n",
    "    flank_seq = []\n",
    "    for i, row in isoform_ptms.iterrows():\n",
    "        iso_id = row['Isoform ID']\n",
    "        protein_sequence = isoforms.loc[iso_id]\n",
    "        if isinstance(protein_sequence, pd.Series):\n",
    "            protein_sequence = protein_sequence['Amino Acid Sequence']\n",
    "                #if multiple transcripts associated with protein, only use first transcript (should be same seq)\n",
    "            if row['Alternative Protein Position (AA)'] == row['Alternative Protein Position (AA)']:\n",
    "                pos = int(float(row['Alternative Protein Position (AA)']))\n",
    "                if pos <= flank_size:\n",
    "                    #if amino acid does not have long enough N-terminal flanking sequence, add spaces to cushion sequence\n",
    "                    spaces = ''.join([' ' for i in range(flank_size - pos + 1)])\n",
    "                    flank_seq.append(spaces + protein_sequence[0:pos-1]+protein_sequence[pos-1].lower()+protein_sequence[pos:pos+flank_size])\n",
    "                elif len(protein_sequence)-pos <= flank_size:\n",
    "                    #if amino acid does not have long enough C-terminal flanking sequence, add spaces to cushion sequence\n",
    "                    spaces = ''.join([' ' for i in range(flank_size - (len(protein_sequence)-pos))])\n",
    "                    flank_seq.append(protein_sequence[pos-flank_size-1:pos-1]+protein_sequence[pos-1].lower()+protein_sequence[pos:]+spaces)\n",
    "                else:\n",
    "                    #full flanking sequence available\n",
    "                    flank_seq.append(protein_sequence[pos-flank_size-1:pos-1]+protein_sequence[pos-1].lower()+protein_sequence[pos:pos+flank_size])\n",
    "            else:\n",
    "                flank_seq.append(np.nan)\n",
    "        else:\n",
    "            flank_seq.append(np.nan)\n",
    "    return flank_seq\n",
    "\n",
    "\n",
    "def getFlankingSequences_can(transcripts, residue_info, flank_size = 5):\n",
    "    flank_seq = []\n",
    "    for i, row in residue_info.iterrows():\n",
    "        trans_id = row['Transcripts']\n",
    "        if ';' in trans_id:\n",
    "            trans_id = trans_id.split(';')[0]\n",
    "            \n",
    "        protein_sequence = transcripts.loc[trans_id]\n",
    "        if isinstance(protein_sequence, pd.Series):\n",
    "            protein_sequence = protein_sequence['Amino Acid Sequence']\n",
    "                #if multiple transcripts associated with protein, only use first transcript (should be same seq)\n",
    "            if row['PTM Location (AA)'] == row['PTM Location (AA)']:\n",
    "                pos = int(float(row['PTM Location (AA)']))\n",
    "                if pos <= flank_size:\n",
    "                    #if amino acid does not have long enough N-terminal flanking sequence, add spaces to cushion sequence\n",
    "                    spaces = ''.join([' ' for i in range(flank_size - pos + 1)])\n",
    "                    flank_seq.append(spaces + protein_sequence[0:pos-1]+protein_sequence[pos-1].lower()+protein_sequence[pos:pos+flank_size])\n",
    "                elif len(protein_sequence)-pos <= flank_size:\n",
    "                    #if amino acid does not have long enough C-terminal flanking sequence, add spaces to cushion sequence\n",
    "                    spaces = ''.join([' ' for i in range(flank_size - (len(protein_sequence)-pos))])\n",
    "                    flank_seq.append(protein_sequence[pos-flank_size-1:pos-1]+protein_sequence[pos-1].lower()+protein_sequence[pos:]+spaces)\n",
    "                else:\n",
    "                    #full flanking sequence available\n",
    "                    flank_seq.append(protein_sequence[pos-flank_size-1:pos-1]+protein_sequence[pos-1].lower()+protein_sequence[pos:pos+flank_size])\n",
    "            else:\n",
    "                flank_seq.append(np.nan)\n",
    "        else:\n",
    "            flank_seq.append(np.nan)\n",
    "    return flank_seq\n",
    "\n",
    "def matchedFlankSeq(seq1, seq2):\n",
    "    return (seq1 == seq2)*1\n",
    "\n",
    "def compareAllFlankSeqs(residue_info, res, flank_size = 5, unique_isoforms = True):\n",
    "    \"\"\"\n",
    "    Given the alternative ptms and canonical ptm data, compare flanking sequences and determine if they are identical. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    flank_size:\n",
    "        size of the flanking sequence to compare. IMPORTANT, this should not be larger than the available flanking sequence in the ptm_info dataframe\n",
    "    \"\"\"\n",
    "    conserved_flank = []\n",
    "    for i in res.index:\n",
    "        #check if alt flanking seq exists\n",
    "        alt_flank = res.loc[i, 'Flanking Sequence']\n",
    "        if alt_flank != alt_flank:\n",
    "            conserved_flank.append(np.nan)\n",
    "        else:\n",
    "            \n",
    "            ptm = res.loc[i, 'Source of PTM']\n",
    "            if ';' in ptm:\n",
    "                for p in ptm.split(';'):\n",
    "                    try:\n",
    "                        tmp_info = residue_info.loc[p]\n",
    "                        if isinstance(tmp_info, pd.DataFrame):\n",
    "                            iso_id = res.loc[i, 'Isoform ID']\n",
    "                            trans_id = isoforms.loc[iso_id, 'Transcript stable ID'].split(';')\n",
    "                            tmp_info = tmp_info[tmp_info['Transcripts'] == trans_id[0]]\n",
    "                            if tmp_info.shape[0] == 0:\n",
    "                                conserved_flank.append(np.nan)\n",
    "                            else:\n",
    "                                can_flank = tmp_info['Flanking Sequence'].values[0]\n",
    "                            can_flank = tmp_info['Flanking Sequence'].values[0]\n",
    "                        else:\n",
    "                            can_flank = tmp_info['Flanking Sequence']\n",
    "                        #can_flank = can_flank[n_term:c_term]\n",
    "                        conserved_flank.append(matchedFlankSeq(can_flank, alt_flank))\n",
    "                        success = True\n",
    "                    except:\n",
    "                        pass\n",
    "                if not success:\n",
    "                    conserved_flank.append(matchedFlankSeq(can_flank, alt_flank))\n",
    "            else:\n",
    "                \n",
    "                tmp_info = residue_info.loc[ptm]\n",
    "                if isinstance(tmp_info, pd.DataFrame):\n",
    "                    iso_id = res.loc[i, 'Isoform ID']\n",
    "                    trans_id = isoforms.loc[iso_id, 'Transcript stable ID'].split(';')\n",
    "                    tmp_info = tmp_info[tmp_info['Transcripts'] == trans_id[0]]\n",
    "                    if tmp_info.shape[0] == 0:\n",
    "                        conserved_flank.append(np.nan)\n",
    "                    else:\n",
    "                        can_flank = tmp_info['Flanking Sequence'].values[0]\n",
    "                else:\n",
    "                    can_flank = tmp_info['Flanking Sequence']\n",
    "                #can_flank = can_flank[n_term:c_term]\n",
    "                conserved_flank.append(matchedFlankSeq(can_flank, alt_flank))\n",
    "                \n",
    "                    #conserved_flank.append(np.nan)\n",
    "    return conserved_flank\n",
    "\n",
    "def compareAllFlankSeqs2(residue_info, res, flank_size = 5, unique_isoforms = True):\n",
    "    \"\"\"\n",
    "    Given the alternative ptms and canonical ptm data, compare flanking sequences and determine if they are identical. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    flank_size:\n",
    "        size of the flanking sequence to compare. IMPORTANT, this should not be larger than the available flanking sequence in the ptm_info dataframe\n",
    "    \"\"\"\n",
    "    conserved_flank = []\n",
    "    for i in res.index:\n",
    "        #check if alt flanking seq exists\n",
    "        alt_flank = res.loc[i, 'Flanking Sequence']\n",
    "        if alt_flank != alt_flank:\n",
    "            conserved_flank.append(np.nan)\n",
    "        else:\n",
    "            \n",
    "            ptm = res.loc[i, 'Source of PTM'].split(';')[0]\n",
    "            try:\n",
    "                tmp_info = residue_info.loc[ptm]\n",
    "                can_flank = tmp_info['Flanking Sequence']\n",
    "                #can_flank = can_flank[n_term:c_term]\n",
    "                conserved_flank.append(matchedFlankSeq(can_flank, alt_flank))\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                conserved_flank.append(np.nan)\n",
    "                \n",
    "                    #conserved_flank.append(np.nan)\n",
    "\n",
    "    return conserved_flank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = pd.read_csv(config.processed_data_dir + 'transcripts.csv', index_col = 0)\n",
    "residue_info['Flanking Sequence'] = getFlankingSequences_can(transcripts, residue_info, flank_size = 5)\n",
    "\n",
    "mods_to_test = ['PHOS','UBIQ', 'ACET', 'GLCN', 'METH','SUMO', 'DIMETH', 'NTRY', 'HYDR', 'TRIMETH','SULF', 'PALM', 'GGLU']\n",
    "mod_column = 'Mod Class'\n",
    "for mod in mods_to_test:\n",
    "    print(f'Getting null {mod} data')\n",
    "    tmp_mods = exploded_mods[exploded_mods[mod_column] == mod].copy()\n",
    "    #load toy mapped residues\n",
    "    residues = tmp_mods['Residue'].unique()\n",
    "    sizes = tmp_mods.groupby('Residue').size()\n",
    "    mapped_residues = {}\n",
    "    for res in residues:\n",
    "        try:\n",
    "            mapped_residues[res] = getIsoformSpecificPTMs(pd.read_csv(f'../MockModifications/mapped/{residue_dict[res]}.csv', dtype = {'Exon ID (Alternative)':str, \n",
    "                                                                        'Chromosome/scaffold name': str, 'Ragged':str, 'Genomic Coordinates':str, 'Exon ID (Canonical)': str, \n",
    "                                                                            'Alternative Residue': str, 'Protein':str, 'Canonical Protein Position (AA)': str, \n",
    "                                                                        'Alternative Protein Position (AA)':str,'Mapping Result':str, 'Second Exon':str}), isoforms)\n",
    "        except:\n",
    "            print(f'{residue_dict[res]} not found. {sizes[res]} with modification.')\n",
    "            \n",
    "    unique_res = tmp_mods['Residue'].unique()\n",
    "    num_mod = tmp_mods.groupby('Residue').size()[mapped_residues.keys()]\n",
    "    \n",
    "    np.random.seed(100)\n",
    "    flank_conservation_list = []\n",
    "    for i in tqdm.tqdm(range(100)):\n",
    "        #for each residue, randomly sample the number that matches that found within modification population\n",
    "        sampled_results = None\n",
    "        for residue in num_mod.index:\n",
    "            #residue_list = residue_info.loc[residue_info['Residue'] == residue, \"PTM\"].unique()\n",
    "            residue_list = np.unique(residue_info[residue_info['Residue'] == residue].index.values)\n",
    "            sample = np.random.choice(residue_list, size = num_mod[residue], replace = False)\n",
    "            if sampled_results is None:\n",
    "                conservation_data = residue_info.loc[sample].copy()\n",
    "                sampled_results = mapped_residues[residue][mapped_residues[residue]['Source of PTM'].isin(sample)]\n",
    "            else:\n",
    "                conservation_data = pd.concat([conservation_data, residue_info.loc[sample]])\n",
    "                sampled_results = pd.concat([sampled_results,mapped_residues[residue][mapped_residues[residue]['Source of PTM'].isin(sample)]])\n",
    "\n",
    "        #get flanking sequences\n",
    "        sampled_results = sampled_results.reset_index()\n",
    "        sampled_results['Flanking Sequence'] = getFlankingSequences(mapper.isoforms, sampled_results)\n",
    "        sampled_results = sampled_results.dropna(subset = 'Flanking Sequence')\n",
    "        conserved_flanks = compareAllFlankSeqs2(residue_info, sampled_results)\n",
    "        conserved_flanks = [f for f in conserved_flanks if f == f]\n",
    "        #calculate fraction of ptms with conserved flank\n",
    "        flank_conservation_list.append(1- sum(conserved_flanks)/len(conserved_flanks))\n",
    "        \n",
    "                                               \n",
    "        \n",
    "    # open file\n",
    "    with open(figshare_dir + f'/Analysis_For_Paper/Null_Model/Null_Flank_Rates/{mod}.txt', 'w+') as f:\n",
    "\n",
    "        # write elements of list\n",
    "        for items in flank_conservation_list:\n",
    "            f.write('%s\\n' %items)\n",
    "\n",
    "        print(\"File written successfully\")\n",
    "\n",
    "\n",
    "    # close the file\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
